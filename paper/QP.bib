
@article{abdurraqibHowGillianWelch2020,
  title = {How {{Gillian Welch}} and {{David Rawlings Held Onto Optimism}}},
  author = {Abdurraqib, Hanif},
  year = {2020},
  month = nov,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {The uncertainties of 2020 led the folk duo to discover a new emotional urgency in songs about the slow, challenging, beautiful heat of living.},
  chapter = {Magazine},
  langid = {american},
  keywords = {Bob,Cash,Country Music,David,Dylan,Emmylou,Folk Music,Gillian,Harris,Johnny,Nashville (Tenn),Quarantine (Life and Culture),Rawlings,Welch}
}

@article{abueladasEffectsLexicalPhonological2018,
  title = {The {{Effects}} of {{Lexical}} and {{Phonological Factors}} on {{Talker Processing}}},
  author = {Abu El Adas, Sandy and Levi, Susannah V.},
  year = {2018},
  month = mar,
  journal = {The Journal of the Acoustical Society of America},
  volume = {143},
  number = {3},
  pages = {1923--1923},
  issn = {0001-4966},
  doi = {10.1121/1.5036275}
}

@book{AcousticEffectsMedical,
  title = {Acoustic {{Effects}} of {{Medical}}, {{Cloth}}, and {{Transparent Face Masks}} on {{Speech Signals}}: {{The Journal}} of the {{Acoustical Society}} of {{America}}: {{Vol}} 148, {{No}} 4}
}

@book{AcousticPhoneticCharacteristicsSpeech,
  title = {Acoustic-{{Phonetic Characteristics}} of {{Speech Produced}} with {{Communicative Intent}} to {{Counter Adverse Listening Conditions}}: {{The Journal}} of the {{Acoustical Society}} of {{America}}: {{Vol}} 130, {{No}} 4}
}

@article{adriaansProsodicExaggerationInfantDirected2017,
  title = {Prosodic {{Exaggeration}} within {{Infant-Directed Speech}}: {{Consequences}} for {{Vowel Learnability}}},
  shorttitle = {Prosodic {{Exaggeration}} within {{Infant-Directed Speech}}},
  author = {Adriaans, Frans and Swingley, Daniel},
  year = {2017},
  month = may,
  journal = {The Journal of the Acoustical Society of America},
  volume = {141},
  number = {5},
  pages = {3070--3078},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.4982246}
}

@article{aksentijevicOscillatoryEntrainmentVirtual2013,
  title = {The {{Oscillatory Entrainment}} of {{Virtual Pitch Perception}}},
  author = {Aksentijevic, Aleksandar and Northeast, Anthony and Elliott, Mark},
  year = {2013},
  journal = {Front. Psychol.},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00210},
  abstract = {Evidence suggests that synchronized brain oscillations in the low gamma range (around 33 Hz) are involved in the perceptual integration of harmonic complex tones. This process involves the binding of harmonic components into ``harmonic templates'' \textendash{} neural structures responsible for pitch coding in the brain. We investigated the hypothesis that oscillatory harmonic binding promotes a change in pitch perception style from spectral (frequency) to virtual (relational). Using oscillatory priming we asked 24 participants to judge as rapidly as possible, the direction of an ambiguous target with ascending spectral and descending virtual contour. They made significantly more virtual responses when primed at 29, 31 and 33 Hz and when the first target tone was harmonically related to the prime, suggesting that neural synchronization in the low gamma range could facilitate a shift towards virtual pitch processing.},
  langid = {english},
  keywords = {gamma-band,harmonic templates,oscillatory priming,pitch coding,Pitch Perception,virtual pitch}
}

@article{alber1997quantity,
  title = {Quantity Sensitivity as the Result of Constraint Interaction},
  author = {Alber, Birgit},
  year = {1997},
  journal = {Phonology in progress: progress in phonology. The Hague: Holland Academic Graphics},
  pages = {1--45},
  file = {/Users/sarah/Zotero/storage/44S49DMQ/roa-310-alber-2-1.ps}
}

@article{albouyDistinctSensitivitySpectrotemporal2020,
  title = {Distinct {{Sensitivity}} to {{Spectrotemporal Modulation Supports Brain Asymmetry}} for {{Speech}} and {{Melody}}},
  author = {Albouy, Philippe and Benjamin, Lucas and Morillon, Benjamin and Zatorre, Robert J.},
  year = {2020},
  month = feb,
  journal = {Science},
  volume = {367},
  number = {6481},
  pages = {1043--1047},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaz3468},
  abstract = {Speech versus music in the brain To what extent does the perception of speech and music depend on different mechanisms in the human brain? What is the anatomical basis underlying this specialization? Albouy et al. created a corpus of a cappella songs that contain both speech (semantic) and music (melodic) information and degraded each stimulus selectively in either the temporal or spectral domain. Degradation of temporal information impaired speech recognition but not melody recognition, whereas degradation of spectral information impaired melody recognition but not speech recognition. Brain scanning revealed a right-left asymmetry for speech and music. Classification of speech content occurred exclusively in the left auditory cortex, whereas classification of melodic content occurred only in the right auditory cortex. Science, this issue p. 1043 Does brain asymmetry for speech and music emerge from acoustical cues or from domain-specific neural networks? We selectively filtered temporal or spectral modulations in sung speech stimuli for which verbal and melodic content was crossed and balanced. Perception of speech decreased only with degradation of temporal information, whereas perception of melodies decreased only with spectral degradation. Functional magnetic resonance imaging data showed that the neural decoding of speech and melodies depends on activity patterns in left and right auditory regions, respectively. This asymmetry is supported by specific sensitivity to spectrotemporal modulation rates within each region. Finally, the effects of degradation on perception were paralleled by their effects on neural classification. Our results suggest a match between acoustical properties of communicative signals and neural specializations adapted to that purpose. A human brain imaging study reveals that low-level acoustical cues support hemispheric lateralization of speech and music perception. A human brain imaging study reveals that low-level acoustical cues support hemispheric lateralization of speech and music perception.},
  chapter = {Report},
  copyright = {Copyright \textcopyright{} 2020 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
  langid = {english},
  pmid = {32108113}
}

@article{albrightFeatureBasedGeneralisationSource2009,
  title = {Feature-{{Based Generalisation}} as a {{Source}} of {{Gradient Acceptability}}},
  author = {Albright, Adam},
  year = {2009},
  journal = {Phonology},
  volume = {26},
  number = {1},
  pages = {9--41},
  issn = {0952-6757},
  abstract = {Phonological judgements are often gradient: blick\${$>\$$}?bwick\${$>\$$}*bnick\${$>\$$}**bzick. The mechanisms behind gradient generalisation remain controversial, however. This paper tests the role of phonological features in helping speakers evaluate which novel combinations receive greater lexical support. A model is proposed in which the acceptability of a string is based on the most probable combination of natural classes that it instantiates. The model is tested on its ability to predict acceptability ratings of nonce words, and its predictions are compared against those of models that lack features or economise on feature specifications. The proposed model achieves the best balance of performance on attested and unattested sequences, and is a significant predictor of acceptability even after the other models are factored out. The feature-based model's predictions do not completely subsume those of simpler models, however. This may indicate multiple levels of evaluation, involving segment-based phonotactic probability and feature-based gradient phonological grammaticality.}
}

@article{allopennaTrackingTimeCourse1998,
  title = {Tracking the {{Time Course}} of {{Spoken Word Recognition Using Eye Movements}}: {{Evidence}} for {{Continuous Mapping Models}}},
  shorttitle = {Tracking the {{Time Course}} of {{Spoken Word Recognition Using Eye Movements}}},
  author = {Allopenna, Paul D. and Magnuson, James S. and Tanenhaus, Michael K.},
  year = {1998},
  month = may,
  journal = {Journal of Memory and Language},
  volume = {38},
  number = {4},
  pages = {419--439},
  issn = {0749596X},
  doi = {10.1006/jmla.1997.2558},
  langid = {english}
}

@incollection{alma991044196869706011,
  title = {{Eesti keele s\~onafonoloogia / Mati Hint.}},
  booktitle = {{Eesti keele s\~onafonoloogia}},
  author = {Hint, Mati.},
  year = {1973},
  publisher = {{Eesti NSV Teaduste Akadeemia, Keele ja Kirjanduse Instituut}},
  address = {{Tallinn}},
  langid = {estonian},
  lccn = {75582567},
  keywords = {Estonian language – Phonology}
}

@article{aloniIndefinitesComparatives2014,
  title = {Indefinites in {{Comparatives}}},
  author = {Aloni, Maria and Roelofsen, Floris},
  year = {2014},
  journal = {Natural Language Semantics},
  volume = {22},
  number = {2},
  pages = {145--167},
  publisher = {{Springer}},
  issn = {0925-854X},
  abstract = {The goal of this paper is to explain the meaning and distribution of indefinites in comparatives, focusing on English some and any and German irgend-indefinites. We consider three competing theories of comparatives in combination with an alternative semantics of some and any, and a novel account of stressed irgend-indefinites. One of the resulting accounts, based on Heim's analysis of comparatives, predicts all the relevant differences in quantificational force, and explains why free choice indefinites are licensed in comparatives.}
}

@book{AlteredOscillationsModulatory2020,
  title = {Altered {{Oscillations}}: {{The Modulatory Effect}} of {{DMT}} on {{Brain Waves}}},
  shorttitle = {Altered {{Oscillations}}},
  year = {2020},
  month = jan,
  journal = {Psychedelic Science Review},
  abstract = {A recent Nature paper provides novel insights into the neural correlates of the Breakthrough Experience associated with DMT.},
  chapter = {Scientific Research},
  langid = {american}
}

@article{andruskiEffectSubphoneticDifferences1994,
  title = {The {{Effect}} of {{Subphonetic Differences}} on {{Lexical Access}}},
  author = {Andruski, Jean E. and Blumstein, Sheila E. and Burton, Martha},
  year = {1994},
  month = sep,
  journal = {Cognition},
  volume = {52},
  number = {3},
  pages = {163--187},
  issn = {00100277},
  doi = {10.1016/0010-0277(94)90042-6},
  abstract = {This study investigated whether lexical access is affected by inherent acoustic variations that contribute to the identity of a phonetic feature and ultimately a phonetic segment. Two experiments were conducted to determine whether the magnitude of semantic (associative) priming in a lexical decision task is influenced when the acoustic manifestation of the initial voiceless stop consonant (specifically, voice onset time) of a prime word semantically related to a lexical decision target was .systematically manipulated (e.g., prime: ``king''; target: ``queen ``). Results showed no effect of the acoustic manipulations at the longer inter-stimulus interval (250 ms); however, at the shorter interstimulus interval (50 ms), the magnitude of semantic facilitation decreased as a function of the voice onset time manipulations. In addition, there was a tendency toward slower lexical decision latencies when the prime word had a real word voiced counterpart than when it did not. These results suggest that activation levels of words in the lexicon are graded, depending on the subphonetic shape of the input word. Results also suggest that words which are phonologically similar to the intended word candidate are activated to some extent, whether the input provides a relatively poor phonetic representation of the intended word or a good one.},
  langid = {english}
}

@article{anwyl-irvineGorillaOurMidst2020,
  title = {Gorilla in Our Midst: {{An}} Online Behavioral Experiment Builder},
  shorttitle = {Gorilla in Our Midst},
  author = {{Anwyl-Irvine}, Alexander L. and Massonni{\'e}, Jessica and Flitton, Adam and Kirkham, Natasha and Evershed, Jo K.},
  year = {2020},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {52},
  number = {1},
  pages = {388--407},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01237-x},
  abstract = {Behavioral researchers are increasingly conducting their studies online, to gain access to large and diverse samples that would be difficult to get in a laboratory environment. However, there are technical access barriers to building experiments online, and web browsers can present problems for consistent timing\textemdash an important issue with reaction-time-sensitive measures. For example, to ensure accuracy and test\textendash retest reliability in presentation and response recording, experimenters need a working knowledge of programming languages such as JavaScript. We review some of the previous and current tools for online behavioral research, as well as how well they address the issues of usability and timing. We then present the Gorilla Experiment Builder (gorilla.sc), a fully tooled experiment authoring and deployment platform, designed to resolve many timing issues and make reliable online experimentation open and accessible to a wider range of technical abilities. To demonstrate the platform's aptitude for accessible, reliable, and scalable research, we administered a task with a range of participant groups (primary school children and adults), settings (without supervision, at home, and under supervision, in both schools and public engagement events), equipment (participant's own computer, computer supplied by the researcher), and connection types (personal internet connection, mobile phone 3G/4G). We used a simplified flanker task taken from the attentional network task (Rueda, Posner, \& Rothbart, 2004). We replicated the ``conflict network'' effect in all these populations, demonstrating the platform's capability to run reaction-time-sensitive experiments. Unresolved limitations of running experiments online are then discussed, along with potential solutions and some future features of the platform.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/IW6Y6H3Z/Anwyl-Irvine et al. - 2020 - Gorilla in our midst An online behavioral experim.pdf}
}

@article{anwyl-irvineRealisticPrecisionAccuracy2020,
  title = {Realistic {{Precision}} and {{Accuracy}} of {{Online Experiment Platforms}}, {{Web Browsers}}, and {{Devices}}},
  author = {{Anwyl-Irvine}, Alexander and Dalmaijer, Edwin S. and Hodges, Nick and Evershed, Jo K.},
  year = {2020},
  month = nov,
  journal = {Behav Res},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01501-5},
  abstract = {Due to increasing ease of use and ability to quickly collect large samples, online behavioural research is currently booming. With this popularity, it is important that researchers are aware of who online participants are, and what devices and software they use to access experiments. While it is somewhat obvious that these factors can impact data quality, the magnitude of the problem remains unclear. To understand how these characteristics impact experiment presentation and data quality, we performed a battery of automated tests on a number of realistic set-ups. We investigated how different web-building platforms (Gorilla v.20190828, jsPsych v6.0.5, Lab.js v19.1.0, and psychoJS/PsychoPy3 v3.1.5), browsers (Chrome, Edge, Firefox, and Safari), and operating systems (macOS and Windows 10) impact display time across 30 different frame durations for each software combination. We then employed a robot actuator in realistic set-ups to measure response recording across the aforementioned platforms, and between different keyboard types (desktop and integrated laptop). Finally, we analysed data from over 200,000 participants on their demographics, technology, and software to provide context to our findings. We found that modern web platforms provide reasonable accuracy and precision for display duration and manual response time, and that no single platform stands out as the best in all features and conditions. In addition, our online participant analysis shows what equipment they are likely to use.},
  langid = {english}
}

@article{arbesmanComparativeAnalysisNetworks2010,
  title = {Comparative {{Analysis}} of {{Networks}} of {{Phonologically Similar Words}} in {{English}} and {{Spanish}}},
  author = {Arbesman, Samuel and Strogatz, Steven and Vitevitch, Michael},
  year = {2010},
  month = mar,
  journal = {Entropy},
  volume = {12},
  number = {3},
  pages = {327--337},
  issn = {1099-4300},
  doi = {10.3390/e12030327},
  abstract = {Previous network analyses of several languages revealed a unique set of structural characteristics. One of these characteristics\textemdash{} the presence of many smaller components (referred to as islands)\textemdash{} was further examined with a comparative analysis of the island constituents. The results showed that Spanish words in the islands tended to be phonologically and semantically similar to each other, but English words in the islands tended only to be phonologically similar to each other. The results of this analysis yielded hypotheses about language processing that can be tested with psycholinguistic experiments, and offer insight into cross-language differences in processing that have been previously observed.},
  langid = {english}
}

@article{arbesmanSTRUCTUREPHONOLOGICALNETWORKS2010,
  title = {{{THE STRUCTURE OF PHONOLOGICAL NETWORKS ACROSS MULTIPLE LANGUAGES}}},
  author = {Arbesman, Samuel and Strogatz, Steven H. and Vitevitch, Michael S.},
  year = {2010},
  month = mar,
  journal = {Int. J. Bifurcation Chaos},
  volume = {20},
  number = {03},
  pages = {679--685},
  issn = {0218-1274, 1793-6551},
  doi = {10.1142/S021812741002596X},
  abstract = {The network characteristics based on the phonological similarities in the lexicons of several languages were examined. These languages differed widely in their history and linguistic structure, but commonalities in the network characteristics were observed. These networks were also found to be different from other networks studied in the literature. The properties of these networks suggest explanations for various aspects of linguistic processing and hint at deeper organization within the human language.},
  langid = {english}
}

@article{arbesmanSTRUCTUREPHONOLOGICALNETWORKS2012,
  title = {{{THE STRUCTURE OF PHONOLOGICAL NETWORKS ACROSS MULTIPLE LANGUAGES}}},
  author = {ARBESMAN, SAMUEL and STROGATZ, STEVEN H. and VITEVITCH, MICHAEL S.},
  year = {2012},
  month = may,
  journal = {International Journal of Bifurcation and Chaos},
  doi = {10.1142/S021812741002596X},
  abstract = {The network characteristics based on the phonological similarities in the lexicons of several languages were examined. These languages differed widely in their history and linguistic structure, but...},
  langid = {english}
}

@incollection{arvanitiRhythmClassesSpeech2012,
  title = {Rhythm Classes and Speech Perception},
  booktitle = {Understanding {{Prosody}}},
  author = {Arvaniti, Amalia},
  editor = {Niebuhr, Oliver},
  year = {2012},
  month = jan,
  publisher = {{DE GRUYTER}},
  address = {{Berlin, Boston}},
  doi = {10.1515/9783110301465.75},
  isbn = {978-3-11-030146-5},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/5C66MUF4/Arvaniti - 2012 - Rhythm classes and speech perception.pdf}
}

@article{arvanitiRoleRhythmClass2013,
  title = {The Role of Rhythm Class, Speaking Rate, and {{F0}} in Language Discrimination},
  author = {Arvaniti, Amalia and Rodriquez, Tara},
  year = {2013},
  month = jan,
  journal = {Laboratory Phonology},
  volume = {4},
  number = {1},
  issn = {1868-6354, 1868-6346},
  doi = {10.1515/lp-2013-0002},
  abstract = {The division of languages into stress-, syllable-, and mora-timing is said to be supported by experiments showing that languages are discriminated only if they belong to different rhythm classes, a distinction said to be reflected in the duration and variability of consonantal and vocalic intervals (timing). The role of rhythm classes in discrimination is tested here along with the alternative that discrimination is due to speaking rate and F0 differences and is independent of rhythm class. Five AAX experiments with English as context (AA) and Polish, Danish, Spanish, Greek, or Korean as test (X) were conducted using the sasasa transform and modifying F0 and speaking rate, so as to compare responses to stimuli that retained the original speaking rate and F0 of each language and stimuli that were stripped of this information (speaking rate, F0, or both) while retaining their timing. Discrimination was possible both across and within rhythm classes when speaking rates differed between context and test but was largely impossible once speaking rate differences were eliminated. F0 also played a significant if less consistent role in discrimination. The changes in responses associated with speaking rate and F0 indicate that language discrimination arises from interactions between prosodic factors and that timing contributes but little. Consequently the results cast doubt both on the ecological validity of the sasasa transform, which brings timing to the fore while eliminating F0 modulation, and on the rhythm class typology said to be reflected in timing distinctions.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/QXWG89ER/Arvaniti and Rodriquez - 2013 - The role of rhythm class, speaking rate, and F0 in.pdf}
}

@article{asuEstonian2009,
  title = {Estonian},
  author = {Asu, Eva Liina and Teras, Pire},
  year = {2009},
  month = dec,
  journal = {Journal of the International Phonetic Association},
  volume = {39},
  number = {3},
  pages = {367--372},
  publisher = {{Cambridge University Press}},
  issn = {1475-3502, 0025-1003},
  doi = {10.1017/S002510030999017X},
  abstract = {Estonian belongs to the Finnic branch of the Finno-Ugric language family and is closely related to Finnish. It has about one million native speakers in Estonia and about 150,000 elsewhere in the world. In phonetics, Estonian is probably best known for its three degrees of contrastive quantity: short (Q1), long (Q2) and overlong (Q3).},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/SDA7FDCL/Asu and Teras - 2009 - Estonian.pdf;/Users/sarah/Zotero/storage/JYRE5Q6F/629DFE570A2E6606733B29A0145B4512.html}
}

@article{atkinsonClosingGap2013,
  title = {Closing the Gap},
  author = {Atkinson, Judy},
  year = {2013},
  file = {/Users/sarah/Zotero/storage/LEWXB48G/Atkinson - 2013 - Closing the gap.pdf}
}

@article{baese-berkSpeakingRateConsistency2015,
  title = {Speaking {{Rate Consistency}} in {{Native}} and {{Non-Native Speakers}} of {{English}}},
  author = {{Baese-Berk}, Melissa M. and Morrill, Tuuli H.},
  year = {2015},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {138},
  number = {3},
  pages = {EL223-EL228},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.4929622},
  abstract = {Non-native speech differs from native speech in multiple ways. Previous research has described segmental and suprasegmental differences between native and non-native speech in terms of group averages. For example, average speaking rate for non-natives is slower than for natives. However, it is unknown whether non-native speech is also more variable than native speech. This study introduces a method of comparing rate change across utterances, demonstrating that non-native speaking rate is more variable than native speech. These results suggest that future work examining non-native speech perception and production should investigate both mean differences and variability in the signal.}
}

@article{baeza-blancasRecurrenceNetworksNatural2019,
  title = {Recurrence {{Networks}} in {{Natural Languages}}},
  author = {{Baeza-Blancas}, Edgar and {Obreg{\'o}n-Quintana}, Bibiana and {Hern{\'a}ndez-G{\'o}mez}, Candelario and {G{\'o}mez-Mel{\'e}ndez}, Domingo and {Aguilar-Vel{\'a}zquez}, Daniel and Liebovitch, Larry S. and {Guzm{\'a}n-Vargas}, Lev},
  year = {2019},
  month = may,
  journal = {Entropy},
  volume = {21},
  number = {5},
  pages = {517},
  doi = {10.3390/e21050517},
  abstract = {We present a study of natural language using the recurrence network method. In our approach, the repetition of patterns of characters is evaluated without considering the word structure in written texts from different natural languages. Our dataset comprises 85 ebookseBooks written in 17 different European languages. The similarity between patterns of length m is determined by the Hamming distance and a value r is considered to define a matching between two patterns, i.e., a repetition is defined if the Hamming distance is equal or less than the given threshold value r. In this way, we calculate the adjacency matrix, where a connection between two nodes exists when a matching occurs. Next, the recurrence network is constructed for the texts and some representative network metrics are calculated. Our results show that average values of network density, clustering, and assortativity are larger than their corresponding shuffled versions, while for metrics like such as closeness, both original and random sequences exhibit similar values. Moreover, our calculations show similar average values for density among languages which that belong to the same linguistic family. In addition, the application of a linear discriminant analysis leads to well-separated clusters of family languages based on based on the network-density properties. Finally, we discuss our results in the context of the general characteristics of written texts.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {natural languages,patterns repetition,recurrence networks}
}

@article{bakerVariabilityWordDuration2009,
  title = {Variability in {{Word Duration}} as a {{Function}} of {{Probability}}, {{Speech Style}}, and {{Prosody}}},
  author = {Baker, Rachel E. and Bradlow, Ann R.},
  year = {2009},
  month = dec,
  journal = {Lang Speech},
  volume = {52},
  number = {4},
  pages = {391--413},
  publisher = {{SAGE Publications Ltd}},
  issn = {0023-8309},
  doi = {10.1177/0023830909336575},
  abstract = {This article examines how probability (lexical frequency and previous mention), speech style, and prosody affect word duration, and how these factors interact. Participants read controlled materials in clear and plain speech styles. As expected, more probable words (higher frequencies and second mentions) were significantly shorter than less probable words, and words in plain speech were significantly shorter than those in clear speech. Interestingly, we found second mention reduction effects in both clear and plain speech, indicating that while clear speech is hyper-articulated, this hyper-articulation does not override probabilistic effects on duration. We also found an interaction between mention and frequency, but only in plain speech. High frequency words allowed more second mention reduction than low frequency words in plain speech, revealing a tendency to hypo-articulate as much as possible when all factors support it. Finally, we found that first mentions were more likely to be accented than second mentions. However, when these differences in accent likelihood were controlled, a significant second mention reduction effect remained. This supports the concept of a direct link between probability and duration, rather than a relationship solely mediated by prosodic prominence.},
  langid = {english}
}

@article{bakerVariabilityWordDuration2009a,
  title = {Variability in {{Word Duration}} as a {{Function}} of {{Probability}}, {{Speech Style}}, and {{Prosody}}},
  author = {Baker, Rachel E. and Bradlow, Ann R.},
  year = {2009},
  month = dec,
  journal = {Lang Speech},
  volume = {52},
  number = {4},
  pages = {391--413},
  publisher = {{SAGE Publications Ltd}},
  issn = {0023-8309},
  doi = {10.1177/0023830909336575},
  abstract = {This article examines how probability (lexical frequency and previous mention), speech style, and prosody affect word duration, and how these factors interact. Participants read controlled materials in clear and plain speech styles. As expected, more probable words (higher frequencies and second mentions) were significantly shorter than less probable words, and words in plain speech were significantly shorter than those in clear speech. Interestingly, we found second mention reduction effects in both clear and plain speech, indicating that while clear speech is hyper-articulated, this hyper-articulation does not override probabilistic effects on duration. We also found an interaction between mention and frequency, but only in plain speech. High frequency words allowed more second mention reduction than low frequency words in plain speech, revealing a tendency to hypo-articulate as much as possible when all factors support it. Finally, we found that first mentions were more likely to be accented than second mentions. However, when these differences in accent likelihood were controlled, a significant second mention reduction effect remained. This supports the concept of a direct link between probability and duration, rather than a relationship solely mediated by prosodic prominence.}
}

@article{ballingProbabilitySurprisalAuditory2012,
  title = {Probability and {{Surprisal}} in {{Auditory Comprehension}} of {{Morphologically Complex Words}}},
  author = {Balling, Laura Winther and Baayen, R. Harald},
  year = {2012},
  month = oct,
  journal = {Cognition},
  volume = {125},
  number = {1},
  pages = {80--106},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2012.06.003},
  abstract = {Two auditory lexical decision experiments document for morphologically complex words two points at which the probability of a target word given the evidence shifts dramatically. The first point is reached when morphologically unrelated competitors are no longer compatible with the evidence. Adapting terminology from Marslen-Wilson (1984), we refer to this as the word's initial uniqueness point (UP1). The second point is the complex uniqueness point (CUP) introduced by Balling and Baayen (2008), at which morphologically related competitors become incompatible with the input. Later initial as well as complex uniqueness points predict longer response latencies. We argue that the effects of these uniqueness points arise due to the large surprisal (Levy, 2008) carried by the phonemes at these uniqueness points, and provide independent evidence that how cumulative surprisal builds up in the course of the word co-determines response latencies. The presence of effects of surprisal, both at the initial uniqueness point of complex words, and cumulatively throughout the word, challenges the Shortlist B model of Norris and McQueen (2008), and suggests that a Bayesian approach to auditory comprehension requires complementation from information theory in order to do justice to the cognitive cost of updating probability distributions over lexical candidates.},
  langid = {english},
  keywords = {(cumulative) Surprisal,Kullback–Leibler divergence,Morphological family size,Morphological processing,Neighborhood measures,Shortlist B,Spoken word recognition,Uniqueness points}
}

@article{barajasLearningMistakesUsing2015,
  title = {Learning from {{Mistakes}}: {{Using Audio-Recorded Transcription Errors}} to {{Probe}} the {{Sociocognitive Paradigm}} in {{Language Processing}}},
  shorttitle = {Learning from {{Mistakes}}},
  author = {Barajas, El{\'i}as Dom{\'i}nguez},
  year = {2015},
  journal = {Discourse Studies},
  volume = {17},
  number = {3},
  pages = {259--281},
  issn = {1461-4456},
  abstract = {This article argues that errors in audio data processing should be (re)examined to explore and expose the underlying components that enable linguistic communication and cross-cultural understanding. Examples of errors in the transcription of a Mexican social network's conversations are analyzed to demonstrate the potential of such data in the development of sociocognitive language-processing theories (those that combine formal and pragmatic approaches). It is suggested that researchers working with audio-recorded data should expand the scope of what is considered useful data for the sake of both methodological reflexivity and identifying the underlying cognitive processes enabling linguistic understanding.}
}

@article{bausNeighbourhoodDensityFrequency2008,
  title = {Neighbourhood Density and Frequency Effects in Speech Production: {{A}} Case for Interactivity},
  shorttitle = {Neighbourhood Density and Frequency Effects in Speech Production},
  author = {Baus, Cristina and Costa, Albert and Carreiras, Manuel},
  year = {2008},
  month = sep,
  journal = {Language and Cognitive Processes},
  volume = {23},
  number = {6},
  pages = {866--888},
  publisher = {{Routledge}},
  issn = {0169-0965},
  doi = {10.1080/01690960801962372},
  abstract = {In three experiments, we explore the effects of phonological properties such as neighbourhood density and frequency on speech production in Spanish. Specifically, we assess the reliability of the recent observation made by Vitevitch and Stamer (2006), according to which the neighbourhood effect in Spanish has a reverse polarity to that observed in other languages. In Experiment 1, we replicate Vitevitch and Stamer's (2006) experiment, this time adding a control group. The same inhibitory neighbourhood effect found for both groups can not corroborate the hypothesis posited by Vitevitch and Stamer. In Experiment 2, our results show that native speakers of Spanish named pictures with words belonging to high density neighbourhoods faster than those belonging to low density neighbourhoods. In Experiment 3, we test for effects of neighbourhood frequency during lexical selection. Again, we find a facilitatory effect for words with a high-frequency neighbourhood. Together, the results of the present experiments suggest that lexical selection is facilitated by the number of neighbours and by neighbourhoods with higher frequency. These findings are consistent with the predictions of interactive models.},
  annotation = {\_eprint: https://doi.org/10.1080/01690960801962372},
  file = {/Users/sarah/Zotero/storage/URB4GIE6/Baus et al. - 2008 - Neighbourhood density and frequency effects in spe.pdf;/Users/sarah/Zotero/storage/8TY9RX5X/01690960801962372.html}
}

@article{beckfordwassinkIntraspeakerVariabilityVowel2007,
  title = {Intraspeaker {{Variability}} in {{Vowel Production}}: {{An Investigation}} of {{Motherese}}, {{Hyperspeech}}, and {{Lombard Speech}} in {{Jamaican Speakers}}},
  shorttitle = {Intraspeaker {{Variability}} in {{Vowel Production}}},
  author = {Beckford Wassink, Alicia and Wright, Richard A. and Franklin, Amber D.},
  year = {2007},
  month = jul,
  journal = {Journal of Phonetics},
  volume = {35},
  number = {3},
  pages = {363--379},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2006.07.002},
  abstract = {Examination of five acoustic parameters (F0, F1, F2, segmental duration, and intensity) allowed comparison of Infant-Directed Speech (IDS), Hyperspeech, and the Lombard reflex. These phenomena have typically been investigated separately, each characterized in terms of one or two acoustic features (e.g., intensity for Lombard speech). The present two-part experiment examined intraspeaker and interspeaker variability in speakers of Jamaican Creole and Jamaican English. IDS and Lombard speech showed similar adjustments in two parameters (F0 and intensity), and IDS and Citation speech showed the greatest spectral differences. This result is important because it shows that while one or two acoustic parameters may be crucial characteristics of a type of exaggerated speech, task production involved the systematic adjustment of a complex set of continuous acoustic parameters. Taken together, the acoustic outcomes for the types of perturbations investigated here allow the tasks to be arranged along a continuum. These adjustments resemble patterns associated with the manipulation of sociolinguistic markers reported in sociophonetic studies of ``style-shifting.'' We argue that the two phenomena may be treated under a unified account of intraspeaker variability that builds upon the sociolinguistic concept of Audience Design.},
  langid = {english}
}

@article{berinsteinWPPNo471979,
  title = {{{WPP}}, {{No}}. 47: {{A Cross-linguistic Study}} on the {{Perception}} and {{Production}} of {{Stress}}},
  shorttitle = {{{WPP}}, {{No}}. 47},
  author = {Berinstein, Ava E.},
  year = {1979},
  month = nov,
  abstract = {Author(s): Berinstein, Ava E.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/HJZI7EQP/Berinstein - 1979 - WPP, No. 47 A Cross-linguistic Study on the Perce.pdf;/Users/sarah/Zotero/storage/PR2PC8ZB/0t0699hc.html}
}

@article{bialystokUsingDRMParadigm2020,
  title = {Using the {{DRM Paradigm}} to {{Assess Language Processing}} in {{Monolinguals}} and {{Bilinguals}}},
  author = {Bialystok, Ellen and Dey, Avanti and Sullivan, Margot D. and Sommers, Mitchell S.},
  year = {2020},
  month = jan,
  journal = {Mem Cogn},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/s13421-020-01016-6},
  abstract = {Both languages are jointly activated in the bilingual brain, requiring bilinguals to select the target language while avoiding interference from the unwanted language. This cross-language interference is similar to the within-language interference created by the Deese\textendash{} Roediger\textendash{} McDermott false memory paradigm (DRM; Roediger \& McDermott, 1995, Journal of Experimental Psychology: Learning, Memory, and Cognition, 21[4], 803\textendash{} 814). Although the mechanisms mediating false memory in the DRM paradigm remain an area of investigation, two of the more prominent theories\textemdash{} implicit associative response (IAR) and fuzzy trace\textemdash{} provide frameworks for using the DRM paradigm to advance our understanding of bilingual language processing. Three studies are reported comparing accuracy of monolingual and bilingual participants on different versions of the DRM. Study 1 presented lists of phonological associates and found that bilinguals showed higher rates of false recognition than did monolinguals. Study 2 used the standard semantic variant of the task and found that bilinguals showed lower false recognition rates than did monolinguals. Study 3 replicated and extended the findings in Experiment 2 in another semantic version of the task presented to younger and older adult monolingual and bilingual participants. These results are discussed within the frameworks of IAR and fuzzy-trace theories as further explicating differences between monolingual and bilingual processing.},
  langid = {english}
}

@book{BidirectionalClearSpeech,
  title = {Bidirectional {{Clear Speech Perception Benefit}} for {{Native}} and {{High-Proficiency Non-Native Talkers}} and {{Listeners}}: {{Intelligibility}} and {{Accentedness}}: {{The Journal}} of the {{Acoustical Society}} of {{America}}: {{Vol}} 130, {{No}} 6}
}

@article{billingtonAcousticEvidenceRightEdge2020,
  title = {Acoustic {{Evidence}} for {{Right-Edge Prominence}} in {{Nafsan}}},
  author = {Billington, Rosey and Fletcher, Janet and Thieberger, Nick and Volchok, Ben},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {2829--2844},
  issn = {0001-4966},
  doi = {10.1121/10.0000995},
  langid = {english}
}

@article{blumenfeldGenerativeMetricsOverview2016,
  title = {Generative {{Metrics}}: {{An Overview}}: {{Metrics}}},
  shorttitle = {Generative {{Metrics}}},
  author = {Blumenfeld, Lev},
  year = {2016},
  month = sep,
  journal = {Language and Linguistics Compass},
  volume = {10},
  number = {9},
  pages = {413--430},
  issn = {1749818X},
  doi = {10.1111/lnc3.12204},
  abstract = {This overview article covers the field of metrics as a branch of linguistics, focusing on the generative tradition. A brief outline of the basic ideas of foundational papers by Halle \& Keyser and Kiparsky is followed by a discussion of three theoretical issues: the nature of representations; gradience and variation; and the interface of metrics with phonology. The last section covers theoretical approaches to typology.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/JKA9QCAH/Blumenfeld - 2016 - Generative Metrics An Overview Metrics.pdf}
}

@misc{boersnaPraatDoingPhonetics,
  title = {Praat: Doing {{Phonetics}} by {{Computer}}},
  author = {Boersna, Paul},
  howpublished = {https://www.fon.hum.uva.nl/praat/},
  file = {/Users/sarah/Zotero/storage/5PQQQ3H2/praat.html}
}

@book{bohnLanguageExperienceSecond2007,
  title = {Language {{Experience}} in {{Second Language Speech Learning}}: {{In Honor}} of {{James Emil Flege}}},
  shorttitle = {Language {{Experience}} in {{Second Language Speech Learning}}},
  author = {Bohn, Ocke-Schwen and Munro, Murray J.},
  year = {2007},
  month = jan,
  publisher = {{John Benjamins Publishing}},
  abstract = {This stimulating collection of articles from leading international researchers provides a state-of-the-art overview of core issues in second language speech perception and production. Aimed at phoneticians, speech scientists, psycholinguists, applied linguists, and pedagogical specialists, it presents engaging discussions of fundamental problems and controversies within the field, as well as new empirical findings arising from a variety of methodological approaches. Its twenty chapters, inspired by the ground-breaking work of James E. Flege, address such topics as the theoretical underpinnings of second language speech learning; the nature and etiology of foreign accents; the effects of age, experience, and training; speech intelligibility; and the acquisition of vowels, consonants, tone, and prosody. This volume will serve as a valuable resource, not only for researchers, but for anyone wishing to gain an understanding of an area of linguistics that is rapidly growing in importance.},
  isbn = {978-90-272-1973-2},
  langid = {english},
  keywords = {Language Arts \& Disciplines / Linguistics / General}
}

@article{bottalicoEffectMasksSpeech2020,
  title = {Effect of {{Masks}} on {{Speech Intelligibility}} in {{Auralized Classrooms}}},
  author = {Bottalico, Pasquale and Murgia, Silvia and Puglisi, Giuseppina Emma and Astolfi, Arianna and Kirk, Karen Iler},
  year = {2020},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {148},
  number = {5},
  pages = {2878--2884},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0002450},
  abstract = {This study explored the effects of wearing face masks on classroom communication. The effects of three different types of face masks (fabric, surgical, and N95 masks) on speech intelligibility (SI) presented to college students in auralized classrooms were evaluated. To simulate realistic classroom conditions, speech stimuli were presented in the presence of speech-shaped noise with a signal-to-noise ratio of +3\textbackslash,dB under two different reverberation times (0.4\textbackslash,s and 3.1\textbackslash,s). The use of fabric masks yielded a significantly greater reduction in SI compared to the other masks. Therefore, surgical masks or N95 masks are recommended in teaching environments.}
}

@article{brandtRacismResearchCase1978,
  title = {Racism and {{Research}}: {{The Case}} of the {{Tuskegee Syphilis Study}}},
  shorttitle = {Racism and {{Research}}},
  author = {Brandt, Allan M.},
  year = {1978},
  journal = {The Hastings Center Report},
  volume = {8},
  number = {6},
  pages = {21--29},
  publisher = {{[Hastings Center, Wiley]}},
  issn = {0093-0334},
  doi = {10.2307/3561468}
}

@article{braviManualTranscriptionInstrumental2016,
  title = {Manual {{Transcription}} and {{Instrumental Analysis}} of {{Singing}} through {{Praat}}},
  author = {Bravi, Paolo},
  year = {2016},
  volume = {4},
  pages = {22},
  abstract = {In the field of ethnomusicology, the main tool-of-the-trade for music analysis has been musical transcription on the score, despite its acknowledged cultural bias and the limits of staff notation as a means of representing music conceived and performed outside of the Western music culture. In the digital era, a number of analytical tools have been designed which may serve to solve some of the problems related to the use of the score as a method for describing and visualizing music. These tools allow analyses to be performed, which were virtually impossible for most ethnomusicologists until a few decades ago. Praat, the well known software developed by Paul Boersma and David Weenink and designed for phonetic studies, may also be helpful for the annotation and analysis of the singing voice. This paper deals with some aspects of the use of this program for musicological aims, focussing on the relation between acoustic data and subjective musical interpretations and their relevance in analytic and perceptual investigations.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/43EZWMJK/Bravi - 2016 - Manual Transcription and Instrumental Analysis of .pdf}
}

@article{brentUnifiedModelLexical1997,
  title = {Toward a {{Unified Model}} of {{Lexical Acquisition}} and {{Lexical Access}}},
  author = {Brent, Michael R.},
  year = {1997},
  month = may,
  journal = {Journal of Psycholinguistic Research},
  volume = {26},
  number = {3},
  pages = {363--375},
  issn = {1573-6555},
  doi = {10.1023/A:1025032825951},
  abstract = {Much effort has gone into constructing models of how children segment speech and thereby discover the words of their language. Much effort has also gone into constructing models of how adults access their mental lexicons and thereby segment speech into words. In this paper, I explore the possibility of a model that could account for both word discovery by children and on-line segmentation by adults. In particular, I discuss extensions to the distributional regularity (DR) model of Brent and Cartwright (1996) that could yield an account of on-line segmentation as well as word discovery.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/3H9B6QG3/2086-Article Text-7982-1-10-20170908.pdf;/Users/sarah/Zotero/storage/W455YU3C/Brent - 1997 - Toward a Unified Model of Lexical Acquisition and .pdf}
}

@techreport{bridgesTimingMegaStudyComparing2020,
  type = {Preprint},
  title = {The {{Timing Mega-Study}}: {{Comparing}} a {{Range}} of {{Experiment Generators}}, {{Both Lab-Based}} and {{Online}}},
  shorttitle = {The {{Timing Mega-Study}}},
  author = {Bridges, David and Pitiot, Alain and MacAskill, Michael R. and Peirce, Jonathan Westley},
  year = {2020},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/d6nu5},
  abstract = {Many researchers in the behavioral sciences depend on research software that presents stimuli, and records response times, with sub-millisecond precision. There are a large number of software packages with which to conduct these behavioural experiments and measure response times and performance of participants. Very little information is available, however, on what timing performance they achieve in practice. Here we report a wide-ranging study looking at the precision and accuracy of visual and auditory stimulus timing and response times, measured with a Black Box Toolkit. We compared a range of popular packages: PsychoPy, E-Prime\textregistered, NBS Presentation\textregistered, Psychophysics Toolbox, OpenSesame, Expyriment, Gorilla, jsPsych, Lab.js and Testable. Where possible, the packages were tested on Windows, MacOS, and Ubuntu, and in a range of browsers for the online studies, to try to identify common patterns in performance. Among the lab-based experiments, Psychtoolbox, PsychoPy, Presentation and E-Prime provided the best timing, all with mean precision under 1 millisecond across the visual, audio and response measures. OpenSesame had slightly less precision across the board, but most notably in audio stimuli and Expyriment had rather poor precision. Across operating systems, the pattern was that precision was generally very slightly better under Ubuntu than Windows, and that Mac OS was the worst, at least for visual stimuli, for all packages. Online studies did not deliver the same level of precision as lab-based systems, with slightly more variability in all measurements. That said, PsychoPy and Gorilla, broadly the best performers, were achieving very close to millisecond precision on a number of browser configurations. For response times (using a high-performance button box), most of the packages achieved precision at least under 10 ms in all browsers, with PsychoPy achieving a precision under 3.5 ms in all. There was considerable variability between operating systems and browsers, especially in audio-visual synchrony which is the least precise aspect of the browser-based experiments. Nonetheless, the data indicate that online methods can be suitable for a wide range of studies, with due thought about the sources of variability that result.The results, from over 110,000 trials, highlight the wide range of timing qualities that can occur even in these dedicated software packages for the task. We stress the importance of scientists making their own timing validation measurements for their own stimuli and computer configuration.}
}

@article{broselowSyllableWeightConvergence1997,
  title = {Syllable Weight: Convergence of Phonology and Phonetics},
  shorttitle = {Syllable Weight},
  author = {Broselow, E. and Chen, Su-I. and Huffman, M.},
  year = {1997},
  doi = {10.1017/S095267579700331X},
  abstract = {In some languages, syllable weight depends exclusively on vowel  length, while in others, coda consonants add weight to syllables. In this paper  we assume that syllable weight is reflected in moraic structure, and that weight-bearing coda consonants are the exclusive dependents of a mora, while weightless consonants share a mora with the preceding vowel. We consider whether the durations of vowels and coda consonants reflect the distinction between a segment which occupies its own mora and a segment that shares a mora. We examine three patterns of coda weight, reflected  in stress assignment: in Hindi, codas always contribute to syllable weight;  in Malayalam, coda consonants are always weightless; and in Levantine Arabic, coda weight is contextually determined, with word-internal codas contributing to syllable weight following a short vowel, but weightless following a long vowel. These phonological patterns translate into different moraic representations of CVC and CVVC syllables across the different languages. We examine the durations of vowels and coda consonants in CV, CVC, CVV and CVVC syllables in Hindi, Malayalam and Levantine Arabic, and find that in all three languages, segments that we represent as mora-sharing are significantly shorter than segments that we represent as occupying an independent mora. The striking differences in durational patterns across the three languages correlate with the different moraic representations proposed on the basis of phonological patterning.}
}

@article{brouwerInterplayEmotionModality2020,
  title = {The {{Interplay}} between {{Emotion}} and {{Modality}} in the {{Foreign-Language Effect}} on {{Moral Decision Making}}},
  author = {Brouwer, Susanne},
  year = {2020},
  month = may,
  journal = {Bilingualism},
  pages = {1--8},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S136672892000022X},
  abstract = {This study examined whether the FOREIGN-LANGUAGE EFFECT, an increase in bilinguals' rate of rational decisions to moral dilemmas in their foreign versus their native language, is influenced by emotion and the modality in which the dilemmas are presented. 154 Dutch\textendash{} English bilinguals were asked to read and listen to personal and impersonal moral dilemmas in Dutch or in English. Importantly, the reading task had the character of a self-paced reading task to resemble the listening task as closely as possible. In both modalities, participants' task was to indicate whether the proposed action was appropriate or not. Results showed that the Foreign-Language effect was present for personal dilemmas only. In addition, an effect of modality demonstrated that participants took overall more rational decisions during the listening than the reading task. These findings give insight in the interplay between language, emotion and task demands, revealing that moral decision making is context-dependent.},
  langid = {english}
}

@article{brownUniversalFeaturesPhonological2018,
  title = {Universal {{Features}} in {{Phonological Neighbor Networks}}},
  author = {Brown, Kevin S. and Allopenna, Paul D. and Hunt, William R. and Steiner, Rachael and Saltzman, Elliot and McRae, Ken and Magnuson, James S.},
  year = {2018},
  month = jul,
  journal = {Entropy},
  volume = {20},
  number = {7},
  pages = {526},
  doi = {10.3390/e20070526},
  abstract = {Human speech perception involves transforming a countinuous acoustic signal into discrete linguistically meaningful units (phonemes) while simultaneously causing a listener to activate words that are similar to the spoken utterance and to each other. The Neighborhood Activation Model posits that phonological neighbors (two forms [words] that differ by one phoneme) compete significantly for recognition as a spoken word is heard. This definition of phonological similarity can be extended to an entire corpus of forms to produce a phonological neighbor network (PNN). We study PNNs for five languages: English, Spanish, French, Dutch, and German. Consistent with previous work, we find that the PNNs share a consistent set of topological features. Using an approach that generates random lexicons with increasing levels of phonological realism, we show that even random forms with minimal relationship to any real language, combined with only the empirical distribution of language-specific phonological form lengths, are sufficient to produce the topological properties observed in the real language PNNs. The resulting pseudo-PNNs are insensitive to the level of lingustic realism in the random lexicons but quite sensitive to the shape of the form length distribution. We therefore conclude that ``universal'' features seen across multiple languages are really string universals, not language universals, and arise primarily due to limitations in the kinds of networks generated by the one-step neighbor definition. Taken together, our results indicate that caution is warranted when linking the dynamics of human spoken word recognition to the topological properties of PNNs, and that the investigation of alternative similarity metrics for phonological forms should be a priority.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {neighborhood activation model,networks,phonological neighbor network,phonology}
}

@article{brungartInformationalEnergeticMasking2001,
  title = {Informational and {{Energetic Masking Effects}} in the {{Perception}} of {{Multiple Simultaneous Talkers}}},
  author = {Brungart, Douglas S. and Simpson, Brian D. and Ericson, Mark A. and Scott, Kimberly R.},
  year = {2001},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {110},
  number = {5},
  pages = {2527--2538},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.1408946}
}

@article{brysbaertPowerAnalysisEffect2018,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  year = {2018},
  month = jan,
  journal = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  langid = {english}
}

@article{carpenterRhythmSpeechMusic2016,
  title = {Rhythm in the {{Speech}} and {{Music}} of {{Jazz}} and {{Riddim Musicians}}},
  author = {Carpenter, Angela C. and Levitt, Andrea G.},
  year = {2016},
  month = sep,
  journal = {Music Perception},
  volume = {34},
  number = {1},
  pages = {94--103},
  issn = {0730-7829, 1533-8312},
  doi = {10.1525/mp.2016.34.1.94},
  abstract = {Previous research has demonstrated similarities in the rhythmic characteristics of the speech and instrumental music within individual languages, such as French or English, but clear differences in these rhythmic patterns between languages. A recent finding has shown a comparable result for the rhythmic patterns of the spontaneous speech and instrumental music of musicians who speak different dialects of English, such that within-dialect speech and music rhythms are more similar to one another than are across-dialect rhythms. We extend the latter finding by comparing the rhythmic characteristics of the spontaneous speech and jazz productions of jazz musicians who speak American English with those of the spontaneous speech and riddim productions of Jamaican musicians, who speak Jamaican English. We found that the speech and music rhythmic patterns were similar within each dialect but different across dialects. Though scholars have suggested a link between speech prosody and jazz in the past, this is the first study known to us to demonstrate a link between the rhythmic properties of the speech and music of jazz musicians.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/XGSXNBJW/Carpenter and Levitt - 2016 - Rhythm in the Speech and Music of Jazz and Riddim .pdf}
}

@article{cascioSomatosensoryProcessingNeurodevelopmental2010,
  title = {Somatosensory Processing in Neurodevelopmental Disorders},
  author = {Cascio, Carissa J.},
  year = {2010},
  month = jun,
  journal = {Journal of Neurodevelopmental Disorders},
  volume = {2},
  number = {2},
  pages = {62--69},
  issn = {1866-1947, 1866-1955},
  doi = {10.1007/s11689-010-9046-3},
  abstract = {The purpose of this article is to review the role of somatosensory perception in typical development, its aberration in a range of neurodevelopmental disorders, and the potential relations between tactile processing abnormalities and central features of each disorder such as motor, communication, and social development. Neurodevelopmental disorders that represent a range of symptoms and etiologies, and for which multiple peer-reviewed articles on somatosensory differences have been published, were chosen to include in the review. Relevant studies in animal models, as well as conditions of early sensory deprivation, are also included. Somatosensory processing plays an important, yet often overlooked, role in typical development and is aberrant in various neurodevelopmental disorders. This is demonstrated in studies of behavior, sensory thresholds, neuroanatomy, and neurophysiology in samples of children with Fragile X syndrome, autism spectrum disorders (ASD), attention deficit hyperactivity disorder (ADHD), and cerebral palsy (CP). Impaired somatosensory processing is found in a range of neurodevelopmental disorders and is associated with deficits in communication, motor ability, and social skills in these disorders. Given the central role of touch in early development, both experimental and clinical approaches should take into consideration the role of somatosensory processing in the etiology and treatment of neurodevelopmental disorders.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/4XLK4V2X/Cascio - 2010 - Somatosensory processing in neurodevelopmental dis.pdf}
}

@article{chiICAPFrameworkLinking2014,
  title = {The {{ICAP Framework}}: {{Linking Cognitive Engagement}} to {{Active Learning Outcomes}}},
  shorttitle = {The {{ICAP Framework}}},
  author = {Chi, Michelene T. H. and Wylie, Ruth},
  year = {2014},
  month = oct,
  journal = {Educational Psychologist},
  volume = {49},
  number = {4},
  pages = {219--243},
  publisher = {{Routledge}},
  issn = {0046-1520},
  doi = {10.1080/00461520.2014.965823},
  abstract = {This article describes the ICAP framework that defines cognitive engagement activities on the basis of students' overt behaviors and proposes that engagement behaviors can be categorized and differentiated into one of four modes: Interactive, Constructive, Active, and Passive. The ICAP hypothesis predicts that as students become more engaged with the learning materials, from passive to active to constructive to interactive, their learning will increase. We suggest possible knowledge-change processes that support the ICAP hypothesis and address the limitations and caveats of the hypothesis. In addition, empirical validation for the hypothesis is provided by examining laboratory and classroom studies that focus on three specific engagement activities: note taking, concept mapping and self-explaining. We also consider how ICAP can be used as a tool for explaining discrepant findings, dictate the proper choice of a control condition, and evaluate students' outputs. Finally, we briefly compare ICAP to existing theories of learning.},
  annotation = {\_eprint: https://doi.org/10.1080/00461520.2014.965823},
  file = {/Users/sarah/Zotero/storage/CJCY7XM3/00461520.2014.html}
}

@article{choProsodicallyDrivenPhonetic2007,
  title = {Prosodically {{Driven Phonetic Detail}} in {{Speech Processing}}: {{The Case}} of {{Domain-Initial Strengthening}} in {{English}}},
  shorttitle = {Prosodically {{Driven Phonetic Detail}} in {{Speech Processing}}},
  author = {Cho, Taehong and McQueen, James M. and Cox, Ethan A.},
  year = {2007},
  month = apr,
  journal = {Journal of Phonetics},
  volume = {35},
  number = {2},
  pages = {210--243},
  issn = {00954470},
  doi = {10.1016/j.wocn.2006.03.003},
  abstract = {We explore the role of the acoustic consequences of domain-initial strengthening in spoken-word recognition. In two cross-modal identity-priming experiments, listeners heard sentences and made lexical decisions to visual targets, presented at the onset of the second word in two-word sequences containing lexical ambiguities (e.g., bus tickets, with the competitor bust). These sequences contained Intonational Phrase (IP) or Prosodic Word (Wd) boundaries, and the second word's initial Consonant and Vowel (CV, e.g., [tI]) was spliced from another token of the sequence in IP- or Wd-initial position. Acoustic analyses showed that IP-initial consonants were articulated more strongly than Wd-initial consonants. In Experiment 1, related targets were post-boundary words (e.g., tickets). No strengthening effect was observed (i.e., identity priming effects did not vary across splicing conditions). In Experiment 2, related targets were pre-boundary words (e.g., bus). There was a strengthening effect (stronger priming when the post-boundary CVs were spliced from IP-initial than from Wd-initial position), but only in Wd-boundary contexts. These were the conditions where phonetic detail associated with domain-initial strengthening could assist listeners most in lexical disambiguation. We discuss how speakers may strengthen domain-initial segments during production and how listeners may use the resulting acoustic correlates of prosodic strengthening during word recognition.},
  langid = {english}
}

@incollection{christiansenNoworNeverProcessingBottleneck2016,
  title = {The {{Now-or-Never Processing Bottleneck}}},
  booktitle = {Creating {{Language}}},
  author = {Christiansen, Morten H. and Chater, Nick},
  year = {2016},
  series = {Integrating {{Evolution}}, {{Acquisition}}, and {{Processing}}},
  pages = {93--134},
  publisher = {{Mit Press}},
  abstract = {Language happens in the here-and-now. Although, as we shall see, this provides one of the most important constraints on language, we rarely notice it during normal language use. Nonetheless, we have all felt the effects of this constraint at one point or another. This is perhaps most obvious when listening to someone speaking an unfamiliar language, which often forces us to reexperience some of the ``great blooming, buzzing confusion'' that William James (1890) so famously noted is his classic work on psychology. In many cases, it seems that the speaker of the foreign language is talking very fast, making it},
  isbn = {978-0-262-03431-9}
}

@article{chuPhysicalDistancingFace2020,
  title = {Physical {{Distancing}}, {{Face Masks}}, and {{Eye Protection}} to {{Prevent Person-to-Person Transmission}} of {{SARS-CoV-2}} and {{COVID-19}}: {{A Systematic Review}} and {{Meta-Analysis}}},
  shorttitle = {Physical {{Distancing}}, {{Face Masks}}, and {{Eye Protection}} to {{Prevent Person-to-Person Transmission}} of {{SARS-CoV-2}} and {{COVID-19}}},
  author = {Chu, Derek K and Akl, Elie A and Duda, Stephanie and Solo, Karla and Yaacoub, Sally and Sch{\"u}nemann, Holger J and Chu, Derek K and Akl, Elie A and {El-harakeh}, Amena and Bognanni, Antonio and Lotfi, Tamara and Loeb, Mark and Hajizadeh, Anisa and Bak, Anna and Izcovich, Ariel and {Cuello-Garcia}, Carlos A and Chen, Chen and Harris, David J and Borowiack, Ewa and Chamseddine, Fatimah and Sch{\"u}nemann, Finn and Morgano, Gian Paolo and Muti Sch{\"u}nemann, Giovanna E U and Chen, Guang and Zhao, Hong and Neumann, Ignacio and Chan, Jeffrey and Khabsa, Joanne and Hneiny, Layal and Harrison, Leila and Smith, Maureen and Rizk, Nesrine and Giorgi Rossi, Paolo and AbiHanna, Pierre and {El-khoury}, Rayane and Stalteri, Rosa and Baldeh, Tejan and Piggott, Thomas and Zhang, Yuan and Saad, Zahra and Khamis, Assem and Reinap, Marge and Duda, Stephanie and Solo, Karla and Yaacoub, Sally and Sch{\"u}nemann, Holger J},
  year = {2020},
  month = jun,
  journal = {The Lancet},
  volume = {395},
  number = {10242},
  pages = {1973--1987},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(20)31142-9},
  abstract = {Background Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes COVID-19 and is spread person-to-person through close contact. We aimed to investigate the effects of physical distance, face masks, and eye protection on virus transmission in health-care and non-health-care (eg, community) settings. Methods We did a systematic review and meta-analysis to investigate the optimum distance for avoiding person-to-person virus transmission and to assess the use of face masks and eye protection to prevent transmission of viruses. We obtained data for SARS-CoV-2 and the betacoronaviruses that cause severe acute respiratory syndrome, and Middle East respiratory syndrome from 21 standard WHO-specific and COVID-19-specific sources. We searched these data sources from database inception to May 3, 2020, with no restriction by language, for comparative studies and for contextual factors of acceptability, feasibility, resource use, and equity. We screened records, extracted data, and assessed risk of bias in duplicate. We did frequentist and Bayesian meta-analyses and random-effects meta-regressions. We rated the certainty of evidence according to Cochrane methods and the GRADE approach. This study is registered with PROSPERO, CRD42020177047. Findings Our search identified 172 observational studies across 16 countries and six continents, with no randomised controlled trials and 44 relevant comparative studies in health-care and non-health-care settings (n=25\textbackslash hphantom,697 patients). Transmission of viruses was lower with physical distancing of 1 m or more, compared with a distance of less than 1 m (n=10\textbackslash hphantom,736, pooled adjusted odds ratio [aOR] 0\$\textbackslash cdot\$18, 95\% CI 0\$\textbackslash cdot\$09 to 0\$\textbackslash cdot\$38; risk difference [RD] -10\$\textbackslash cdot\$2\%, 95\% CI -11\$\textbackslash cdot\$5 to -7\$\textbackslash cdot\$5; moderate certainty); protection was increased as distance was lengthened (change in relative risk [RR] 2\$\textbackslash cdot\$02 per m; pinteraction=0\$\textbackslash cdot\$041; moderate certainty). Face mask use could result in a large reduction in risk of infection (n=2647; aOR 0\$\textbackslash cdot\$15, 95\% CI 0\$\textbackslash cdot\$07 to 0\$\textbackslash cdot\$34, RD -14\$\textbackslash cdot\$3\%, -15\$\textbackslash cdot\$9 to -10\$\textbackslash cdot\$7; low certainty), with stronger associations with N95 or similar respirators compared with disposable surgical masks or similar (eg, reusable 12\textendash{} 16-layer cotton masks; pinteraction=0\$\textbackslash cdot\$090; posterior probability \${$>\$$}95\%, low certainty). Eye protection also was associated with less infection (n=3713; aOR 0\$\textbackslash cdot\$22, 95\% CI 0\$\textbackslash cdot\$12 to 0\$\textbackslash cdot\$39, RD -10\$\textbackslash cdot\$6\%, 95\% CI -12\$\textbackslash cdot\$5 to -7\$\textbackslash cdot\$7; low certainty). Unadjusted studies and subgroup and sensitivity analyses showed similar findings. Interpretation The findings of this systematic review and meta-analysis support physical distancing of 1 m or more and provide quantitative estimates for models and contact tracing to inform policy. Optimum use of face masks, respirators, and eye protection in public and health-care settings should be informed by these findings and contextual factors. Robust randomised trials are needed to better inform the evidence for these interventions, but this systematic appraisal of currently best available evidence might inform interim guidance. Funding World Health Organization.},
  langid = {english}
}

@article{CodaMirrorV22010,
  title = {The {{Coda Mirror V2}}},
  year = {2010},
  journal = {Acta Linguistica Hungarica (Since 2017 Acta Linguistica Academica)},
  volume = {57},
  number = {4},
  pages = {411--431},
  issn = {1216-8076, 1588-2624},
  langid = {english}
}

@article{coetzeeFrequencyBiasesPhonological2013,
  title = {Frequency {{Biases}} in {{Phonological Variation}}},
  author = {Coetzee, Andries W. and Kawahara, Shigeto},
  year = {2013},
  journal = {Natural Language \& Linguistic Theory},
  volume = {31},
  number = {1},
  pages = {47--89},
  issn = {0167-806X},
  abstract = {In the past two decades, variation has received a lot of attention in mainstream generative phonology, and several different models have been developed to account for variable phonological phenomena. However, all existing generative models of phonological variation account for the overall rate at which some process applies in a corpus, and therefore implicitly assume that all words are affected equally by a variable process. In this paper, we show that this is not the case. Many variable phenomena are more likely to apply to frequent than to infrequent words. A model that accounts perfectly for the overall rate of application of some variable process therefore does not necessarily account very well for the actual application of the process to individual words. We illustrate this with two examples, English t/d-deletion and Japanese geminate devoicing. We then augment one existing generative model (noisy Harmonic Grammar) to incorporate the contribution of usage frequency to the application of variable processes. In this model, the influence of frequency is incorporated by scaling the weights of faithfulness constraints up or down for words of different frequencies. This augmented model accounts significantly better for variation than existing generative models.}
}

@article{cohnIntelligibilityFaceMaskedSpeech2021,
  title = {Intelligibility of {{Face-Masked Speech Depends}} on {{Speaking Style}}: {{Comparing Casual}}, {{Clear}}, and {{Emotional Speech}}},
  shorttitle = {Intelligibility of {{Face-Masked Speech Depends}} on {{Speaking Style}}},
  author = {Cohn, Michelle and Pycha, Anne and Zellou, Georgia},
  year = {2021},
  month = may,
  journal = {Cognition},
  volume = {210},
  pages = {104570},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2020.104570},
  abstract = {This study investigates the impact of wearing a fabric face mask on speech comprehension, an underexplored topic that can inform theories of speech production. Speakers produced sentences in three speech styles (casual, clear, positive-emotional) while in both face-masked and non-face-masked conditions. Listeners were most accurate at word identification in multi-talker babble for sentences produced in clear speech, and less accurate for casual speech (with emotional speech accuracy numerically in between). In the clear speaking style, face-masked speech was actually more intelligible than non-face-masked speech, suggesting that speakers make clarity adjustments specifically for face masks. In contrast, in the emotional condition, face-masked speech was less intelligible than non-face-masked speech, and in the casual condition, no difference was observed, suggesting that `emotional' and `casual' speech are not styles produced with the explicit intent to be intelligible to listeners. These findings are discussed in terms of automatic and targeted speech adaptation accounts.},
  langid = {english},
  keywords = {Face-masked speech,Models of speech production,Speech-in-noise word comprehension}
}

@book{ConversationalClearSpeech,
  title = {Conversational and {{Clear Speech Intelligibility}} of /{{bVd}}/ {{Syllables Produced}} by {{Native}} and {{Non-Native English Speakers}}: {{The Journal}} of the {{Acoustical Society}} of {{America}}: {{Vol}} 128, {{No}} 1}
}

@article{coppockDefinitenessDeterminacy2015,
  title = {Definiteness and {{Determinacy}}},
  author = {Coppock, Elizabeth and Beaver, David},
  year = {2015},
  month = oct,
  journal = {Linguist and Philos},
  volume = {38},
  number = {5},
  pages = {377--435},
  issn = {0165-0157, 1573-0549},
  doi = {10.1007/s10988-015-9178-8},
  abstract = {This paper distinguishes between definiteness and determinacy. Definiteness is seen as a morphological category which, in English, marks a (weak) uniqueness presupposition, while determinacy consists in denoting an individual. Definite descriptions are argued to be fundamentally predicative, presupposing uniqueness but not existence, and to acquire existential import through general type-shifting operations that apply not only to definites, but also indefinites and possessives. Through these shifts, argumental definite descriptions may become either determinate (and thus denote an individual) or indeterminate (functioning as an existential quantifier). The latter option is observed in examples like `Anna didn't give the only invited talk at the conference', which, on its indeterminate reading, implies that there is nothing in the extension of `only invited talk at the conference'. The paper also offers a resolution of the issue of whether possessives are inherently indefinite or definite, suggesting that, like indefinites, they do not mark definiteness lexically, but like definites, they typically yield determinate readings due to a general preference for the shifting operation that produces them.},
  langid = {english}
}

@article{coppockDefinitenessDeterminacy2015a,
  title = {Definiteness and {{Determinacy}}},
  author = {Coppock, Elizabeth and Beaver, David},
  year = {2015},
  month = oct,
  journal = {Linguist and Philos},
  volume = {38},
  number = {5},
  pages = {377--435},
  issn = {0165-0157, 1573-0549},
  doi = {10.1007/s10988-015-9178-8},
  abstract = {This paper distinguishes between definiteness and determinacy. Definiteness is seen as a morphological category which, in English, marks a (weak) uniqueness presupposition, while determinacy consists in denoting an individual. Definite descriptions are argued to be fundamentally predicative, presupposing uniqueness but not existence, and to acquire existential import through general type-shifting operations that apply not only to definites, but also indefinites and possessives. Through these shifts, argumental definite descriptions may become either determinate (and thus denote an individual) or indeterminate (functioning as an existential quantifier). The latter option is observed in examples like `Anna didn't give the only invited talk at the conference', which, on its indeterminate reading, implies that there is nothing in the extension of `only invited talk at the conference'. The paper also offers a resolution of the issue of whether possessives are inherently indefinite or definite, suggesting that, like indefinites, they do not mark definiteness lexically, but like definites, they typically yield determinate readings due to a general preference for the shifting operation that produces them.},
  langid = {english}
}

@article{coreyAcousticEffectsMedical2020,
  title = {Acoustic {{Effects}} of {{Medical}}, {{Cloth}}, and {{Transparent Face Masks}} on {{Speech Signals}}},
  author = {Corey, Ryan M. and Jones, Uriah and Singer, Andrew C.},
  year = {2020},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {148},
  number = {4},
  pages = {2371--2375},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0002279},
  abstract = {Face masks muffle speech and make communication more difficult, especially for people with hearing loss. This study examines the acoustic attenuation caused by different face masks, including medical, cloth, and transparent masks, using a head-shaped loudspeaker and a live human talker. The results suggest that all masks attenuate frequencies above 1\textbackslash,kHz, that attenuation is greatest in front of the talker, and that there is substantial variation between mask types, especially cloth masks with different materials and weaves. Transparent masks have poor acoustic performance compared to both medical and cloth masks. Most masks have little effect on lapel microphones, suggesting that existing sound reinforcement and assistive listening systems may be effective for verbal communication with masks.}
}

@article{coreyAcousticEffectsMedical2020a,
  title = {Acoustic {{Effects}} of {{Medical}}, {{Cloth}}, and {{Transparent Face Masks}} on {{Speech Signals}}},
  author = {Corey, Ryan M. and Jones, Uriah and Singer, Andrew C.},
  year = {2020},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {148},
  number = {4},
  pages = {2371--2375},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0002279},
  abstract = {Face masks muffle speech and make communication more difficult, especially for people with hearing loss. This study examines the acoustic attenuation caused by different face masks, including medical, cloth, and transparent masks, using a head-shaped loudspeaker and a live human talker. The results suggest that all masks attenuate frequencies above 1\textbackslash,kHz, that attenuation is greatest in front of the talker, and that there is substantial variation between mask types, especially cloth masks with different materials and weaves. Transparent masks have poor acoustic performance compared to both medical and cloth masks. Most masks have little effect on lapel microphones, suggesting that existing sound reinforcement and assistive listening systems may be effective for verbal communication with masks.}
}

@book{courtoisTreatingComplexTraumatic2009,
  title = {Treating Complex Traumatic Stress Disorders: {{An}} Evidence-Based Guide},
  shorttitle = {Treating Complex Traumatic Stress Disorders},
  author = {Courtois, Christine A. and Ford, Julian D.},
  year = {2009},
  series = {Treating Complex Traumatic Stress Disorders: {{An}} Evidence-Based Guide},
  pages = {xxi, 468},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  abstract = {Chronic childhood trauma, such as prolonged abuse or family violence, can severely disrupt a person's development, basic sense of self, attachment security, and later relationships. Adults with this type of history often come to therapy with complex symptoms that go beyond existing criteria for posttraumatic stress disorder (PTSD). This book assembles expert clinicians to present the latest thinking on complex traumatic stress disorders along with practical guidelines for conceptualization and treatment. Richly illustrated with clinical material, the book offers a wide selection of tools and approaches specifically tailored to the needs of this population. Part I reviews the major features of complex traumatic stress disorders, contrasts them to other posttraumatic reactions, and identifies the core components of effective treatment. Evidence-based assessment instruments and procedures are detailed. While the book focuses primarily on treating adult survivors, best-practice recommendations for working with children are also provided. Other crucial topics include ways to build a trusting therapeutic relationship and strategies for therapist self-care. Parts II and III present an array of specialized treatment models for individuals, couples, families, and groups. Featuring extensive session transcripts, each chapter describes the theoretical and empirical underpinnings of the therapy at hand and demonstrates the "whats," "whys," and "how-tos" of intervention. A range of different psychotherapies, as well as psychopharmacology, are discussed. The concluding chapter distills essential lessons learned and highlights key unanswered questions for clinical research. Grounded in the best available knowledge, this tightly edited volume belongs on the desks of clinicians and researchers in clinical psychology, psychiatry, social work, nursing, counseling, and couple and family therapy. Clinical graduate students will find it a uniquely informative text for courses on trauma and PTSD. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  isbn = {978-1-60623-039-8},
  keywords = {Child Abuse,Chronic Stress,Domestic Violence,Early Experience,Emotional Trauma,Evidence Based Practice,Posttraumatic Stress Disorder,Treatment},
  file = {/Users/sarah/Zotero/storage/48C5H68E/2009-04501-000.html}
}

@article{dahanSubcategoricalMismatchesTime2001,
  title = {Subcategorical Mismatches and the Time Course of Lexical Access: {{Evidence}} for Lexical Competition},
  shorttitle = {Subcategorical Mismatches and the Time Course of Lexical Access},
  author = {Dahan, Delphine and Magnuson, James S. and Tanenhaus, Michael K. and Hogan, Ellen M.},
  year = {2001},
  month = oct,
  journal = {Language and Cognitive Processes},
  volume = {16},
  number = {5-6},
  pages = {507--534},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690960143000074},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/WYRFX69P/Dahan et al. - 2001 - Subcategorical mismatches and the time course of l.pdf}
}

@article{dahanSubcategoricalMismatchesTime2001a,
  title = {Subcategorical Mismatches and the Time Course of Lexical Access: {{Evidence}} for Lexical Competition},
  shorttitle = {Subcategorical Mismatches and the Time Course of Lexical Access},
  author = {Dahan, Delphine and Magnuson, James S. and Tanenhaus, Michael K. and Hogan, Ellen M.},
  year = {2001},
  month = oct,
  journal = {Language and Cognitive Processes},
  volume = {16},
  number = {5-6},
  pages = {507--534},
  publisher = {{Routledge}},
  issn = {0169-0965},
  doi = {10.1080/01690960143000074},
  abstract = {Participants' eye movements were monitored as they followed spoken instructions to click on a pictured object with a computer mouse (e.g., ''click on the net''). Participants were slower to fixate the target picture when the onset of the target word came from a competitor word (e.g., ne(ck)t) than from a nonword (e.g., ne(p)t), as predicted by models of spoken-word recognition that incorporate lexical competition. This was found whether the picture of the competitor word (e.g., the picture of a neck) was present on the display or not. Simulations with the TRACE model captured the major trends of fixations to the target and its competitor over time. We argue that eye movements provide a fine-grained measure of lexical activation over time, and thus reveal effects of lexical competition that are masked by response measures such as lexical decisions.},
  annotation = {\_eprint: https://doi.org/10.1080/01690960143000074},
  file = {/Users/sarah/Zotero/storage/BZM3RJEK/01690960143000074.html}
}

@article{dallastonQuantitativePrevalenceCreaky2020,
  title = {The {{Quantitative Prevalence}} of {{Creaky Voice}} ({{Vocal Fry}}) in {{Varieties}} of {{English}}: {{A Systematic Review}} of the {{Literature}}},
  shorttitle = {The {{Quantitative Prevalence}} of {{Creaky Voice}} ({{Vocal Fry}}) in {{Varieties}} of {{English}}},
  author = {Dallaston, Katherine and Docherty, Gerard},
  year = {2020},
  month = mar,
  journal = {PLoS One},
  volume = {15},
  number = {3},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0229960},
  abstract = {Background/aim It is widely believed that `creaky voice' (`creak', `vocal fry', `glottal fry') is increasingly prevalent among some English speakers, particularly among young American women. Motivated by the widespread and cross-disciplinary interest in the phenomenon, this paper offers a systematic review of peer-reviewed research (up to January 2019) on the prevalence of creaky voice in varieties of English. The review aimed to understand whose and what speech has been studied, how creaky voice prevalence has been measured, and what the findings collectively reveal. Method Literature was located by searching four electronic databases (ProQuest, PubMed, SCOPUS, Web of Science) and the proceedings of two recurrent conferences (`ICPhS' and `SST'). Studies were included if they reported the prevalence of creaky voice in naturalistic samples of English spoken by vocally-healthy speakers. Reference lists of included studies were cross-checked. Results Only ten studies meeting inclusion criteria were identified. All studies sampled a small number of speakers and/or short durations of speech. Nine were recent studies of American-English speakers, and many of these sampled young, female, college students. Across the ten studies, creaky voice was detected using three types of methods, and prevalence was calculated using five different formulae. The findings show that prevalence varies across groups, individuals, and contexts. However, the precise nature of this variability remains unclear due to the scarcity and methodological heterogeneity of the research. Conclusions This paper illustrated the application of systematic literature review methods in sociophonetic research\textemdash{} a field in which such methods are not common. The review found that creaky voice prevalence in English is not well understood, and that widespread claims of its recent increase among young American women have not been empirically confirmed. A number of specific limitations in the existing research are highlighted, which may serve as a guide for future research design.},
  pmcid = {PMC7065773},
  pmid = {32160255}
}

@article{danlySpeechProsodyBroca1982,
  title = {Speech {{Prosody}} in {{Broca}}'s {{Aphasia}}},
  author = {Danly, Martha and Shapiro, Barbara},
  year = {1982},
  month = jul,
  journal = {Brain and Language},
  volume = {16},
  number = {2},
  pages = {171--190},
  issn = {0093934X},
  doi = {10.1016/0093-934X(82)90082-7},
  langid = {english}
}

@article{dedomenicoMathematicalFormulationMultilayer2013,
  title = {Mathematical {{Formulation}} of {{Multilayer Networks}}},
  author = {De Domenico, Manlio and {Sol{\'e}-Ribalta}, Albert and Cozzo, Emanuele and Kivel{\"a}, Mikko and Moreno, Yamir and Porter, Mason A. and G{\'o}mez, Sergio and Arenas, Alex},
  year = {2013},
  month = dec,
  journal = {Phys. Rev. X},
  volume = {3},
  number = {4},
  pages = {041022},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.3.041022},
  langid = {english}
}

@article{deeseInfluenceInterItemAssociative1959,
  title = {Influence of {{Inter-Item Associative Strength}} upon {{Immediate Free Recall}}},
  author = {Deese, James},
  year = {1959},
  month = dec,
  journal = {Psychol Rep},
  volume = {5},
  number = {3},
  pages = {305--312},
  issn = {0033-2941},
  doi = {10.2466/pr0.1959.5.3.305},
  langid = {english}
}

@article{deesePredictionOccurrenceParticular1959,
  title = {On the {{Prediction}} of {{Occurrence}} of {{Particular Verbal Intrusions}} in {{Immediate Recall}}},
  author = {Deese, James},
  year = {1959},
  month = jul,
  journal = {Journal of Experimental Psychology},
  volume = {58},
  number = {1},
  pages = {17--22},
  issn = {0022-1015},
  doi = {10.1037/h0046671},
  abstract = {'Lists consisting of 12 words each were presented to 50 Ss for a test of immediate recall. In the recall of these lists, particular words occurred as intrusions which varied in frequency from 0\% for one list to 44\% for another. Data gathered on word-association frequencies clearly showed that the probability of a particular word occurring in recall as an intrusion was determined by the average frequency with which that word occurs as an association to words on the list.' (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {immediate recall,Memory,Recall (Learning),Short-Term,Verbal Ability,verbal intrusions,words,Words (Phonetic Units)}
}

@article{dejongStressLexicalFocus2004,
  title = {Stress, {{Lexical Focus}}, and {{Segmental Focus}} in {{English}}: {{Patterns}} of {{Variation}} in {{Vowel Duration}}},
  shorttitle = {Stress, {{Lexical Focus}}, and {{Segmental Focus}} in {{English}}},
  author = {{de Jong}, Kenneth},
  year = {2004},
  month = oct,
  journal = {Journal of Phonetics},
  volume = {32},
  number = {4},
  pages = {493--516},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2004.05.002},
  abstract = {This paper reports a study of the effects of stress and two types of focus on vowel duration and quality in English. Our previous work on Arabic has found that while such factors as phonemic quantity and the voicing of a following consonant affect vowel duration, such effects differ from one another concerning how they interact with stress and focus. Quantity effects are larger with stress and focus, while voicing effects remain about the same across stress and focus conditions. These results suggest that vowel duration differences due to vowel quantity indicate a linguistic contrast, but vowel duration differences due to consonant voicing do not. The current paper tests this interpretation by extending the previous studies of Arabic to a similar corpus in English. This paper finds durational differences between vowel categories and between vowels preceding voiced and voiceless stops. As in Arabic, stress increases differences due to vowel category. Unlike in Arabic, however, stress also increases vowel duration differences due to voicing of the following consonant. Focus effects are mediated by stress such that increases in durational differences are localized largely in syllables which are primary stressed and accented. Results show that both stress and focus can be used to distinguish contrastive from noncontrastive aspects of speech behavior.},
  langid = {english},
  keywords = {Focus,Quantity,Stress,Voicing,Vowel duration}
}

@article{dejongSupraglottalArticulationProminence1995,
  title = {The {{Supraglottal Articulation}} of {{Prominence}} in {{English}}: {{Linguistic Stress}} as {{Localized Hyperarticulation}}},
  shorttitle = {The {{Supraglottal Articulation}} of {{Prominence}} in {{English}}},
  author = {{de Jong}, Kenneth J.},
  year = {1995},
  month = jan,
  journal = {The Journal of the Acoustical Society of America},
  volume = {97},
  number = {1},
  pages = {491--504},
  issn = {0001-4966},
  doi = {10.1121/1.412275},
  langid = {english}
}

@article{derwingPauseBreakTaskEliciting1992,
  title = {A '{{Pause-Break}}' {{Task}} for {{Eliciting Syllable Boundary Judgments}} from {{Literate}} and {{Illiterate Speakers}}: {{Preliminary Results}} for {{Five Diverse Languages}}},
  shorttitle = {A '{{Pause-Break}}' {{Task}} for {{Eliciting Syllable Boundary Judgments}} from {{Literate}} and {{Illiterate Speakers}}},
  author = {Derwing, Bruce L.},
  year = {1992},
  month = jan,
  journal = {Language and Speech; London},
  volume = {35},
  number = {1},
  pages = {219--235},
  publisher = {{Kingston Press Services}},
  address = {{London, United Kingdom, London}},
  issn = {0023-8309},
  langid = {english},
  keywords = {Linguistics/Philology}
}

@article{dewallBelongingnessCorePersonality2011,
  title = {Belongingness as a {{Core Personality Trait}}: {{How Social Exclusion Influences Social Functioning}} and {{Personality Expression}}},
  shorttitle = {Belongingness as a {{Core Personality Trait}}},
  author = {DeWall, C. Nathan and Deckman, Timothy and Pond Jr., Richard S. and Bonser, Ian},
  year = {2011},
  journal = {Journal of Personality},
  volume = {79},
  number = {6},
  pages = {1281--1314},
  issn = {1467-6494},
  doi = {10.1111/j.1467-6494.2010.00695.x},
  abstract = {People have a fundamental need for positive and lasting relationships. This need to belong is rooted in evolutionary history and gave rise to the development of traits that enable individuals to gain acceptance and to avoid rejection. Because belongingness is a core component of human functioning, social exclusion should influence many cognitive, emotional, and behavioral outcomes and personality expression. This article summarizes recent evidence that social exclusion causes an assortment of outcomes, many of which depend on whether the excluded can gain acceptance or forestall possible distress. It highlights common overlap in physical and social pain systems and how a physical painkiller can reduce the pain of social exclusion. Finally, it shows how social exclusion moderates the effects of traits on cognition, emotion, and behavior. To appreciate personality processes in social contexts, scientists should consider how people respond to social exclusion and how the need to belong influences personality expression.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-6494.2010.00695.x},
  file = {/Users/sarah/Zotero/storage/SVBPP97T/DeWall et al. - 2011 - Belongingness as a Core Personality Trait How Soc.pdf;/Users/sarah/Zotero/storage/JIYD9JDA/j.1467-6494.2010.00695.html}
}

@article{driverEnhancementSelectiveListening1996,
  title = {Enhancement of {{Selective Listening}} by {{Illusory Mislocation}} of {{Speech Sounds Due}} to {{Lip-Reading}}},
  author = {Driver, Jon},
  year = {1996},
  month = may,
  journal = {Nature},
  volume = {381},
  number = {6577},
  pages = {66--68},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/381066a0},
  abstract = {MECHANISMS of human attention allow selective processing of just the relevant events among the many stimuli bombarding our senses1. Most laboratory studies examine attention within just a single sense, but in the real world many important events are specified multimodally, as in verbal communication. Speech comprises visual lip movements as well as sounds, and lip-reading contributes to speech perception, even for listeners with good hearing, by a process of audiovisual integration2. Such examples raise the problem of how we coordinate our spatial attention across the sensory modalities, to select sights and sounds from a common source for further processing. Here we show that this problem is alleviated by allowing some cross-modal matching before attentional selection is completed. Cross-modal matching can lead to an illusion, whereby sounds are mislocated at their apparent visual source3; this crossmodal illusion can enhance selective spatial attention to speech sounds.},
  copyright = {1996 Nature Publishing Group},
  langid = {english}
}

@book{DYNAMOHome,
  title = {{{DYNAMO}} | {{Home}}}
}

@misc{EchoesEchoesEpisodic,
  title = {Echoes of Echoes? {{An}} Episodic Theory of Lexical Access. - {{PsycNET}}},
  shorttitle = {Echoes of Echoes?},
  abstract = {APA PsycNet DoiLanding page},
  howpublished = {/doiLanding?doi=10.1037\%2F0033-295X.105.2.251},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/J56JERIC/doiLanding.html}
}

@article{eekSimplePerceptionExperiments,
  title = {Simple {{Perception Experiments}} on {{Estonian Word Prosody}}: {{Foot Structure}} vs. {{Segmental Quantity}}},
  author = {Eek, Arvo and Meister, Einar},
  pages = {34},
  abstract = {The following paper comprises three main parts. In the initial part we present a concise review of the data concerning Estonian word prosody. The data found in the literature raise new questions. In the second part some of these questions are tested by perception experiments. We succeeded in showing the existence of only two (short vs. long), not three phonological quantity degrees on segmental and syllabic levels. All three accents (traditionally called syllabic quantity degrees) can be identified only when information about the second syllable vowel has been delivered to listeners. The smallest prosodic unit in Estonian does not coincide with the syllable. Disyllabic accent feet are minimal distinctive prosodic units in Estonian. The main region of the stress foot, essential for the perception of accent types, consists of the stressed syllable rhyme (minimally its final part, i.e. the final half of the long nucleus or the coda peak) and of the nucleus of the following unstressed syllable. The concentration of the perceptually relevant informtition around the syllable boundary creates a perceptual impression that the long heavy accent (A3) has always a certain kind of peakedness whereas the long light accent (A2) has not. Besides segmental durations, listeners need additional information for the identification of accents embedded in a wider context than is delivered by the stressed syllable alone. All A3 feet are either vowel-peaked or consonant-peaked, other possibilities are lacking. In an unbalanced A3 disyllabic foot the perceptual effect of peakedness is strengthened against the background of the weakened, shortened, and qualitatively reduced second syllable vowel. The balance of A2 becomes conspicuous against the background of the lengthened and unreduced second syllable vowel. Accents, as the minimal distinctive prosodic units, ar closely connected with the stress pattern of a word. The domain of accents is a stress foot, irrespective of whether the foot is primarily or secondarily stressed. In the stress foot there operate two temporal regulation mechanisms. The higher-level temporal regulation, determined by the stress for the whole stress foot (up to trisyllabic feet), is expressed in an isochronic trend according to which addition of phonemes to the stress foot decreases the durations of the constituent segments in the foot, but does not affect accents. The lower-level temporal regulation mechanism, subordinated to the whole stress foot, characterizes isochrony of the accent foot. A stress-conditioned trend to isochrony influences absolute durations of the intrasyllabic constituents, whereas an accent-conditioned temporal regulation (e.g. inversely propor tional duration relations) expresses intersyllabic accent-characteristic temporal reorgani zation of the constituents in isochronous accent feet. In the final part of the paper we present the main principles of a conceptual framework for the description of Estonian word prosody.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/H7UUJQHH/Eek and Meister - Simple Perception Experiments on Estonian Word Pro.pdf}
}

@book{EffectMasksSpeech,
  title = {Effect of {{Masks}} on {{Speech Intelligibility}} in {{Auralized Classrooms}}: {{The Journal}} of the {{Acoustical Society}} of {{America}}: {{Vol}} 148, {{No}} 5}
}

@book{EffectsSpeechClarity,
  title = {Effects of {{Speech Clarity}} on {{Recognition Memory}} for {{Spoken Sentences}}}
}

@misc{EffectTraumaBrain2016,
  type = {Text},
  title = {The Effect of Trauma on the Brain Development of Children},
  year = {2016},
  month = jun,
  journal = {Child Family Community Australia},
  abstract = {An overview of cognitive development in children who have experienced trauma, and principles to support effective practice responses},
  howpublished = {https://aifs.gov.au/cfca/publications/effect-trauma-brain-development-children},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/IVFMNKW4/effect-trauma-brain-development-children.html}
}

@article{eijklotteEffectsWordFrequency,
  title = {The {{Effects}} of {{Word Frequency}} and {{Word Probability}} on {{Speech Rhythm}} in {{Dysarthria}}},
  author = {{Eijk Lotte} and {Fletcher Annalise} and {McAuliffe Megan} and {Janse Esther}},
  journal = {Journal of Speech, Language, and Hearing Research},
  publisher = {{American Speech-Language-Hearing Association}},
  doi = {10.1044/2020_JSLHR-19-00389},
  abstract = {Purpose In healthy speakers, the more frequent and probable a word is in its context, the shorter the word tends to be. This study investigated whether these probabilistic effects were similarly sized for speakers with dysarthria of different severities. Method Fifty-six speakers of New Zealand English (42 speakers with dysarthria and 14 healthy speakers) were recorded reading the Grandfather Passage. Measurements of word duration, frequency, and transitional word probability were taken. Results As hypothesized, words with a higher frequency and probability tended to be shorter in duration. There was also a significant interaction between word frequency and speech severity. This indicated that the more severe the dysarthria, the smaller the effects of word frequency on speakers' word durations. Transitional word probability also interacted with speech severity, but did not account for significant unique variance in the full model. Conclusions These results suggest that, as the severity of dysarthria increases, the duration of words is less affected by probabilistic variables. These findings may be due to reductions in the control and execution of muscle movement exhibited by speakers with dysarthria.}
}

@article{espinalIntonationalEncodingDouble2011,
  title = {Intonational {{Encoding}} of {{Double Negation}} in {{Catalan}}},
  author = {Espinal, M. Teresa and Prieto, Pilar},
  year = {2011},
  month = jul,
  journal = {Journal of Pragmatics},
  series = {Silence as a {{Pragmatic Phenomenon}}},
  volume = {43},
  number = {9},
  pages = {2392--2410},
  issn = {0378-2166},
  doi = {10.1016/j.pragma.2011.03.002},
  abstract = {In this paper we shall explore the phenomenon of double negation (DN) in a negative concord language like Catalan from an inferential perspective. According to recent developments within the generative approach to the theory of sentential grammar, a proper account of this phenomenon requires an analysis of the lexical, syntactic, and semantic conditions involved. Yet this model only attempts to account for the phenomenon of DN if two negative operators or two strong negative quantifiers are involved within a syntactic structure. In order to investigate the syntactic and prosodic conditions that affect DN interpretation in a question\textendash{} answer (Q\textendash{} A) dialogue in Catalan, we conducted a set of perception experiments with Central Catalan listeners. Our study supports the hypothesis that different formal conditions in the Q and A utterances (specifically, a command negative wh- Q combined with a contradictory intonational contour in the A) affect the corresponding interpretation, and that intonation encodes procedural restrictions on the proposition expressed. Results from these perception experiments confirm that the intonation contour of the negative word ning\'u `nobody' is the key factor triggering a DN interpretation. This paper aims to contribute to our current knowledge of the prosody\textendash{} meaning interface in the interpretation of negative constructions within recent work on the intonational phonology of Catalan and Relevance Theory.},
  langid = {english},
  keywords = {Catalan,Double negation,Intonation,Procedural meaning}
}

@article{estonianliterarymuseumRegilaulPoliticalWhirlpool2017,
  title = {Regilaul in the {{Political Whirlpool}}: {{On Collecting Regilaul}} in {{Northeast Estonia}} in the {{Second Half}} of the 1950s},
  shorttitle = {Regilaul in the {{Political Whirlpool}}},
  author = {{Estonian Literary Museum} and Saarlo, Liina},
  year = {2017},
  month = apr,
  journal = {Folklore: Electronic Journal of Folklore},
  volume = {67},
  pages = {115--142},
  issn = {14060957, 14060949},
  doi = {10.7592/FEJF2017.67.saarlo},
  abstract = {The article is dedicated to the history of the monumental regilaul publication Vana Kannel and examines the changing position of regilaul in the research politics of Soviet Estonia in the 1950s. The changing form of fieldwork expeditions is dealt with, as the collection of regilaul was seen as a part of the preparation process of the publication. Concentrating on the series of fieldtrips to Alutaguse region in the second half of the 1950s, objectives and details of fieldwork are scrutinized to pinpoint the reasons for the failure of the endeavour. The fundamental question the article examines is the interaction between the dominating ideologies of research politics and the individual interests of folklore collectors.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/8PAAUCFE/ContentServer.pdf;/Users/sarah/Zotero/storage/FR8C3BUM/Estonian Literary Museum and Saarlo - 2017 - Regilaul in the Political Whirlpool On Collecting.pdf}
}

@article{ettingerRoleMorphologyPhoneme2014,
  title = {The {{Role}} of {{Morphology}} in {{Phoneme Prediction}}: {{Evidence}} from {{MEG}}},
  shorttitle = {The {{Role}} of {{Morphology}} in {{Phoneme Prediction}}},
  author = {Ettinger, Allyson and Linzen, Tal and Marantz, Alec},
  year = {2014},
  month = feb,
  journal = {Brain and Language},
  volume = {129},
  pages = {14--23},
  issn = {0093-934X},
  doi = {10.1016/j.bandl.2013.11.004},
  abstract = {There is substantial neural evidence for the role of morphology (word-internal structure) in visual word recognition. We extend this work to auditory word recognition, drawing on recent evidence that phoneme prediction is central to this process. In a magnetoencephalography (MEG) study, we crossed morphological complexity (bruis-er vs. bourbon) with the predictability of the word ending (bourbon vs. burble). High prediction error (surprisal) led to increased auditory cortex activity. This effect was enhanced for morphologically complex words. Additionally, we calculated for each timepoint the surprisal corresponding to the phoneme perceived at that timepoint, as well as the cohort entropy, which quantifies the competition among words compatible with the string prefix up to that timepoint. Higher surprisal increased neural activity at the end of the word, and higher entropy decreased neural activity shortly after word onset. These results reinforce the role of morphology and phoneme prediction in spoken word recognition.},
  langid = {english},
  keywords = {Entropy,MEG,Morphology,Prediction,Spoken word recognition,Surprisal}
}

@book{evansDyingWords2009,
  title = {Dying {{Words}}},
  author = {Evans, Nicholas},
  year = {2009},
  month = apr,
  publisher = {{Wiley-Blackwell}},
  address = {{Oxford, UK}},
  doi = {10.1002/9781444310450},
  isbn = {978-1-4443-1045-0 978-0-631-23305-3},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/XNLUIEYR/Evans - 2009 - Dying Words.pdf}
}

@misc{ExplainingPhoneticVariation,
  title = {Explaining {{Phonetic Variation}}: {{A Sketch}} of the {{H}}\&amp;{{H Theory}} | {{SpringerLink}}},
  howpublished = {https://link.springer.com/chapter/10.1007/978-94-009-2037-8\_16},
  file = {/Users/sarah/Zotero/storage/UWKS3UUF/978-94-009-2037-8_16.html}
}

@misc{FaceMasksProvide,
  title = {Face Masks Provide Additional Communication Barrier for Nonnative Speech | {{EurekAlert}}! {{Science News}}},
  howpublished = {https://www.eurekalert.org/pub\_releases/2020-12/asoa-fmp120420.php?fbclid=IwAR3aIPlTxfjreZ24I5ucFGtAhgr72OGct0\_EO60hbWw16oSCm3rVO5Ilm6A}
}

@article{failesBlurringPresentUsing2020,
  title = {Blurring {{Past}} and {{Present}}: {{Using False Memory}} to {{Better Understand False Hearing}} in {{Young}} and {{Older Adults}}},
  shorttitle = {Blurring {{Past}} and {{Present}}},
  author = {Failes, Eric and Sommers, Mitchell S. and Jacoby, Larry L.},
  year = {2020},
  month = jul,
  journal = {Mem Cogn},
  issn = {1532-5946},
  doi = {10.3758/s13421-020-01068-8},
  abstract = {A number of recent studies have shown that older adults are more susceptible to context-based misperceptions in hearing (Rogers, Jacoby, \& Sommers, Psychology and Aging, 27, 33\textendash{} 45, 2012; Sommers, Morton, \& Rogers, Remembering: Attributions, Processes, and Control in Human Memory [Essays in Honor of Larry Jacoby], pp. 269\textendash{} 284, 2015) than are young adults. One explanation for these age-related increases in what we term false hearing is that older adults are less able than young individuals to inhibit a prepotent response favored by context. A similar explanation has been proposed for demonstrations of age-related increases in false memory (Jacoby, Bishara, Hessels, \& Toth, Journal of Experimental Psychology: General, 134, 131\textendash{} 148, 2005). The present study was designed to compare susceptibility to false hearing and false memory in a group of young and older adults. In Experiment 1, we replicated the findings of past studies demonstrating increased frequency of false hearing in older, relative to young, adults. In Experiment 2, we demonstrated older adults' increased susceptibility to false memory in the same sample. Importantly, we found that participants who were more prone to false hearing also tended to be more prone to false memory, supporting the idea that the two phenomena share a common mechanism. The results are discussed within the framework of a capture model, which differentiates between context-based responding resulting from failures of cognitive control and context-based guessing.},
  langid = {english}
}

@article{ferreiraPhonologicalInfluencesLexical2003,
  title = {Phonological {{Influences}} on {{Lexical}} ({{Mis}}){{Selection}}},
  author = {Ferreira, Victor S. and Griffin, Zenzi M.},
  year = {2003},
  month = jan,
  journal = {Psychological Science},
  volume = {14},
  number = {1},
  pages = {86--90},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.01424},
  abstract = {Speakers produce words to convey meaning, but does meaning alone determine which words they say? We report three experiments that show independent semantic and phonological influences converging to determine word selection. Speakers named pictures (e.g., of a priest) following visually presented cloze sentences that primed either semantic competitors of the target object name (``The woman went to the convent to become a \ldots ''), homophones of the competitors (``I thought that there would still be some cookies left, but there were \ldots ''), or matched unrelated control object names. Primed semantic competitors (nun) were produced instead of picture names more often than primed unrelated control object names, showing the well-documented influence of semantic similarity on lexical selection. Surprisingly, primed homophone competitors (none) also substituted for picture names more often than control object names even though they only sounded like competitors. Thus, independent semantic and phonological influences can converge to affect word selection.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/IFPA3Y2C/Ferreira and Griffin - 2003 - Phonological Influences on Lexical (Mis)Selection.pdf}
}

@book{fikkertDevelopmentProsodicSystems2003,
  title = {Development in {{Prosodic Systems}}:},
  shorttitle = {Development in {{Prosodic Systems}}},
  editor = {Fikkert, Paula and Jacobs, Haike},
  year = {2003},
  month = dec,
  publisher = {{DE GRUYTER}},
  doi = {10.1515/9783110894530},
  isbn = {978-3-11-016684-2}
}

@incollection{flegeSecondLanguageSpeech1995,
  title = {Second {{Language Speech Learning}}: {{Theory}}, {{Findings}} and {{Problems}}},
  shorttitle = {Second {{Language Speech Learning}}},
  author = {Flege, James},
  year = {1995},
  month = jan,
  pages = {229--273},
  abstract = {The aim of our research is to understand how speech learning changes over the life span and to explain why "earlier is better" as far as learning to pronounce a second language (L2) is concerned. An assumption we make is that the phonetic systems used in the production and perception of vowels and consonants remain adaptiive over the life span, and that phonetic systems reorganize in response to sounds encountered in an L2 through the addition of new phonetic categories, or through the modification of old ones. The chapter is organized in the following way. Several general hypotheses concerning the cause of foreign accent in L2 speech production are summarized in the introductory section. In the next section, a model of L2 speech learning that aims to account for age-related changes in L2 pronunciation is presented. The next three sections present summaries of empirical research dealing with the production and perception of L2 vowels, word-initial consonants, and word-final consonants. The final section discusses questions of general theoretical interest, with special attention to a featural (as opposed to a segmental) level of analysis. Although nonsegmental (i.e., prosodic) dimensions are an important source of foreign accent, the present chapter focuses on phoneme-sized units of speech. Although many different languages are learned as an L2, the focus is on the acquisition of English.}
}

@incollection{fletcherProsodySpeechTiming2010,
  title = {The {{Prosody}} of {{Speech}}: {{Timing}} and {{Rhythm}}},
  shorttitle = {The {{Prosody}} of {{Speech}}},
  booktitle = {The {{Handbook}} of {{Phonetic Sciences}}},
  author = {Fletcher, Janet},
  year = {2010},
  pages = {521--602},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781444317251.ch15},
  abstract = {This chapter contains sections titled: Introduction Lengthenings and Shortenings: The Temporal Signatures of Prosody Speech Timing: A Rhythmic Dimension Tempo and Pausing Concluding Comments References},
  chapter = {15},
  copyright = {Copyright \textcopyright{} 2010 Blackwell Publishing Ltd},
  isbn = {978-1-4443-1725-1},
  langid = {english},
  keywords = {influential interactive segment duration model - rule system by Klatt,intermediate phrase,intonational phrase,isochrony - perceptual phenomenon in spoken English and “stress-timed” languages in general,lengthenings and shortenings - temporal signatures of prosody,measuring tempo - monitoring speaking tempo,prosody of speech - timing and rhythm,segmental and syllable timing patterns – prosodic word,speaking rate and articulation rate,speech - activity in unfolding time,speech rhythms - successions and alternations of events with specific temporal paradigm,syllable duration - factors contributing to syllable timing versus stress timing,syllable structure,utterance,vowel reduction - maximizing difference between stressed and unstressed syllables}
}

@incollection{fletcherProsodySpeechTiming2010a,
  title = {The {{Prosody}} of {{Speech}}: {{Timing}} and {{Rhythm}}},
  shorttitle = {The {{Prosody}} of {{Speech}}},
  booktitle = {The {{Handbook}} of {{Phonetic Sciences}}},
  author = {Fletcher, Janet},
  year = {2010},
  pages = {521--602},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781444317251.ch15},
  abstract = {This chapter contains sections titled: Introduction Lengthenings and Shortenings: The Temporal Signatures of Prosody Speech Timing: A Rhythmic Dimension Tempo and Pausing Concluding Comments References},
  chapter = {15},
  isbn = {978-1-4443-1725-1},
  langid = {english},
  keywords = {influential interactive segment duration model - rule system by Klatt,intermediate phrase,intonational phrase,isochrony - perceptual phenomenon in spoken English and “stress-timed” languages in general,lengthenings and shortenings - temporal signatures of prosody,measuring tempo - monitoring speaking tempo,prosody of speech - timing and rhythm,segmental and syllable timing patterns – prosodic word,speaking rate and articulation rate,speech - activity in unfolding time,speech rhythms - successions and alternations of events with specific temporal paradigm,syllable duration - factors contributing to syllable timing versus stress timing,syllable structure,utterance,vowel reduction - maximizing difference between stressed and unstressed syllables}
}

@book{ForeignAccentComprehensibility,
  title = {Foreign {{Accent}}, {{Comprehensibility}}, and {{Intelligibility}} in the {{Speech}} of {{Second Language Learners}} - {{Munro}} - 1995 - {{Language Learning}} - {{Wiley Online Library}}}
}

@article{fortAmazonMechanicalTurk2011,
  title = {Amazon {{Mechanical Turk}}: {{Gold Mine}} or {{Coal Mine}}?},
  shorttitle = {Amazon {{Mechanical Turk}}},
  author = {Fort, Kar{\"e}n and Adda, Gilles and Cohen, K. Bretonnel},
  year = {2011},
  month = jun,
  journal = {Computational Linguistics},
  volume = {37},
  number = {2},
  pages = {413--420},
  issn = {0891-2017, 1530-9312},
  doi = {10.1162/COLI_a_00057},
  langid = {english}
}

@article{fortAmazonMechanicalTurk2011a,
  title = {Amazon {{Mechanical Turk}}: {{Gold Mine}} or {{Coal Mine}}?},
  shorttitle = {Amazon {{Mechanical Turk}}},
  author = {Fort, Kar{\"e}n and Adda, Gilles and Cohen, K. Bretonnel},
  year = {2011},
  month = jun,
  journal = {Computational Linguistics},
  volume = {37},
  number = {2},
  pages = {413--420},
  issn = {0891-2017, 1530-9312},
  doi = {10.1162/COLI_a_00057},
  langid = {english}
}

@article{foxDiscriminationDurationRatios1987,
  title = {Discrimination of Duration Ratios by Native {{English}} and {{Estonian}} Listeners},
  author = {Fox, Robert Allen and Lehiste, Ilse},
  year = {1987},
  month = oct,
  journal = {Journal of Phonetics},
  volume = {15},
  number = {4},
  pages = {349--363},
  issn = {0095-4470},
  doi = {10.1016/S0095-4470(19)30586-8},
  abstract = {It has been suggested that Estonian has a three-way quantity distinction among disyllabic word structures in terms of the ratio of the duration of first syllable compared to the duration of the second syllable. The present study examines the ability of Estonian speakers and American English speakers to discriminate among a set of duration ratios independent of other phonetic factors such as fundamental frequency or segmental variations. Subjects were required to discriminate among pairs of noise bursts whose durations were in the ratios of 1 : 2, 2: 3, 3: 2 and 2 : 1. In half the noise sequences the combined duration of noise 1 + noise 2 was 350ms, in the other half the combined duration was 450 ms. The results obtained show that both groups of listeners clearly recognized only two contrastive patterns: 1 : 2 and 2 : 3 vs. 3 : 2 and 2 : 1. In addition, overall sequence duration had a significant effect upon duration ratio discrimination. In terms of a language group difference, the Estonian and English groups differed only in terms of responses to very different ratios (e.g. 1 : 2 vs. 2 : 1; 2 : 3 vs. 2 : 1), in particular, the Estonian group produced fewer errors. The data support a reanalysis of the three-way quantity contrast into two distinct binary decisions: one based on quantity (short\textendash long vs. long\textendash short disyllabic structures) and one possibly based on fundamental frequency differences.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/RMF8RH7P/Fox and Lehiste - 1987 - Discrimination of duration ratios by native Englis.pdf;/Users/sarah/Zotero/storage/PH7KH8KQ/S0095447019305868.html}
}

@article{foxDiscriminationDurationRatios1989,
  title = {Discrimination of Duration Ratios in Bisyllabic Tokens by Native {{English}} and {{Estonian}} Listeners},
  author = {Fox, Robert Allen and Lehiste, Ilse},
  year = {1989},
  month = jul,
  journal = {Journal of Phonetics},
  volume = {17},
  number = {3},
  pages = {167--174},
  issn = {0095-4470},
  doi = {10.1016/S0095-4470(19)30427-9},
  abstract = {In an earlier study [Journal of Phonetics (1987), 15, 349\textendash 363], we examined the ability of Estonian and English speakers to discriminate among pairs of noise bursts whose durations were in the ratios of 1 : 2, 2: 3, 3 : 2, and 2 : 1. The results obtained showed that both groups of listeners clearly recognized only two contrastive patterns: 1 : 2 and 2 : 3 vs. 3 : 2 and 2: 1. Since there may be a difference in the perception of duration ratios when listeners are in a speech mode of perception rather than a non-speech mode, the present study is a replication of the earlier study using bisyllabic tokens as stimuli instead of noise-burst sequences. Again, the obtained results show the same contrastive patterns. The data support a reanalysis of the three-way quantity contrast in Estonian into two-way contrast based on duration (short-long vs. long-short) and a contrast based upon F0 contours.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/NYNUW4JN/Fox and Lehiste - 1989 - Discrimination of duration ratios in bisyllabic to.pdf;/Users/sarah/Zotero/storage/IF7XZVJN/S0095447019304279.html}
}

@article{foxPhonologicalNeighborhoodCompetition2015,
  title = {Phonological {{Neighborhood Competition Affects Spoken Word Production Irrespective}} of {{Sentential Context}}},
  author = {Fox, Neal P. and Reilly, Megan and Blumstein, Sheila E.},
  year = {2015},
  month = aug,
  journal = {J Mem Lang},
  volume = {83},
  pages = {97--117},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2015.04.002},
  abstract = {Two experiments examined the influence of phonologically similar neighbors on articulation of words' initial stop consonants in order to investigate the conditions under which lexically-conditioned phonetic variation arises. In Experiment 1, participants produced words in isolation. Results showed that the voice-onset time (VOT) of a target's initial voiceless stop was predicted by its overall neighborhood density, but not by its having a voicing minimal pair. In Experiment 2, participants read aloud the same targets after semantically predictive sentence contexts and after neutral sentence contexts. Results showed that, although VOTs were shorter in words produced after predictive contexts, the neighborhood density effect on VOT production persisted irrespective of context. These findings suggest that global competition from a word's neighborhood affects spoken word production independently of contextual modulation and support models in which activation cascades automatically and obligatorily among all of a selected target word's phonological neighbors during acoustic-phonetic encoding.},
  pmcid = {PMC4481884},
  pmid = {26124538}
}

@article{fribergGenerativeRulesMusic22,
  title = {Generative {{Rules}} for {{Music Performance}}: {{A Formal Description}} of a {{Rule System}}},
  shorttitle = {Generative {{Rules}} for {{Music Performance}}},
  author = {Friberg, Anders},
  year = 1991,
  journal = {Computer Music Journal},
  volume = {15},
  number = {2},
  pages = {56},
  issn = {01489267},
  doi = {10.2307/3680917},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/6JACW4IJ/Friberg - 1991 - Generative Rules for Music Performance A Formal D.pdf}
}

@article{fudgeSyllables1969,
  title = {Syllables},
  author = {Fudge, E. C.},
  year = {1969},
  month = sep,
  journal = {J. Ling.},
  volume = {5},
  number = {2},
  pages = {253--286},
  issn = {0022-2267, 1469-7742},
  doi = {10.1017/S0022226700002267},
  abstract = {Kohler (1966 a , 1966 b : 346\textendash{} 348) asks whether the syllable is a phonological universal, and concludes negatively. 1 The way to support such a conclusion is not difficult to imagine: the sort of specific objections to the syllable which Kohler raises would, if well-founded, be sufficient to prove his case.},
  langid = {english}
}

@book{FullArticleDimensions,
  title = {Full {{Article}}: {{Dimensions}} of {{Similarity}} in the {{Mental Lexicon}}}
}

@book{FullArticleTime,
  title = {Full {{Article}}: {{The Time Course}} of {{Contextual Cohort Effects}} in {{Auditory Processing}} of {{Category-Ambiguous Words}}: {{MEG Evidence}} for a {{Single}} ``{{Clash}}'' as {{Noun}} or {{Verb}}}
}

@book{FunctionalNeuroanatomyMetrical,
  title = {Functional {{Neuroanatomy}} of {{Metrical Stress Evaluation}} of {{Perceived}} and {{Imagined Spoken Words}} | {{Cerebral Cortex}} | {{Oxford Academic}}}
}

@article{gagnepainTemporalPredictiveCodes2012,
  title = {Temporal {{Predictive Codes}} for {{Spoken Words}} in {{Auditory Cortex}}},
  author = {Gagnepain, Pierre and Henson, Richard N. and Davis, Matthew H.},
  year = {2012},
  month = apr,
  journal = {Current Biology},
  volume = {22},
  number = {7},
  pages = {615--621},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2012.02.015},
  abstract = {Humans can recognize spoken words with unmatched speed and accuracy. Hearing the initial portion of a word such as ``formu\textbackslash ldots '' is sufficient for the brain to identify ``formula'' from the thousands of other words that partially match [1, 2, 3, 4, 5, 6]. Two alternative computational accounts propose that partially matching words (1) inhibit each other until a single word is selected (``formula'' inhibits ``formal'' by lexical competition [7, 8, 9]) or (2) are used to predict upcoming speech sounds more accurately (segment prediction error is minimal after sequences like ``formu\textbackslash ldots '' [10, 11, 12]). To distinguish these theories we taught participants novel words (e.g., ``formubo'') that sound like existing words (``formula'') on two successive days [13, 14, 15, 16]. Computational simulations show that knowing ``formubo'' increases lexical competition when hearing ``formu\textbackslash ldots '', but reduces segment prediction error. Conversely, when the sounds in ``formula'' and ``formubo'' diverge, the reverse is observed. The time course of magnetoencephalographic brain responses in the superior temporal gyrus (STG) is uniquely consistent with a segment prediction account. We propose a predictive coding model of spoken word recognition in which STG neurons represent the difference between predicted and heard speech sounds. This prediction error signal explains the efficiency of human word recognition and simulates neural responses in auditory regions.},
  langid = {english}
}

@article{gahlManyNeighborhoodsPhonological2016,
  title = {Many {{Neighborhoods}}: {{Phonological}} and {{Perceptual Neighborhood Density}} in {{Lexical Production}} and {{Perception}}},
  shorttitle = {Many {{Neighborhoods}}},
  author = {Gahl, Susanne and Strand, Julia F.},
  year = {2016},
  month = aug,
  journal = {Journal of Memory and Language},
  series = {Speaking and {{Listening}}: {{Relationships Between Language Production}} and {{Comprehension}}},
  volume = {89},
  pages = {162--178},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2015.12.006},
  abstract = {We examine the relationship of lexical representations, pronunciation variation, and word recognition, by investigating effects of two lexical variables: Phonological Neighborhood Density (the number of words that can be formed by a single phoneme substitution, addition, or deletion from the target word), as well as a measure of the perceptual similarity of a target word to other words in the lexicon. We show that perceptual similarity to other words affects recognition, but not production. Phonological Neighborhood Density, on the other hand, affects both word durations and recognition accuracy (words with many neighbors shorten and are difficult recognition targets). We interpret our results as indicating that effects of Phonological Neighborhood Density on pronunciation are not generally due to perceptual similarity of the target to other words. Our results are consistent with a more general line of research demonstrating effects of `central' processes on `peripheral' processes such as articulation, as well as effects of modality-specific properties, such as auditory similarity and motor movements, on measures thought to tap central processes.},
  langid = {english},
  keywords = {Lexical competition,Perceptual confusability,Phonological neighborhood density,Spoken word production,Word duration,Word identification}
}

@article{gahlWhyReducePhonological2012,
  title = {Why {{Reduce}}? {{Phonological Neighborhood Density}} and {{Phonetic Reduction}} in {{Spontaneous Speech}}},
  shorttitle = {Why {{Reduce}}?},
  author = {Gahl, Susanne and Yao, Yao and Johnson, Keith},
  year = {2012},
  month = may,
  journal = {Journal of Memory and Language},
  volume = {66},
  number = {4},
  pages = {789--806},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2011.11.006},
  abstract = {Frequent or contextually predictable words are often phonetically reduced, i.e. shortened and produced with articulatory undershoot. Explanations for phonetic reduction of predictable forms tend to take one of two approaches: Intelligibility-based accounts hold that talkers maximize intelligibility of words that might otherwise be difficult to recognize; production-based accounts hold that variation reflects the speed of lexical access and retrieval in the language production system. Here we examine phonetic variation as a function of phonological neighborhood density, capitalizing on the fact that words from dense phonological neighborhoods tend to be relatively difficult to recognize, yet easy to produce. We show that words with many phonological neighbors tend to be phonetically reduced (shortened in duration and produced with more centralized vowels) in connected speech, when other predictors of phonetic variation are brought under statistical control. We argue that our findings are consistent with the predictions of production-based accounts of pronunciation variation.},
  langid = {english},
  keywords = {Audience design,Language production,Lexical access,Lexical neighborhood,Pronunciation variation,Spontaneous speech corpus}
}

@article{gahlWhyReducePhonological2012a,
  title = {Why {{Reduce}}? {{Phonological Neighborhood Density}} and {{Phonetic Reduction}} in {{Spontaneous Speech}}},
  shorttitle = {Why {{Reduce}}?},
  author = {Gahl, Susanne and Yao, Yao and Johnson, Keith},
  year = {2012},
  month = may,
  journal = {Journal of Memory and Language},
  volume = {66},
  number = {4},
  pages = {789--806},
  issn = {0749596X},
  doi = {10.1016/j.jml.2011.11.006},
  abstract = {Frequent or contextually predictable words are often phonetically reduced, i.e. shortened and produced with articulatory undershoot. Explanations for phonetic reduction of predictable forms tend to take one of two approaches: Intelligibility-based accounts hold that talkers maximize intelligibility of words that might otherwise be difficult to recognize; production-based accounts hold that variation reflects the speed of lexical access and retrieval in the language production system. Here we examine phonetic variation as a function of phonological neighborhood density, capitalizing on the fact that words from dense phonological neighborhoods tend to be relatively difficult to recognize, yet easy to produce. We show that words with many phonological neighbors tend to be phonetically reduced (shortened in duration and produced with more centralized vowels) in connected speech, when other predictors of phonetic variation are brought under statistical control. We argue that our findings are consistent with the predictions of production-based accounts of pronunciation variation.},
  langid = {english}
}

@article{garamiLexicalInfluenceStress2017,
  title = {Lexical Influence on Stress Processing in a Fixed-Stress Language},
  author = {Garami, Linda and Rag{\'o}, Anett and Honbolyg{\'o}, Ferenc and Cs{\'e}pe, Val{\'e}ria},
  year = {2017},
  month = jul,
  journal = {International Journal of Psychophysiology},
  volume = {117},
  pages = {10--16},
  issn = {0167-8760},
  doi = {10.1016/j.ijpsycho.2017.03.006},
  abstract = {In the present study, we investigate how lexicality affects the processing of suprasegmental features at the word level. In contrast to earlier studies which analyzed the role of either segmental or suprasegmental feature in language processing our aim was to investigate the effect of the lexical status on the processing of violated stress pattern defined by linguistic rules. We have conducted a passive oddball ERP experiment, presenting a frequent CVCV word with legal (familiar) and illegal (unfamiliar) stress patterns. Former results obtained with pseudo-words in a similar paradigm enabled to assess the influence of lexical information on stress processing. The presence of lexically relevant information resulted in different ERP patterns compared to those obtained with pseudo-words. We obtained two consecutive MMN responses to the illegally stressed words while violating the illegal stress pattern with a legal one the deviant stimulus elicited two consecutive MMN responses as well. In the latter condition lexicality clearly enhanced the comparison of prosodic information between standard and deviant stimuli, as these components very completely missing when presenting pseudo-words. We interpret the results that lexicality acts as a filter since in the absence of lexical familiarity unfamiliar stress patterns are discriminated better. Our results highlight that even when stress is fully predictable, it is taken into account during pre-attentive processing of linguistic input.},
  langid = {english},
  keywords = {ERP,MMN,Speech perception,Word stress},
  file = {/Users/sarah/Zotero/storage/KZ8S5DGL/Garami et al. - 2017 - Lexical influence on stress processing in a fixed-.pdf;/Users/sarah/Zotero/storage/2UFNVLMQ/S0167876017302210.html}
}

@book{gawneLinksLinguisticDiscrimination,
  title = {3 {{Links}} for {{Linguistic Discrimination}} and {{African American English}}},
  author = {Gawne, Lauren},
  abstract = {Today's 3 links are for Linguistic Discrimination and African American English: John Baugh - "Linguistic Profiling" (2003) - The Social Life of Language YouTube video This video introduces John Baugh's work on linguistic profiling. Mike Mena summarises the concept of linguistic profiling, `white voice' in American society, and accent discrimination. An edited video of Mike Mena speaking to camera with some video clips, and quoted text on screen. 10m48s. Auto-generated subtitles. See also}
}

@article{geudensRhymingWordsOnset2005,
  title = {Rhyming {{Words}} and {{Onset}}\textendash{} {{Rime Constituents}}: {{An Inquiry}} into {{Structural Breaking Points}} and {{Emergent Boundaries}} in the {{Syllable}}},
  shorttitle = {Rhyming {{Words}} and {{Onset}}\textendash{} {{Rime Constituents}}},
  author = {Geudens, Astrid and Sandra, Dominiek and Martensen, Heike},
  year = {2005},
  month = dec,
  journal = {Journal of Experimental Child Psychology},
  series = {Linguistic {{Constraints}} on {{Literacy Development}}},
  volume = {92},
  number = {4},
  pages = {366--387},
  issn = {0022-0965},
  doi = {10.1016/j.jecp.2005.07.002},
  abstract = {Geudens and Sandra, in their 2003 study, investigated the special role of onsets and rimes in Dutch-speaking children's explicit phonological awareness. In the current study, we tapped implicit phonological knowledge using forced-choice similarity judgment (Experiment 1) and recall of syllable lists (Experiment 2). In Experiment 1, Dutch-speaking prereaders judged rime-sharing pseudowords (/fɑs/\textendash/mɑs/) to sound more similar than pseudowords sharing an equally sized nonrime unit (/fɑs/\textendash/fɑk/). However, in a syllable recall task (/t{$\epsilon$}f/, /ris/, /nɑl/), Dutch-speaking prereaders were as likely to produce recombination errors that broke up the rime (/t{$\epsilon$}s/) as to produce errors that retained the rime (/r{$\epsilon$}f/). Thus, a rime effect was obtained in a task that highlighted the phonological similarity between items sharing their rimes, but this effect disappeared in tasks without repetition of rime units. We conclude that children's sensitivity to rimes depends on similarity relations and might not reflect a fixed perceived structure of spoken syllables.},
  langid = {english},
  keywords = {Onset–rime structure,Phonological representations,Phonological sensitivity,Recall errors,Rhyme,Short-term memory,Similarity judgment}
}

@article{gilbertRecognitionMemoryNoise2014,
  title = {Recognition {{Memory}} in {{Noise}} for {{Speech}} of {{Varying Intelligibility}}},
  author = {Gilbert, Rachael C. and Chandrasekaran, Bharath and Smiljanic, Rajka},
  year = {2014},
  month = jan,
  journal = {The Journal of the Acoustical Society of America},
  volume = {135},
  number = {1},
  pages = {389--399},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.4838975},
  abstract = {This study investigated the extent to which noise impacts normal-hearing young adults' speech processing of sentences that vary in intelligibility. Intelligibility and recognition memory in noise were examined for conversational and clear speech sentences recorded in quiet (quiet speech, QS) and in response to the environmental noise (noise-adapted speech, NAS). Results showed that (1) increased intelligibility through conversational-to-clear speech modifications led to improved recognition memory and (2) NAS presented a more naturalistic speech adaptation to noise compared to QS, leading to more accurate word recognition and enhanced sentence recognition memory. These results demonstrate that acoustic-phonetic modifications implemented in listener-oriented speech enhance speech-in-noise processing beyond word recognition. Effortful speech processing in challenging listening environments can thus be improved by speaking style adaptations on the part of the talker. In addition to enhanced intelligibility, a substantial improvement in recognition memory can be achieved through speaker adaptations to the environment and to the listener when in adverse conditions.}
}

@article{goldingerEchoesEchoesEpisodic19980501,
  title = {Echoes of Echoes? {{An}} Episodic Theory of Lexical Access.},
  shorttitle = {Echoes of Echoes?},
  author = {Goldinger, Stephen D.},
  year = {19980501},
  journal = {Psychological Review},
  volume = {105},
  number = {2},
  pages = {251},
  publisher = {{US: American Psychological Association}},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.105.2.251},
  file = {/Users/sarah/Zotero/storage/CMQEA7HI/Goldinger - Echoes of echoes An episodic theory of lexical ac.pdf;/Users/sarah/Zotero/storage/XJDZK8ZN/1998-01102-003.html}
}

@article{goldingerEchoesEchoesEpisodic19980501a,
  title = {Echoes of Echoes? {{An}} Episodic Theory of Lexical Access.},
  shorttitle = {Echoes of Echoes?},
  author = {Goldinger, Stephen D.},
  year = {19980501},
  journal = {Psychological Review},
  volume = {105},
  number = {2},
  pages = {251},
  publisher = {{US: American Psychological Association}},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.105.2.251},
  file = {/Users/sarah/Zotero/storage/UPDZ6GFV/Goldinger - Echoes of echoes An episodic theory of lexical ac.pdf;/Users/sarah/Zotero/storage/TSKMRKM9/1998-01102-003.html}
}

@book{goldinHowMedicalMasks2020,
  title = {How {{Do Medical Masks Degrade Speech Reception}}? - {{Hearing Review}}},
  shorttitle = {How {{Do Medical Masks Degrade Speech Reception}}?},
  author = {Goldin, A and Weinstein, BE and Shiman, N},
  year = {2020},
  abstract = {Medical and surgical masks can block speech signals and important information, making this an even more important issue in the Era of COVID-19.},
  langid = {american}
}

@article{golstonPhonologyGreekLyric2005,
  title = {The Phonology of {{Greek}} Lyric Meter},
  author = {Golston, Chris and Riad, Tomas},
  year = {2005},
  month = mar,
  journal = {Journal of Linguistics},
  volume = {41},
  number = {1},
  pages = {77--115},
  issn = {0022-2267, 1469-7742},
  doi = {10.1017/S0022226704003068},
  abstract = {The meter of Greek lyric poetry shows great variation within and between lines regarding the shape, number and combinations of basic metrical units. We offer a simplifying analysis in terms of markedness, in which meters are defined by distinctive violations of linguistic constraints controlling rhythm, layering, binarity, and alignment. The constraints that are distinctively violated in meter are low ranked in the phonology of Greek.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/BKTUQQ3V/Golston and Riad - 2005 - The phonology of Greek lyric meter.pdf}
}

@article{golstonScansionAlliterationBeowulf,
  title = {Scansion and Alliteration in {{Beowulf}}},
  author = {Golston, Chris and Riad, Tomas},
  pages = {32},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/ND6C2KCZ/Golston and Riad - Scansion and alliteration in Beowulf.pdf}
}

@article{gordonPHONETICCORRELATESSTRESS1997,
  title = {{{PHONETIC CORRELATES OF STRESS AND THE PROSODIC HIERARCHY IN ESTONIAN}}},
  author = {Gordon, Matthew},
  year = {1997},
  journal = {Estonian prosody: Papers from a symposium},
  pages = {(pp. 100-124)},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/77TFEE7B/Gordon - PHONETIC CORRELATES OF STRESS AND THE PROSODIC HIE.pdf}
}

@article{gordonPhonologicalNeighborhoodEffects2002,
  title = {Phonological {{Neighborhood Effects}} in {{Aphasic Speech Errors}}: {{Spontaneous}} and {{Structured Contexts}}},
  shorttitle = {Phonological {{Neighborhood Effects}} in {{Aphasic Speech Errors}}},
  author = {Gordon, Jean K},
  year = {2002},
  month = aug,
  journal = {Brain and Language},
  volume = {82},
  number = {2},
  pages = {113--145},
  issn = {0093-934X},
  doi = {10.1016/S0093-934X(02)00001-9},
  abstract = {The current study investigates the influence of phonological neighborhoods on the accuracy of speech production in aphasia by examining errors produced in both spontaneous and structured speech tasks. Characteristics of the phonological neighborhoods of spontaneously produced aphasic errors are compared to the neighborhood characteristics of correctly produced targets in a picture description task. Accuracy of picture naming is also examined with reference to the phonological neighborhood characteristics of the stimuli. Results show that frequency of occurrence and neighborhood density play a facilitative role in speech production, replicating findings from recent studies with normal subjects. It is argued that the results are most parsimoniously explained within an interactive activation framework of lexical access.},
  langid = {english},
  keywords = {Aphasia,Lexical access,Neighborhood effects,Speech errors}
}

@article{gordonPhonologicalNeighborhoodEffects2002a,
  title = {Phonological {{Neighborhood Effects}} in {{Aphasic Speech Errors}}: {{Spontaneous}} and {{Structured Contexts}}},
  shorttitle = {Phonological {{Neighborhood Effects}} in {{Aphasic Speech Errors}}},
  author = {Gordon, Jean K},
  year = {2002},
  month = aug,
  journal = {Brain and Language},
  volume = {82},
  number = {2},
  pages = {113--145},
  issn = {0093-934X},
  doi = {10.1016/S0093-934X(02)00001-9},
  abstract = {The current study investigates the influence of phonological neighborhoods on the accuracy of speech production in aphasia by examining errors produced in both spontaneous and structured speech tasks. Characteristics of the phonological neighborhoods of spontaneously produced aphasic errors are compared to the neighborhood characteristics of correctly produced targets in a picture description task. Accuracy of picture naming is also examined with reference to the phonological neighborhood characteristics of the stimuli. Results show that frequency of occurrence and neighborhood density play a facilitative role in speech production, replicating findings from recent studies with normal subjects. It is argued that the results are most parsimoniously explained within an interactive activation framework of lexical access.},
  langid = {english},
  keywords = {Aphasia,Lexical access,Neighborhood effects,Speech errors}
}

@book{gordonPhonologicalTypology2016,
  title = {Phonological {{Typology}}},
  author = {Gordon, M.K.},
  year = {2016},
  volume = {1},
  publisher = {{Oxford University Press}}
}

@article{gordonSyllableStructureExtrametricality2010,
  title = {Syllable {{Structure}} and {{Extrametricality}}: {{A Typological}} and {{Phonetic Study}}},
  shorttitle = {Syllable {{Structure}} and {{Extrametricality}}},
  author = {Gordon, Matthew and Jany, Carmen and Nash, Carlos and Takara, Nobutaka},
  year = {2010},
  month = jan,
  journal = {Studies in Language. International Journal sponsored by the Foundation ``Foundations of Language''},
  volume = {34},
  number = {1},
  pages = {131--166},
  publisher = {{John Benjamins}},
  issn = {0378-4177, 1569-9978},
  doi = {10.1075/sl.34.1.15gor},
  abstract = {This paper proposes a functional basis for final consonant extrametricality, the asymmetric status of CVC syllables as stress-attracting in non-final position of a word but stress-rejecting in final position. A typological study of phonemic vowel length pattern in 10 languages with this final vs. non-final stress asymmetry and 30 languages in which CVC attracts stress in final position indicates a robust asymmetry between languages differing in their stress system's treatment of final CVC. Languages that asymmetrically allow stress on non-final but not on final CVC all lack phonemic vowel length contrast in final position, whereas those lacking the stress asymmetry often have contrastive length in final vowels. It is claimed that the absence of phonemic length in languages that do not stress final CVC facilitates the nearly universal pattern of phonetic final lengthening, which threatens to obscure the perception of phonemic length. The enhanced lengthening of final vowels in languages with final phonemic vowel length reduces the duration ratio of CVC relative to CV, thereby reducing CVC's perceptual prominence and thus its propensity to attract stress in keeping with Lunden's (2006) proportional duration theory of weight. A phonetic study of two languages differing in the stress-attracting ability of final CVC offers support for the proposed account. Arabic, which displays consonant extrametricality and largely lacks phonemic vowel length in final position, has substantial final vowel lengthening, whereas Kabardian, which stresses final CVC and contrasts vowel length in final position, lacks substantial final lengthening.},
  langid = {english}
}

@book{GorillaExperimentBuilder,
  title = {Gorilla {{Experiment Builder}}},
  journal = {Gorilla},
  abstract = {We help ambitious behavioural scientists run novel online experiments easily}
}

@article{greenbergTemporalPropertiesSpontaneous2003,
  title = {Temporal {{Properties}} of {{Spontaneous Speech}}\textemdash{} a {{Syllable-Centric Perspective}}},
  author = {Greenberg, Steven and Carvey, Hannah and Hitchcock, Leah and Chang, Shuangyu},
  year = {2003},
  month = jul,
  journal = {Journal of Phonetics},
  series = {Temporal {{Integration}} in the {{Perception}} of {{Speech}}},
  volume = {31},
  number = {3},
  pages = {465--485},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2003.09.005},
  abstract = {Temporal properties of the speech signal are of potentially great importance for understanding spoken language and may provide significant insight into the manner in which listeners process spoken language with so little apparent effort. It is the thesis of this study that durational properties of phonetic segments differentially reflect the amount of information contained within a syllable, and that syllable prominence is an indirect measure of linguistic entropy. The ability to understand spoken language appears to depend on a broad distribution of syllable duration, ranging between 50 and 400ms (for American English), which is reflected in the modulation spectrum of the acoustic signal. The upper branch of the modulation spectrum (6\textendash{} 20Hz) reflects unstressed syllables, while the lower branch (\${$<\$$}5Hz) represents mostly heavily stressed syllables. Low-pass filtering the modulation spectrum reduces the intelligibility of spoken sentences in a manner consistent with the differential contribution of stressed and unstressed syllables to understanding spoken language. The origins of this phenomenon are investigated in terms of the durational properties of phonetic segments contained in a corpus of spontaneous American English telephone dialogues (SWITCHBOARD). Forty-five minutes of this material was manually annotated with respect to stress accent, and the relation between accent level and segmental duration examined. Statistical analysis indicates that much of the temporal variation observed at the syllabic and phonetic-segment levels can be accounted for in terms of two basic parameters: (1) stress-accent pattern and (2) position of the segment within the syllable. Segments are generally longest in heavily stressed syllables and shortest in syllables without stress. However, the magnitude of accent's impact on duration varies as a function of syllable position. Duration of the nucleus is heavily affected by stress-accent level\textemdash{} heavily stressed nuclei are, on average, twice as long as their unstressed counterparts, while the duration of the onset is also significantly sensitive to stress, but to a lesser degree. In contrast, stress has relatively little impact on coda duration. This pattern of durational variation suggests that the vocalic nucleus absorbs much of the impact of stress accent and potentially sets the register for interpreting the phonetic segments contained within the syllable. Moreover, the data imply that linguistic entropy is not uniformly distributed across the syllable\textemdash{} the onset and nucleus convey more information than the coda.},
  langid = {english}
}

@phdthesis{greenNativeNonnativeIntuitions2016,
  type = {Thesis},
  title = {Native and Non-Native Intuitions on the Phonology of Binomial Locutions},
  author = {Green, Viola Vladimirovna},
  year = {2016},
  month = aug,
  doi = {10.15781/T26M33663},
  abstract = {Binomial locutions are a well-known case of structural iconicity that exists in many languages. By binomial locutions I understand formations that have the shape of A conjunction B (1a), or A-B (1b): (1).  a. English: bread and butter, wear and tear; French: dire et juger, aller et retour, ni foi ni loi b. English: wishy-washy, helter-skelter; French: p\^ele-m\^ele, clopin-clopant, tohu-bohu  This dissertation deals with phonological patterns in binomial locutions. It will be argued that two kinds of constraints underlie their formation and fossilization of their word order: constraints on the directionality of a certain phonological feature (Birdsong, 1979; Cooper \& Ross, 1975) and constraints on the choice of the corresponding segments (Minkova, 2002; Yip, 1988-2000). I refer to the first kind of constraints as to Directionality Constraints and to the second kind of constraints as to Correspondence Constraints. The main objective of this study is to investigate the psychological reality and the relative strength of these constraints in native and non-native speakers of English and French.  This study is experimental and closely models the hypothesis and the methodology set forth in Birdsong (1979). Speakers' sensitivities to the putative constraints are tested with a computer-based judgment task, using pairs of nonsensical expressions, structured in such a way that one expression obeys a specific constraint, and the other expression disobeys it. The task of the participants is to listen to such pairs and to indicate which of them they prefer by using a 6-point scale. The results of this experiment reveal that native English speakers are more sensitive than both native French speakers and non-native English speakers to Directionality Constraints. Moreover, native English speakers prefer rhyming patterns over ablaut alliterating patterns \textendash{} a trend, that was not observed in other groups tested. Finally, most participants displayed sensitivities to two constraints on directionality \textendash{} Vowel Quality and Final Consonant Number. I argue that sensitivity to these constraints stems from various factors (iconicity, perceptual salience, short-before-long and unmarked-before-marked principles), which all conspire to favor the same order and predict the same direction of fossilization.},
  langid = {english},
  school = {University of Texas at Austin},
  annotation = {Accepted: 2016-11-28T21:33:32Z},
  file = {/Users/sarah/Zotero/storage/M9YX7NIJ/Green - 2016 - Native and non-native intuitions on the phonology .pdf;/Users/sarah/Zotero/storage/6G9EV28V/43817.html}
}

@article{guevara-rukozWhichEpentheticVowel2017,
  title = {Which {{Epenthetic Vowel}}? {{Phonetic Categories}} versus {{Acoustic Detail}} in {{Perceptual Vowel Epenthesis}}},
  shorttitle = {Which {{Epenthetic Vowel}}?},
  author = {{Guevara-Rukoz}, Adriana and Lin, Isabelle and Morii, Masahiro and Minagawa, Yasuyo and Dupoux, Emmanuel and Peperkamp, Sharon},
  year = {2017},
  month = aug,
  journal = {The Journal of the Acoustical Society of America},
  volume = {142},
  number = {2},
  pages = {EL211-EL217},
  issn = {0001-4966},
  doi = {10.1121/1.4998138},
  abstract = {This study aims to quantify the relative contributions of phonetic categories and acoustic detail on phonotactically induced perceptual vowel epenthesis in Japanese listeners. A vowel identification task tested whether a vowel was perceived within illegal consonant clusters and, if so, which vowel was heard. Cross-spliced stimuli were used in which vowel coarticulation present in the cluster did not match the quality of the flanking vowel. Two clusters were used, /hp/ and /kp/, the former containing larger amounts of resonances of the preceding vowel. While both flanking vowel and coarticulation influenced vowel quality, the influence of coarticulation was larger, especially for /hp/.},
  langid = {english}
}

@article{hancocketalMeasuringActivationLevel2003,
  title = {Measuring the {{Activation Level}} of {{Critical Lures}} in the {{Deese-Roediger-McDermott Paradigm}}},
  author = {{Hancock et al}},
  year = {2003},
  journal = {The American Journal of Psychology},
  volume = {Vol. 116},
  number = {No. 1 (Spring, 2003)},
  pages = {1--14},
  doi = {DOI: 10.2307/1423332 · Source: PubMed}
}

@article{haneyRestrictingUseSolitary2018,
  title = {Restricting the {{Use}} of {{Solitary Confinement}}},
  author = {Haney, Craig},
  year = {2018},
  journal = {Annual Review of Criminology},
  volume = {1},
  number = {1},
  pages = {285--310},
  doi = {10.1146/annurev-criminol-032317-092326},
  abstract = {A robust scientific literature has established the negative psychological effects of solitary confinement. The empirical findings are supported by a theoretical framework that underscores the importance of social contact to psychological as well as physical well-being. In essence, human beings have a basic need to establish and maintain connections to others and the deprivation of opportunities to do so has a range of deleterious consequences. These scientific conclusions, as well as concerns about the high cost and lack of any demonstrated penological purpose that solitary confinement reliably serves, have led to an emerging consensus among correctional as well as professional, mental health, legal, and human rights organizations to drastically limit the practice.},
  keywords = {conditions of confinement,prison effects,prison isolation,solitary confinement},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-criminol-032317-092326},
  file = {/Users/sarah/Zotero/storage/NBITS3AS/Haney - 2018 - Restricting the Use of Solitary Confinement.pdf}
}

@article{harleyPhonologicalActivationSemantic1993,
  title = {Phonological Activation of Semantic Competitors during Lexical Access in Speech Production},
  author = {Harley, Trevor A.},
  year = {1993},
  month = aug,
  journal = {Language and Cognitive Processes},
  volume = {8},
  number = {3},
  pages = {291--309},
  publisher = {{Routledge}},
  issn = {0169-0965},
  doi = {10.1080/01690969308406957},
  abstract = {Experimental evidence from picture-naming tasks suggests that lexical access in speech production (lexicalisation) occurs in two non-overlapping stages. Semantic information is used to access an abstract lexical form; only when this stage is complete does phonological realisation begin. Such experimental data are interpreted as evidence against connectionist models of lexicalisation. This paper argues that, counterintuitively, connectionist models are not inconsistent with these data. This proposal is supported by appropriate simulations. Interactive activation models of speech production have the additional advantage of accounting for speech error and other data.},
  annotation = {\_eprint: https://doi.org/10.1080/01690969308406957},
  file = {/Users/sarah/Zotero/storage/86ILIR58/01690969308406957.html}
}

@article{hausenMusicSpeechProsody2013,
  title = {Music and {{Speech Prosody}}: {{A Common Rhythm}}},
  shorttitle = {Music and {{Speech Prosody}}},
  author = {Hausen, Maija and Torppa, Ritva and Salmela, Viljami R. and Vainio, Martti and S{\"a}rk{\"a}m{\"o}, Teppo},
  year = {2013},
  journal = {Front. Psychol.},
  volume = {4},
  publisher = {{Frontiers}},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00566},
  abstract = {Disorders of music and speech perception, known as amusia and aphasia, have traditionally been regarded as dissociated deficits based on studies of brain damaged patients. This has been taken as evidence that music and speech are perceived by largely separate and independent networks in the brain. However, recent studies of congenital amusia have broadened this view by showing that the deficit is associated with problems in perceiving speech prosody, especially intonation and emotional prosody. In the present study the association between the perception of music and speech prosody was investigated with healthy Finnish adults (n = 61) using an on-line music perception test including the Scale subtest of Montreal Battery of Evaluation of Amusia (MBEA) and Off-Beat and Out-of-key tasks as well as a prosodic verbal task that measures the perception of word stress. Regression analyses showed that there was a clear association between prosody perception and music perception, especially in the domain of rhythm perception. This association was evident after controlling for music education, age, pitch perception, visuospatial perception and working memory. Pitch perception was significantly associated with music perception but not with prosody perception. The association between music perception and visuospatial perception (measured using analogous tasks) was less clear. Overall, the pattern of results indicates that there is a robust link between music and speech perception and that this link can be mediated by rhythmic cues (time and stress).},
  langid = {english},
  keywords = {MBEA,music perception,speech prosody perception,visuospatial perception,word stress},
  file = {/Users/sarah/Zotero/storage/C9TWSPIS/Hausen et al. - 2013 - Music and Speech Prosody A Common Rhythm.pdf}
}

@article{hayesCompensatoryLengtheningMoraic1989,
  title = {Compensatory {{Lengthening}} in {{Moraic Phonology}}},
  author = {Hayes, Bruce},
  year = {1989},
  journal = {Linguistic Inquiry},
  volume = {20},
  number = {2},
  pages = {253--306},
  issn = {0024-3892},
  file = {/Users/sarah/Zotero/storage/PICUH3H5/Hayes - 1989 - Compensatory Lengthening in Moraic Phonology.pdf}
}

@article{hayesCompensatoryLengtheningMoraic1989a,
  title = {Compensatory {{Lengthening}} in {{Moraic Phonology}}},
  author = {Hayes, Bruce},
  year = {1989},
  journal = {Linguistic Inquiry},
  volume = {20},
  number = {2},
  pages = {253--306},
  publisher = {{The MIT Press}},
  issn = {0024-3892}
}

@article{hayesExtrametricalityEnglishStress1982,
  title = {Extrametricality and {{English Stress}}},
  author = {Hayes, Bruce},
  year = {1982},
  journal = {Linguistic Inquiry},
  volume = {13},
  number = {2},
  pages = {227--276},
  publisher = {{The MIT Press}},
  issn = {0024-3892}
}

@article{hayesMaxentGrammarsMetrics2012,
  title = {Maxent Grammars for the Metrics of {{Shakespeare}} and {{Milton}}},
  author = {Hayes, Bruce and Wilson, Colin and Shisko, Anne},
  year = {2012},
  journal = {Language},
  volume = {88},
  number = {4},
  pages = {691--731},
  issn = {1535-0665},
  doi = {10.1353/lan.2012.0089},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/X7S4LYTK/Hayes et al. - 2012 - Maxent grammars for the metrics of Shakespeare and.pdf}
}

@article{hayesRolePhonologicalPhrasing1996,
  title = {The Role of Phonological Phrasing in Sung and Chanted Verse},
  author = {Hayes, Bruce and Kaun, Abigail},
  year = {1996},
  journal = {The Linguistic Review},
  volume = {13},
  number = {3-4},
  issn = {0167-6318, 1613-3676},
  doi = {10.1515/tlir.1996.13.3-4.243},
  abstract = {This article is a study of the metrics of sung and chanted verse, based on a data corpus of 670 English folksong lines, as well as chanted renditions of the corpus by ten native speaker consultants. Our theoretical focus is on the role of phonological phrasing in metrics. We find that in sung and chanted verse, an especially tight correspondence to the metrical pattern is imposed on linguistic material that is either bounded within a tight phrasal domain or located at the right edge of a high-level domain. These patterns have been observed earlier for spoken verse. But for the phenomenon of metrical inversion, the behavior of sung and chanted verse is quite different from spoken verse. We develop an explanation of the difference, based on the idea that inversion in sung and chanted verse occurs only in those cases where it is the best available metrical option.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/IZ2FYXTQ/Hayes and Kaun - 1996 - The role of phonological phrasing in sung and chan.pdf}
}

@article{herbstrittComplexProbabilityExpressions2019,
  title = {Complex {{Probability Expressions}} \& {{Higher-Order Uncertainty}}: {{Compositional Semantics}}, {{Probabilistic Pragmatics}} \& {{Experimental Data}}},
  shorttitle = {Complex {{Probability Expressions}} \& {{Higher-Order Uncertainty}}},
  author = {Herbstritt, Michele and Franke, Michael},
  year = {2019},
  month = may,
  journal = {Cognition},
  volume = {186},
  pages = {50--71},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2018.11.013},
  abstract = {We present novel experimental data pertaining to the use and interpretation of simple probability expressions (such as possible or likely) and complex ones (such as possibly likely or certainly possible) in situations of higher-order uncertainty, i.e., where speakers may be uncertain about the probability of a chance event. The data is used to critically assess a probabilistic pragmatics model in the vein of Rational Speech Act approaches (e.g., Frank and Goodman, 2012; Franke and J\"ager, 2016; Goodman and Frank, 2016). The model embeds a simple compositional threshold-semantics for probability expressions, following recent work in formal linguistics (Swanson, 2006; Yalcin, 2007, 2010; Lassiter, 2010, 2017; Moss, 2015).},
  langid = {english},
  keywords = {Communication,Pragmatics,Probability,Rationality,Uncertainty}
}

@article{hertensteinTouchCommunicatesDistinct2006,
  title = {Touch Communicates Distinct Emotions. - {{PsycNET}}},
  author = {Hertenstein,, M. J. and Keltner, D and App, B. and Bulleit, B.A. and Jaskolka, A. R.},
  year = {2006},
  doi = {10.1037/1528-3542.6.3.528},
  abstract = {APA PsycNet DoiLanding page},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/68PV5SX8/doiLanding.html}
}

@article{hilbigReactionTimeEffects2016,
  title = {Reaction {{Time Effects}} in {{Lab-}} versus {{Web-Based Research}}: {{Experimental Evidence}}},
  shorttitle = {Reaction {{Time Effects}} in {{Lab-}} versus {{Web-Based Research}}},
  author = {Hilbig, Benjamin E.},
  year = {2016},
  month = dec,
  journal = {Behav Res},
  volume = {48},
  number = {4},
  pages = {1718--1724},
  issn = {1554-3528},
  doi = {10.3758/s13428-015-0678-9},
  abstract = {Although Web-based research is now commonplace, it continues to spur skepticism from reviewers and editors, especially whenever reaction times are of primary interest. Such persistent preconceptions are based on arguments referring to increased variation, the limits of certain software and technologies, and a noteworthy lack of comparisons (between Web and lab) in fully randomized experiments. To provide a critical test, participants were randomly assigned to complete a lexical decision task either (a) in the lab using standard experimental software (E-Prime), (b) in the lab using a browser-based version (written in HTML and JavaScript), or (c) via the Web using the same browser-based version. The classical word frequency effect was typical in size and corresponded to a very large effect in all three conditions. There was no indication that the Web- or browser-based data collection was in any way inferior. In fact, if anything, a larger effect was obtained in the browser-based conditions than in the condition relying on standard experimental software. No differences between Web and lab (within the browser-based conditions) could be observed, thus disconfirming any substantial influence of increased technical or situational variation. In summary, the present experiment contradicts the still common preconception that reaction time effects of only a few hundred milliseconds cannot be detected in Web experiments.},
  langid = {english}
}

@book{hooksTeachingCriticalThinking2010,
  title = {Teaching Critical Thinking: Practical Wisdom},
  shorttitle = {Teaching Critical Thinking},
  author = {{hooks}, bell},
  year = {2010},
  publisher = {{Routledge}},
  address = {{New York}},
  isbn = {978-0-415-96819-5 978-0-415-96820-1 978-0-203-86919-2},
  langid = {english},
  lccn = {LB1025.3 .H67 2010},
  keywords = {Critical thinking,Democracy,Teaching},
  annotation = {OCLC: ocn149307225},
  file = {/Users/sarah/Zotero/storage/XIWEXPDI/hooks - 2010 - Teaching critical thinking practical wisdom.pdf}
}

@article{howsonLoweredF2Observed2020,
  title = {Lowered {{F2 Observed}} in {{Uvular Rhotics Involves}} a {{Tongue Root Gesture}}: {{Evidence}} from {{Upper Sorbian}}},
  shorttitle = {Lowered {{F2 Observed}} in {{Uvular Rhotics Involves}} a {{Tongue Root Gesture}}},
  author = {Howson, Phil J. and Kochetov, Alexei},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {2845--2857},
  issn = {0001-4966},
  doi = {10.1121/10.0000997},
  langid = {english}
}

@article{huangTaskIrrelevantStimulusAttribute2009,
  title = {A {{Task-Irrelevant Stimulus Attribute Affects Perception}} and {{Short-Term Memory}}},
  author = {Huang, Jie and Kahana, Michael J. and Sekuler, Robert},
  year = {2009},
  month = dec,
  journal = {Mem Cognit},
  volume = {37},
  number = {8},
  pages = {1088--1102},
  issn = {0090-502X},
  doi = {10.3758/MC.37.8.1088},
  abstract = {Selective attention protects cognition against intrusions of task-irrelevant stimulus attributes. This protective function was tested in coordinated psychophysical and memory experiments. Stimuli were superimposed, horizontally and vertically oriented gratings of varying spatial frequency; only one orientation was task relevant. Experiment 1 demonstrated that a task-irrelevant spatial frequency interfered with visual discrimination of the task-relevant spatial frequency. Experiment 2 adopted a two-item Sternberg task, using stimuli that had been scaled to neutralize interference at the level of vision. Despite being visually neutralized, the task-irrelevant attribute strongly influenced recognition accuracy and associated reaction times (RTs). This effect was sharply tuned, with the task-irrelevant spatial frequency having an impact only when the task-relevant spatial frequencies of the probe and study items were highly similar to one another. Model-based analyses of judgment accuracy and RT distributional properties converged on the point that the irrelevant orientation operates at an early stage in memory processing, not at a later one that supports decision making.},
  pmcid = {PMC2836167},
  pmid = {19933454}
}

@book{ImpactFaceMasks,
  title = {The {{Impact}} of {{Face Masks}} on the {{Recall}} of {{Spoken Sentences}}: {{The Journal}} of the {{Acoustical Society}} of {{America}}: {{Vol}} 149, {{No}} 1}
}

@book{inoueLaborBasedGradingContracts2019,
  title = {Labor-{{Based Grading Contracts}}: {{Building Equity}} and {{Inclusion}} in the {{Compassionate Writing Classroom}}},
  shorttitle = {Labor-{{Based Grading Contracts}}},
  author = {Inoue, Asao B.},
  year = {2019},
  month = jan,
  publisher = {{The WAC Clearinghouse; University Press of Colorado}},
  doi = {10.37514/PER-B.2019.0216.0},
  isbn = {978-1-64215-021-6},
  langid = {english}
}

@book{inoueLaborBasedGradingContracts2019a,
  title = {Labor-{{Based Grading Contracts}}: {{Building Equity}} and {{Inclusion}} in the {{Compassionate Writing Classroom}}},
  shorttitle = {Labor-{{Based Grading Contracts}}},
  author = {Inoue, Asao B.},
  year = {2019},
  month = jan,
  publisher = {{The WAC Clearinghouse; University Press of Colorado}},
  doi = {10.37514/PER-B.2019.0216.0},
  isbn = {978-1-64215-021-6},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/DBBJN5IG/Inoue - 2019 - Labor-Based Grading Contracts Building Equity and.pdf}
}

@misc{KalevalaEstonianPerspective2018,
  title = {Kalevala \textendash{} the {{Estonian}} Perspective},
  year = {2018},
  month = feb,
  journal = {FMQ},
  abstract = {The main theme of the first ever FMQ magazine in 1985 was the Kalevala. In the issue composers and researchers like Pekka Lounela, Eero Tarasti, Erkki Salmenhaa},
  howpublished = {https://fmq.fi/articles/kalevala-the-estonian-perspective},
  langid = {american},
  file = {/Users/sarah/Zotero/storage/CJYNVPEP/kalevala-the-estonian-perspective.html}
}

@inproceedings{karunatilakeTraditionalFolkMelody2012,
  title = {Traditional and Folk Melody Classifier on Culture Style Using {{Markov}} Models and Neural Networks},
  booktitle = {Proceedings of the 2012 {{Joint International Conference}} on {{Human-Centered Computer Environments}}},
  author = {Karunatilake, Chamila and Nishimura, Satoshi and Osano, Minetada},
  year = {2012},
  month = mar,
  series = {{{HCCE}} '12},
  pages = {203--207},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2160749.2160791},
  abstract = {Music plays a vital role in any culture despite whether it is primary or modern and it is a good indicator reflecting the nature of the culture where it has been produced. Music traditions were developed even in the pre-historic periods when people did not have a proper method of documentation and scores of music. Melodies of different culture styles exhibit immense differences. Analyzing those differences is essential in various fields particularly ethnomusicology which studies non-western music based on cultural context. This paper presents an attempt of culture based melody classification using pitch. With respect to that, a prototype has been developed in Java, which utilizes a Markov chains and Neural Networks. Experiments were conducted with several datasets which were chosen from the traditional music styles such as Indian and Japanese.},
  isbn = {978-1-4503-1191-5},
  keywords = {culture-based music classification,Kohonen self organizing maps,Markov models},
  file = {/Users/sarah/Zotero/storage/QE87LMWJ/Karunatilake et al. - 2012 - Traditional and folk melody classifier on culture .pdf}
}

@article{keerstockClearSpeechImproves2019,
  title = {Clear {{Speech Improves Listeners}}' {{Recall}}},
  author = {Keerstock, Sandie and Smiljanic, Rajka},
  year = {2019},
  month = dec,
  journal = {The Journal of the Acoustical Society of America},
  volume = {146},
  number = {6},
  pages = {4604--4610},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.5141372},
  abstract = {The present study examined the effect of intelligibility-enhancing clear speech on listeners' recall. Native (n\textbackslash,=\textbackslash,57) and non-native (n\textbackslash,=\textbackslash,31) English listeners heard meaningful sentences produced in clear and conversational speech, and then completed a cued-recall task. Results showed that listeners recalled more words from clearly produced sentences. Sentence-level analysis revealed that listening to clear speech increased the odds of recalling whole sentences and decreased the odds of erroneous and omitted responses. This study showed that the clear speech benefit extends beyond word- and sentence-level recognition memory to include deeper linguistic encoding at the level of syntactic and semantic information.}
}

@article{keerstockEffectsIntelligibilityCrossModal2018,
  title = {Effects of {{Intelligibility}} on {{Within-}} and {{Cross-Modal Sentence Recognition Memory}} for {{Native}} and {{Non-Native Listeners}}},
  author = {Keerstock, Sandie and Smiljani{\'c}, Rajka},
  year = {2018},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {144},
  number = {5},
  pages = {2871--2881},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.5078589},
  abstract = {The goal of the study was to examine whether enhancing the clarity of the speech signal through conversational-to-clear speech modifications improves sentence recognition memory for native and non-native listeners, and if so, whether this effect would hold when the stimuli in the test phase are presented in orthographic instead of auditory form (cross-modal presentation). Sixty listeners (30 native and 30 non-native English) participated in a within-modal (i.e., audio-audio) sentence recognition memory task (Experiment I). Sixty different individuals (30 native and 30 non-native English) participated in a cross-modal (i.e., audio-textual) sentence recognition memory task (Experiment II). The results showed that listener-oriented clear speech enhanced sentence recognition memory for both listener groups regardless of whether the acoustic signal was present during the test phase (Experiment I) or absent (Experiment II). Compared to native listeners, non-native listeners had longer reaction times in the within-modal task and were overall less accurate in the cross-modal task. The results showed that more cognitive resources remained available for storing information in memory during processing of easier-to-understand clearly produced sentences. Furthermore, non-native listeners benefited from signal clarity in sentence recognition memory despite processing speech signals in a cognitively more demanding second language.}
}

@article{keerstockReadingAloudClear2019,
  title = {Reading {{Aloud}} in a {{Clear Speaking Style May Interfere}} with {{Sentence Recognition Memory}}},
  author = {Keerstock, Sandie and Smiljanic, Rajka},
  year = {2019},
  month = mar,
  journal = {The Journal of the Acoustical Society of America},
  volume = {145},
  number = {3},
  pages = {1911--1911},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.5101936}
}

@article{keesomSilenceSolitudeSerotonin2020,
  title = {Silence, {{Solitude}}, and {{Serotonin}}: {{Neural Mechanisms Linking Hearing Loss}} and {{Social Isolation}}},
  shorttitle = {Silence, {{Solitude}}, and {{Serotonin}}},
  author = {Keesom, Sarah M. and Hurley, Laura M.},
  year = {2020},
  month = jun,
  journal = {Brain Sciences},
  volume = {10},
  number = {6},
  pages = {367},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/brainsci10060367},
  abstract = {For social animals that communicate acoustically, hearing loss and social isolation are factors that independently influence social behavior. In human subjects, hearing loss may also contribute to objective and subjective measures of social isolation. Although the behavioral relationship between hearing loss and social isolation is evident, there is little understanding of their interdependence at the level of neural systems. Separate lines of research have shown that social isolation and hearing loss independently target the serotonergic system in the rodent brain. These two factors affect both presynaptic and postsynaptic measures of serotonergic anatomy and function, highlighting the sensitivity of serotonergic pathways to both types of insult. The effects of deficits in both acoustic and social inputs are seen not only within the auditory system, but also in other brain regions, suggesting relatively extensive effects of these deficits on serotonergic regulatory systems. Serotonin plays a much-studied role in depression and anxiety, and may also influence several aspects of auditory cognition, including auditory attention and understanding speech in challenging listening conditions. These commonalities suggest that serotonergic pathways are worthy of further exploration as potential intervening mechanisms between the related conditions of hearing loss and social isolation, and the affective and cognitive dysfunctions that follow.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {auditory,communication,hearing loss,serotonin,social buffering,social isolation},
  file = {/Users/sarah/Zotero/storage/HVUIMT9V/Keesom and Hurley - 2020 - Silence, Solitude, and Serotonin Neural Mechanism.pdf;/Users/sarah/Zotero/storage/JDQ66JBA/367.html}
}

@article{keltererPhonationTypeContrasts2020,
  title = {Phonation {{Type Contrasts}} and {{Tone}} in {{Chichimec}}},
  author = {Kelterer, Anneliese and Schuppler, Barbara},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {3043--3059},
  issn = {0001-4966},
  doi = {10.1121/10.0001015},
  langid = {english}
}

@article{keoughCrossModalEffectsSpeech2019,
  title = {Cross-{{Modal Effects}} in {{Speech Perception}}},
  author = {Keough, Megan and Derrick, Donald and Gick, Bryan},
  year = {2019},
  journal = {Annual Review of Linguistics},
  volume = {5},
  number = {1},
  pages = {49--66},
  doi = {10.1146/annurev-linguistics-011718-012353},
  abstract = {Speech research during recent years has moved progressively away from its traditional focus on audition toward a more multisensory approach. In addition to audition and vision, many somatosenses including proprioception, pressure, vibration, and aerotactile sensation are all highly relevant modalities for experiencing and/or conveying speech. In this article, we review both long-standing cross-modal effects stemming from decades of audiovisual speech research and new findings related to somatosensory effects. Cross-modal effects in speech perception to date have been found to be constrained by temporal congruence and signal relevance, but appear to be unconstrained by spatial congruence. The literature reveals that, far from taking place in a one-, two-, or even three-dimensional space, speech occupies a highly multidimensional sensory space. We argue that future research in cross-modal effects should expand to consider each of these modalities both separately and in combination with other modalities in speech.}
}

@article{kewley-portContributionConsonantVowel2007,
  title = {Contribution of {{Consonant}} versus {{Vowel Information}} to {{Sentence Intelligibility}} for {{Young Normal-Hearing}} and {{Elderly Hearing-Impaired Listeners}}},
  author = {{Kewley-Port}, Diane and Burkle, T. Zachary and Lee, Jae Hee},
  year = {2007},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {122},
  number = {4},
  pages = {2365--2375},
  issn = {0001-4966},
  doi = {10.1121/1.2773986},
  keywords = {Auditory Perception,hearing impairment,sentence,SGPL1 wt Allele}
}

@article{kewley-portContributionConsonantVowel2007a,
  title = {Contribution of {{Consonant}} versus {{Vowel Information}} to {{Sentence Intelligibility}} for {{Young Normal-Hearing}} and {{Elderly Hearing-Impaired Listeners}}},
  author = {{Kewley-Port}, Diane and Burkle, T. Zachary and Lee, Jae Hee},
  year = {2007},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {122},
  number = {4},
  pages = {2365--2375},
  issn = {0001-4966},
  doi = {10.1121/1.2773986},
  abstract = {The purpose of this study was to examine the contribution of information provided by vowels versus consonants to sentence intelligibility in young normal-hearing (YNH) and typical elderly hearing-impaired (EHI) listeners. Sentences were presented in three conditions, unaltered or with either the vowels or the consonants replaced with speech shaped noise. Sentences from male and female talkers in the TIMIT database were selected. Baseline performance was established at a 70dB70dB\${$<\$$}math display="inline" overflow="scroll" altimg="eq-00001.gif"\${$><\$$}mrow\${$><\$$}mn\${$>\$$}70\${$<\$$}/mn\${$><\$$}mspace width="0.3em"\${$><\$$}/mspace\${$><\$$}mi\${$>\$$}dB\${$<\$$}/mi\${$><\$$}/mrow\${$><\$$}/math\${$>\$$} SPL level using YNH listeners. Subsequently EHI and YNH participants listened at 95dB95dB\${$<\$$}math display="inline" overflow="scroll" altimg="eq-00002.gif"\${$><\$$}mrow\${$><\$$}mn\${$>\$$}95\${$<\$$}/mn\${$><\$$}mspace width="0.3em"\${$><\$$}/mspace\${$><\$$}mi\${$>\$$}dB\${$<\$$}/mi\${$><\$$}/mrow\${$><\$$}/math\${$>\$$} SPL. Participants listened to each sentence twice and were asked to repeat the entire sentence after each presentation. Words were scored correct if identified exactly. Average performance for unaltered sentences was greater than 94\%. Overall, EHI listeners performed more poorly than YNH listeners. However, vowel-only sentences were always significantly more intelligible than consonant-only sentences, usually by a ratio of 2:1 across groups. In contrast to written English or words spoken in isolation, these results demonstrated that for spoken sentences, vowels carry more information about sentence intelligibility than consonants for both young normal-hearing and elderly hearing-impaired listeners.}
}

@article{kimProsodicBoundaryInformation2013,
  title = {Prosodic {{Boundary Information Modulates Phonetic Categorization}}},
  author = {Kim, Sahyang and Cho, Taehong},
  year = {2013},
  month = jun,
  journal = {The Journal of the Acoustical Society of America},
  volume = {134},
  number = {1},
  pages = {EL19-EL25},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.4807431},
  abstract = {Categorical perception experiments were performed on an English /b-p/ voice onset time (VOT) continuum with native (American English) and non-native (Korean) listeners to examine whether and how phonetic categorization is modulated by prosodic boundary and language experience. Results demonstrated perceptual shifting according to prosodic boundary strength: A longer VOT was required to identify a sound as /p/ after an intonational phrase than a word boundary, regardless of the listeners' language experience. This suggests that segmental perception is modulated by the listeners' computation of an abstract prosodic structure reflected in phonetic cues of phrase-final lengthening and domain-initial strengthening, which are common across languages.}
}

@article{krakowPhysiologicalOrganizationSyllables1999,
  title = {Physiological {{Organization}} of {{Syllables}}: {{A Review}}},
  author = {Krakow, Rena A.},
  year = {1999},
  journal = {Journal of Phonetics},
  volume = {27},
  number = {1},
  pages = {23--54},
  issn = {0095-4470},
  doi = {10.1006/jpho.1999.0089},
  abstract = {The notion that the syllable is a unit of articulatory organization has long had intuitive appeal, although a series of studies spanning more than two decades failed to support this hypothesis (cf. Stetson, 1951; Draper, Ladefoged \& Whitteridge, 1959; Kozhevenikov \& Chistovich, 1965; Gay, 1978; Kent \& Minifie, 1977; Harris \& Bell-Berti, 1984). More recently, however, a new approach to this issue \textendash{} one that considers syllables to be characteristic patterns of articulatory organization (Krakow, 1989; Browman \& Goldstein, 1995) \textendash{} has provided new insights into the nature of syllable organization in speech. This paper reviews the relevant physiological investigations in the literature and presents new data, which together serve to demonstrate that the syllable is, at its core, a physiological unit. The relation between such evidence and phonological patterns is discussed, including cross-language distributional differences between syllable-initial and syllable-final consonants, as well as such notions as ambisyllabicity and resyllabification.}
}

@article{krauseInvestigatingAlternativeForms2002,
  title = {Investigating {{Alternative Forms}} of {{Clear Speech}}: {{The Effects}} of {{Speaking Rate}} and {{Speaking Mode}} on {{Intelligibility}}},
  shorttitle = {Investigating {{Alternative Forms}} of {{Clear Speech}}},
  author = {Krause, Jean C. and Braida, Louis D.},
  year = {2002},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {112},
  number = {5},
  pages = {2165--2172},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.1509432}
}

@article{krullFOOTISOCHRONYESTONIAN1999,
  title = {{{FOOT ISOCHRONY IN ESTONIAN}}},
  author = {Krull, Diana},
  year = {1999},
  pages = {4},
  abstract = {The duration of Estonian disyllabic feet varies relatively little with the three degrees of quantity. This is due to the duration distribution between the syllables: the first syllable increases with the degree of quantity and the second decreases. The amount of isochrony varies with speaking style: in conversational speech, foot duration is more dependent on the degree of quantity than in list reading. Moreover, in list reading the difference in foot duration between short and long quantity is greater than between long and overlong. The present paper shows that in conversational speech this is true only for words where the bearer of the quantity contrast is a vowel and the F0 contour can constitute an additional cue to overlong quantity. In words where the bearer of the quantity contrast is a consonant, the difference in foot duration is largest between long and overlong quantity. The rhythmic pattern in oral production of poetry is similar to that of conversational speech.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/CRRCIT2S/Krull - FOOT ISOCHRONY IN ESTONIAN.pdf}
}

@article{kuznetsovaEstonianWordProsody2018,
  title = {Estonian {{Word Prosody}} on the {{Procrustean Bed}} of {{Morae}}: {{Eesti}} S\~onaprosoodia Moorade {{Prokrustese}} S\"angis.},
  shorttitle = {Estonian {{Word Prosody}} on the {{Procrustean Bed}} of {{Morae}}},
  author = {Kuznetsova, Natalia},
  year = {2018},
  month = jan,
  journal = {\cyrchar\CYREREV\cyrchar\cyrs\cyrchar\cyrt\cyrchar\cyro\cyrchar\cyrn\cyrchar\cyrs\cyrchar\cyrk\cyrchar\cyra\cyrchar\cyrya{} \cyrchar\cyrs\cyrchar\cyrl\cyrchar\cyro\cyrchar\cyrv\cyrchar\cyre\cyrchar\cyrs\cyrchar\cyrn\cyrchar\cyra\cyrchar\cyrya{} \cyrchar\cyrp\cyrchar\cyrr\cyrchar\cyro\cyrchar\cyrs\cyrchar\cyro\cyrchar\cyrd\cyrchar\cyri\cyrchar\cyrya{} \cyrchar\cyrv{} \cyrchar\CYRP\cyrchar\cyrr\cyrchar\cyro\cyrchar\cyrk\cyrchar\cyrr\cyrchar\cyru\cyrchar\cyrs\cyrchar\cyrt\cyrchar\cyro\cyrchar\cyrv\cyrchar\cyro\cyrchar\cyrm{} \cyrchar\cyrl\cyrchar\cyro\cyrchar\cyrzh\cyrchar\cyre{} \cyrchar\cyrm\cyrchar\cyro\cyrchar\cyrr},
  volume = {9},
  number = {1},
  pages = {209--244},
  publisher = {{University of Tartu Press}},
  issn = {17368987},
  doi = {10.12697/jeful.2018.9.1.09},
  abstract = {The paper analyses existing moraic conceptions of Estonian quantity. Main features of functional, generative and phonetically-instructed moraic accounts of Estonian are considered. In most generative accounts, morae simultaneously represent several layers of functionally and structurally diverse information. This brings along a considerable increase in formal analytical machinery and internal controversies. In a structural functional framework, morae can be used to formalise the prosodic contrast of long and short stressed syllables in Estonian. Its relevance is seen in actual functioning of the prosodic system. This contrast is built upon the segmental contrast of short and long phonemes and, in turn, serves as a basis for the contrast of two distinctive foot accents, light and heavy. As an example, a formal morphonological algorithm of calculating Estonian foot accents, which also shows the place of the syllable weight contrast, is proposed. (English)},
  keywords = {ACCENTS \& accentuation,autosegmentaalne fonoloogia,autosegmental phonology,eesti keel,Estonian,moora,MOORE language,mora,PHONEME (Linguistics),PROSODIC analysis (Linguistics),quantity,sõnaprosoodia,structural functional phonology,strukturaal-funktsionaalne fonoloogia,välted,VERSIFICATION,word prosody,автосегментная фонология,количество,мора,словесная просодия,структурная функциональная фонология,эстонский},
  file = {/Users/sarah/Zotero/storage/GFHSITGH/Kuznetsova - 2018 - Estonian Word Prosody on the Procrustean Bed of Mo.pdf}
}

@article{lawrenceVeljoTormisEstonian,
  title = {Veljo {{Tormis}}, {{Estonian Composer}}},
  author = {Lawrence, Mark Richard},
  pages = {237},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/CB9XXUWZ/Lawrence - Veljo Tormis, Estonian Composer.pdf}
}

@article{leaSweetSilentThought2008,
  title = {Sweet {{Silent Thought}}: {{Alliteration}} and {{Resonance}} in {{Poetry Comprehension}}},
  shorttitle = {Sweet {{Silent Thought}}},
  author = {Lea, R. Brooke and Rapp, David N. and Elfenbein, Andrew and Mitchel, Aaron D. and Romine, Russell Swinburne},
  year = {2008},
  month = jul,
  journal = {Psychological Science},
  volume = {19},
  number = {7},
  pages = {709--716},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2008.02146.x},
  abstract = {Poetic devices like alliteration can heighten readers' aesthetic experiences and enhance poets' recall of their epic pieces. The effects of such devices on memory for and appreciation of poetry are well known; however, the mechanisms underlying these effects are not yet understood. We used current theories of language comprehension as a framework for understanding how alliteration affects comprehension processes. Across three experiments, alliterative cues reactivated readers' memories for previous information when it was phonologically similar to the cue. These effects were obtained when participants read aloud and when they read silently, and with poetry and prose. The results support everyday intuitions about the effects of poetry and aesthetics, and explain the nature of such effects. These findings extend the scope of general memory models by indicating their capacity to explain the influence of nonsemantic discourse features.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/IDBG6ULL/Lea et al. - 2008 - Sweet Silent Thought Alliteration and Resonance i.pdf}
}

@article{lehisteFunctionQuantityFinnish1965,
  title = {The {{Function}} of {{Quantity}} in {{Finnish}} and {{Estonian}}},
  author = {Lehiste, Ilse},
  year = {1965},
  month = jul,
  journal = {Language},
  volume = {41},
  number = {3},
  pages = {447},
  issn = {00978507},
  doi = {10.2307/411787},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/NY3FXQ7S/Lehiste - 1965 - The Function of Quantity in Finnish and Estonian.pdf}
}

@article{libermanStressLinguisticRhythm1977,
  title = {On {{Stress}} and {{Linguistic Rhythm}}},
  author = {Liberman, Mark and Prince, Alan},
  year = {1977},
  journal = {Linguistic Inquiry},
  volume = {8},
  number = {2},
  pages = {249--336},
  publisher = {{The MIT Press}},
  issn = {0024-3892}
}

@incollection{lindblomExplainingPhoneticVariation1990,
  title = {Explaining {{Phonetic Variation}}: {{A Sketch}} of the {{H}}\&{{H Theory}}},
  shorttitle = {Explaining {{Phonetic Variation}}},
  booktitle = {Speech {{Production}} and {{Speech Modelling}}},
  author = {Lindblom, B.},
  editor = {Hardcastle, William J. and Marchal, Alain},
  year = {1990},
  series = {{{NATO ASI Series}}},
  pages = {403--439},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-009-2037-8_16},
  abstract = {The H\&H theory is developed from evidence showing that speaking and listening are shaped by biologically general processes. Speech production is adaptive. Speakers can, and typically do, tune their performance according to communicative and situational demands, controlling the interplay between production-oriented factors on the one hand, and output-oriented constraints on the other. For the ideal speaker, H\&H claims that such adaptations reflect his tacit awareness of the listener's access to sources of information independent of the signal and his judgement of the short-term demands for explicit signal information. Hence speakers are expected to vary their output along a continuum of hyper- and hypospeech. The theory suggests that the lack of invariance that speech signals commonly exhibit (Perkell and Klatt 1986) is a direct consequence of this adaptive organization (cf MacNeilage 1970). Accordingly, in the H\&H program the quest for phonetic invariance is replaced by another research task: Explicating the notion of sufficient discriminability and defining the class of speech signals that meet that criterion.},
  isbn = {978-94-009-2037-8},
  langid = {english},
  keywords = {Speech Perception,Speech Production,Speech Signal,Stimulus Word,Vocal Tract}
}

@article{lingUantitativeCharacterizationsSpeech2000,
  title = {Q Uantitative {{Characterizations}} of {{Speech Rhythm}}: {{Syllable-Timing}} in {{Singapore English}}},
  shorttitle = {Q Uantitative {{Characterizations}} of {{Speech Rhythm}}},
  author = {Ling, Low Ee and Grabe, Esther and Nolan, Francis},
  year = {2000},
  month = dec,
  journal = {Language and Speech},
  volume = {43},
  number = {4},
  pages = {377--401},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/00238309000430040301},
  abstract = {British English and Singapore English are said to differ in rhythmic patterning. British English is commonly described as stress-timed, but Singapore English is claimed to be syllable-timed. In the present paper, we explore the acoustic nature of the suggested cross-varietal difference. In directly comparable samples from British English and Singapore English, two types of acoustic measurements were taken; we calculateda variability index reflecting changes in vowel length over utterances, and measurements reflecting vowel quality. Our findings provide acoustic data which support the hypothesized crossvarietal difference in rhythmic patterning; we show(1) that successive vowel durations are more nearly equal in Singapore English than in British English, and(2) that reduced vowels pattern more peripherally in the F1/F2 formant space in Singapore English than in British English. We complete the paper with a comparison of our vowel variability index with a set of acoustic measures for rhythm proposed by Ramus, Nespor, and Mehler(1999), which focus on variability in vocalic and intervocalic intervals. We conclude that our variability index is more successful in capturing rhythmic differences than Ramus et al. (1999)'s measures, and that an application of our index to Ramus et al.'s intervocalic measure may provide a further diagnostic of rhythmic class.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/QFW3TURG/Ling et al. - 2000 - Q uantitative Characterizations of Speech Rhythm .pdf}
}

@article{lippusAcousticStudyEstonian2014,
  title = {An Acoustic Study of {{Estonian}} Word Stress},
  author = {Lippus, P{\"a}rtel and Asu, Eva Liina and Kalvik, Mari-Liis},
  year = {2014},
  journal = {Proc. Speech Prosody 2014},
  pages = {232--235}
}

@article{lloydLoudnessPureTones1947,
  title = {The {{Loudness}} of {{Pure Tones}}},
  author = {Lloyd, Llewelyn S.},
  year = {1947},
  journal = {The Musical Quarterly},
  volume = {33},
  number = {4},
  pages = {481--489},
  issn = {0027-4631}
}

@misc{LogicPro,
  title = {Logic {{Pro}}},
  journal = {Apple},
  abstract = {Logic~Pro~is a complete professional recording studio on the Mac. And it has everything musicians need to go from first note to final master.},
  howpublished = {https://www.apple.com/logic-pro/},
  langid = {american},
  file = {/Users/sarah/Zotero/storage/Q6TWIZVA/logic-pro.html}
}

@article{lucePhonotacticsDensityEntropy2001,
  title = {Phonotactics, {{Density}}, and {{Entropy}} in {{Spoken Word Recognition}}},
  author = {Luce, Paul A. and Large, Nathan R.},
  year = {2001},
  month = oct,
  journal = {Language and Cognitive Processes},
  volume = {16},
  number = {5-6},
  pages = {565--581},
  publisher = {{Routledge}},
  issn = {0169-0965},
  doi = {10.1080/01690960143000137},
  abstract = {Previous research has demonstrated that increases in phonotactic probability facilitate spoken word processing, whereas increased competition among lexical representations is often associated with slower and less accurate recognition. We examined the combined effects of probabilistic phonotactics and lexical competition by generating words and nonwords that varied orthogonally on phonotactics and similarity neighbourhood density. The results from a speeded same-different task revealed simultaneous facilitative effects of phonotactics and inhibitory effects of lexical competition for real word stimuli. However, the nonword stimuli produced an apparently anomalous pattern of results. In a subsequent experiment, we identified the source of this anomaly by estimating behaviourally the specific lexical competitors activated by our nonwords. Our results suggest that, under specific circumstances, neighbourhood density and probabilistic phonotactics may combine to produce non-additive or synergistic effects of lexical competition on processing times.}
}

@article{luceRecognizingSpokenWords1998,
  title = {Recognizing {{Spoken Words}}: {{The Neighborhood Activation Model}}},
  shorttitle = {Recognizing {{Spoken Words}}},
  author = {Luce, Paul A. and Pisoni, David B.},
  year = {1998},
  month = feb,
  journal = {Ear Hear},
  volume = {19},
  number = {1},
  pages = {1--36},
  issn = {0196-0202},
  abstract = {Objective A fundamental problem in the study of human spoken word recognition concerns the structural relations among the sound patterns of words in memory and the effects these relations have on spoken word recognition. In the present investigation, computational and experimental methods were employed to address a number of fundamental issues related to the representation and structural organization of spoken words in the mental lexicon and to lay the groundwork for a model of spoken word recognition. Design Using a computerized lexicon consisting of transcriptions of 20,000 words, similarity neighborhoods for each of the transcriptions were computed. Among the variables of interest in the computation of the similarity neighborhoods were: 1) the number of words occurring in a neighborhood, 2) the degree of phonetic similarity among the words, and 3) the frequencies of occurrence of the words in the language. The effects of these variables on auditory word recognition were examined in a series of behavioral experiments employing three experimental paradigms: perceptual identification of words in noise, auditory lexical decision, and auditory word naming. Results The results of each of these experiments demonstrated that the number and nature of words in a similarity neighborhood affect the speed and accuracy of word recognition. A neighborhood probability rule was developed that adequately predicted identification performance. This rule, based on choice rule, combines stimulus word intelligibility, neighborhood confusability, and frequency into a single expression. Based on this rule, a model of auditory word recognition, the neighborhood activation model, was proposed. This model describes the effects of similarity neighborhood structure on the process of discriminating among the acoustic-phonetic representations of words in memory. The results of these experiments have important implications for current conceptions of auditory word recognition in normal and hearing impaired populations of children and adults.},
  pmcid = {PMC3467695},
  pmid = {9504270}
}

@article{luceRecognizingSpokenWords1998a,
  title = {Recognizing {{Spoken Words}}: {{The Neighborhood Activation Model}}},
  shorttitle = {Recognizing {{Spoken Words}}},
  author = {Luce, Paul A. and Pisoni, David B.},
  year = {1998},
  month = feb,
  journal = {Ear and Hearing},
  volume = {19},
  number = {1},
  pages = {1},
  issn = {0196-0202},
  abstract = {Objective: A fundamental problem in the study of human spoken word recognition concerns the structural relations among the sound patterns of words in memory and the effects these relations have on spoken word recognition. In the present investigation, computational and experimental methods were employed to address a number of fundamental issues related to the representation and structural organization of spoken words in the mental lexicon and to lay the groundwork for a model of spoken word recognition. Design: Using a computerized lexicon consisting of transcriptions of 20,000 words, similarity neighborhoods for each of the transcriptions were computed. Among the variables of interest in the computation of the similarity neighborhoods were: 1) the number of words occurring in a neighborhood, 2) the degree of phonetic similarity among the words, and 3) the frequencies of occurrence of the words in the language. The effects of these variables on auditory word recognition were examined in a series of behavioral experiments employing three experimental paradigms: perceptual identification of words in noise, auditory lexical decision, and auditory word naming. Results: The results of each of these experiments demonstrated that the number and nature of words in a similarity neighborhood affect the speed and accuracy of word recognition. A neighborhood probability rule was developed that adequately predicted identification performance. This rule, based onLuce's (1959) choice rule, combines stimulus word intelligibility, neighborhood confusability, and frequency into a single expression. Based on this rule, a model of auditory word recognition, the neighborhood activation model, was proposed. This model describes the effects of similarity neighborhood structure on the process of discriminating among the acoustic-phonetic representations of words in memory. The results of these experiments have important implications for current conceptions of auditory word recognition in normal and hearing impaired populations of children and adults.},
  langid = {american}
}

@article{lundenDurationVowelQuality2017,
  title = {Duration, Vowel Quality, and the Rhythmic Pattern of {{English}}},
  author = {Lunden, Anya},
  year = {2017},
  month = nov,
  journal = {Laboratory Phonology},
  volume = {8},
  number = {1},
  doi = {10.5334/labphon.37},
  abstract = {Languages with binary stress systems frequently tolerate a stress lapse over the final two syllables, but almost none tolerate a word-initial stress lapse. Lunden (to appear) argues that this lapse asymmetry can be explained by the presence of word-level final lengthening, which can then create the perception of prominence alternation in languages that use duration as stress correlate. The results of a production and a perception study with English speakers are presented which compare /ɑ/s that occur under stress lapse to /ɑ/s in non-stress-lapse positions. While word-final unstressed /ɑ/ is always longer than non-final unstressed /ɑ/, it is significantly longer when immediately following an unstressed syllable. Similarly, unstressed word-final /ɑ/ has a higher F1 and lower F2 than non-final unstressed /ɑ/, but word-finally this less-reduced vowel is closer to a full vowel when the final syllable is part of a stress lapse. The perception study finds that these differences have perceptual consequences that can lead to a perceived continued rhythm in stress lapse. The phonetic differences explain why a word-final unstressed vowel can be perceived as relatively strong when following an unstressed syllable but as relatively weak when following a stressed syllable.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/NN2RGIDZ/Lunden - 2017 - Duration, vowel quality, and the rhythmic pattern .pdf;/Users/sarah/Zotero/storage/77D6Y9E7/6214.html}
}

@article{lundenPhoneticallyMotivatedPhonologicalAnalysis2010,
  title = {A {{Phonetically-Motivated Phonological Analysis}} of {{Syllable Weight}} and {{Stress}} in the {{Norwegian Language}}.},
  author = {Lunden, Anya},
  year = {2010},
  journal = {Edwin Mellen Press}
}

@article{lundenReanalyzingFinalConsonant2013,
  title = {Reanalyzing {{Final Consonant Extrametricality}}},
  author = {Lunden, Anya},
  year = {2013},
  month = apr,
  journal = {J Comp German Linguistics},
  volume = {16},
  number = {1},
  pages = {1--31},
  issn = {1572-8552},
  doi = {10.1007/s10828-013-9053-3},
  abstract = {Many languages, including Norwegian, exhibit CVC weight asymmetry, where CVC is heavy but behaves as light word-finally. This asymmetry is proposed to be motivated by facts of phonetic length and human perception. A production experiment in Norwegian shows a parallel proportional increase for the rimes of heavy syllables across positions. A theory of weight is advanced in which a syllable shape in a given position is only heavy if it is, on average, sufficiently proportionally longer than the rime of a CV syllable in the same position. While a CVC syllable reaches this proportional increase threshold non-finally, it fails to do so word-finally. Final lengthening affects word-final syllables, causing there to be a smaller proportional increase between the rime of a final CV and final CVC. A further study finds perception to behave as predicted; that is, larger raw increases are needed to reach a sufficient length for word final syllables to be categorized as heavy. The proportional increase theory of weight provides a phonetically and perceptually motivated explanation for CVC weight asymmetry.},
  langid = {english}
}

@article{lundenSyllableWeightDuration2017,
  title = {Syllable Weight and Duration: {{A}} Rhyme/Intervals Comparison},
  shorttitle = {Syllable Weight and Duration},
  author = {Lunden, Anya},
  year = {2017},
  month = jun,
  journal = {Proceedings of the Linguistic Society of America},
  volume = {2},
  number = {0},
  pages = {33-1--12},
  issn = {2473-8689},
  doi = {10.3765/plsa.v2i0.4084},
  abstract = {Steriade (2012) proposed intervals as a more appropriate syllable weight domain than rhymes. This study explores how interval weight cashes out as duration across word positions and compares this to a rhyme-based account. The data reported on in Lunden (2013), from native speakers of Norwegian (a language in which (C)VC syllables are heavy only non-finally) is reanalyzed with intervals. Lunden found that syllable rhymes in all three positions, if taken as a percentage of the average V rhyme in that word position, fell into a coherent pattern for weight. It is shown that interval durations allow for a similar, albeit less robust, pattern. The data from Lunden's (2013) perception experiment that tested the correlation between increased vowel duration and listeners' classification of syllable weight is also recast with interval durations, and the importance of the proportional increase over the raw increase, originally found for the rhyme data, is found to hold for the interval data. Thus, taking intervals as the weight domain is shown to result in reasonable durational relations between interval weights, although interval durations show less separation between some light and heavy units than the rhyme durations do.},
  copyright = {Copyright (c) 2017 Anya Lunden},
  langid = {english},
  keywords = {duration,intervals,rhymes,syllable weight},
  file = {/Users/sarah/Zotero/storage/GWXXPAE7/Lunden - 2017 - Syllable weight and duration A rhymeintervals co.pdf}
}

@article{lundenVowellengthContrastsPhonetic2017,
  title = {Vowel-Length Contrasts and Phonetic Cues to Stress: An Investigation of Their Relation*},
  shorttitle = {Vowel-Length Contrasts and Phonetic Cues to Stress},
  author = {Lunden, Anya and Campbell, Jessica and Hutchens, Mark and Kalivoda, Nick},
  year = {2017},
  month = dec,
  journal = {Phonology},
  volume = {34},
  number = {3},
  pages = {565--580},
  publisher = {{Cambridge University Press}},
  issn = {0952-6757, 1469-8188},
  doi = {10.1017/S0952675717000288},
  abstract = {The functional load hypothesis of Berinstein (1979) put forward the idea that languages which use a suprasegmental property (duration, F0) contrastively will not use it to realise stress. The functional load hypothesis is often cited when stress correlates are discussed, both when it is observed that the language under discussion follows the hypothesis and when it fails to follow it. In the absence of a more wide-ranging assessment of how frequently languages do or do not conform to the functional load hypothesis, it is unknown whether it is an absolute, a strong tendency, a weak tendency or unsupported. The results from a database of reported stress correlates and use of contrastive duration for 140 languages are presented and discussed. No support for the functional load hypothesis is found.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/3GW8XG7T/Lunden et al. - 2017 - Vowel-length contrasts and phonetic cues to stress.pdf;/Users/sarah/Zotero/storage/T8I6EWLT/2839919AEA482697DBDAA513EE086D04.html}
}

@article{lundenWeightFinalSyllables,
  title = {The {{Weight}} of {{Final Syllables}} in {{English}}},
  author = {Lunden, S L Anya},
  pages = {9},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/YJ99YBMF/Lunden - The Weight of Final Syllables in English.pdf}
}

@article{maciuszekThereNoItem2019,
  title = {There {{Is No Item}} vs. {{I Wish There Were}} an {{Item}}: {{Implicit Negation Causes False Recall Just}} as {{Well}} as {{Explicit Negation}}},
  shorttitle = {There {{Is No Item}} vs. {{I Wish There Were}} an {{Item}}},
  author = {Maciuszek, J{\'o}zef and Polak, Mateusz and Sekulak, Martyna},
  year = {2019},
  month = apr,
  journal = {PLoS One},
  volume = {14},
  number = {4},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0215283},
  abstract = {When talking about absence, we may express it in a negative statement (using explicit negation e.g. I was not) or in a positive statement (using implicit negation e.g. I wished I were). Previous research has shown that explicitly negated statements may cause false recall\textendash{} negated items may paradoxically be remembered as present. The current study compares false recall caused by implicit and explicit negation. Participants listened to a recording in which some objects were mentioned as present, some as absent, and some not mentioned at all. The absence of objects was expressed using explicit or implicit negation. Participants' recall of the recording was measured either five minutes or one week after exposure to the recording. Results indicate that implicit and explicit negation lead to a nearly identical false recall of negated items. However, items not mentioned in the recording (i.e. neither mentioned nor negated) were more often recognized as present by participants exposed to implicit, rather than explicit negation. We postulate that false recall of negated items could be explained by participants remembering the item itself, but forgetting the context in which it was present (an affirmative or a negative statement), hence objects would be recalled as present just because they were spoken of.},
  pmcid = {PMC6461274},
  pmid = {30978257}
}

@article{maciuszekThereNoItem2019a,
  title = {There {{Is No Item}} vs. {{I Wish There Were}} an {{Item}}: {{Implicit Negation Causes False Recall Just}} as {{Well}} as {{Explicit Negation}}},
  shorttitle = {There {{Is No Item}} vs. {{I Wish There Were}} an {{Item}}},
  author = {Maciuszek, J{\'o}zef and Polak, Mateusz and Sekulak, Martyna},
  year = {2019},
  month = apr,
  journal = {PLOS ONE},
  volume = {14},
  number = {4},
  pages = {e0215283},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0215283},
  abstract = {When talking about absence, we may express it in a negative statement (using explicit negation e.g. I was not) or in a positive statement (using implicit negation e.g. I wished I were). Previous research has shown that explicitly negated statements may cause false recall\textendash{} negated items may paradoxically be remembered as present. The current study compares false recall caused by implicit and explicit negation. Participants listened to a recording in which some objects were mentioned as present, some as absent, and some not mentioned at all. The absence of objects was expressed using explicit or implicit negation. Participants' recall of the recording was measured either five minutes or one week after exposure to the recording. Results indicate that implicit and explicit negation lead to a nearly identical false recall of negated items. However, items not mentioned in the recording (i.e. neither mentioned nor negated) were more often recognized as present by participants exposed to implicit, rather than explicit negation. We postulate that false recall of negated items could be explained by participants remembering the item itself, but forgetting the context in which it was present (an affirmative or a negative statement), hence objects would be recalled as present just because they were spoken of.},
  langid = {english},
  keywords = {Behavior,Cognition,Cognitive psychology,False memories,Language,Memory,Memory recall,Sentence processing}
}

@article{mageeEffectsFaceMasks2020,
  title = {Effects of {{Face Masks}} on {{Acoustic Analysis}} and {{Speech Perception}}: {{Implications}} for {{Peri-Pandemic Protocols}}},
  shorttitle = {Effects of {{Face Masks}} on {{Acoustic Analysis}} and {{Speech Perception}}},
  author = {Magee, Michelle and Lewis, Courtney and Noffs, Gustavo and Reece, Hannah and Chan, Jess C. S. and Zaga, Charissa J. and Paynter, Camille and Birchall, Olga and Rojas Azocar, Sandra and Ediriweera, Angela and Kenyon, Katherine and Caverl{\'e}, Marja W. and Schultz, Benjamin G. and Vogel, Adam P.},
  year = {2020},
  month = dec,
  journal = {The Journal of the Acoustical Society of America},
  volume = {148},
  number = {6},
  pages = {3562--3568},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0002873},
  abstract = {Wearing face masks (alongside physical distancing) provides some protection against infection from COVID-19. Face masks can also change how people communicate and subsequently affect speech signal quality. This study investigated how three common face mask types (N95, surgical, and cloth) affected acoustic analysis of speech and perceived intelligibility in healthy subjects. Acoustic measures of timing, frequency, perturbation, and power spectral density were measured. Speech intelligibility and word and sentence accuracy were also examined using the Assessment of Intelligibility of Dysarthric Speech. Mask type impacted the power distribution in frequencies above 3\textbackslash,kHz for the N95 mask, and above 5\textbackslash,kHz in surgical and cloth masks. Measures of timing and spectral tilt mainly differed with N95 mask use. Cepstral and harmonics to noise ratios remained unchanged across mask type. No differences were observed across conditions for word or sentence intelligibility measures; however, accuracy of word and sentence translations were affected by all masks. Data presented in this study show that face masks change the speech signal, but some specific acoustic features remain largely unaffected (e.g., measures of voice quality) irrespective of mask type. Outcomes have bearing on how future speech studies are run when personal protective equipment is worn.}
}

@article{manningTrainedKeepBeat2016,
  title = {Trained to Keep a Beat: Movement-Related Enhancements to Timing Perception in Percussionists and Non-Percussionists},
  shorttitle = {Trained to Keep a Beat},
  author = {Manning, Fiona C. and Schutz, Michael},
  year = {2016},
  month = jul,
  journal = {Psychological Research},
  volume = {80},
  number = {4},
  pages = {532--542},
  issn = {1430-2772},
  doi = {10.1007/s00426-015-0678-5},
  abstract = {Many studies demonstrate that musicians exhibit superior timing abilities compared to nonmusicians. Here, we investigated how specific musical expertise can mediate the relationship between movement and timing perception. In the present study, a group of highly trained percussionists (n~=~33) and a group of non-percussionists (n~=~33) were tested on their ability to detect temporal deviations of a tone presented after an isochronous sequence. Participants either tapped along with the sequence using a drumstick (movement condition) or listened without tapping (no-movement condition). Although both groups performed significantly better when moving than when listening alone, percussionists gained a greater benefit from tapping when detecting the smallest probe tone delays compared to non-percussionists. This complements both the musical expertise and timing perception literature by demonstrating that percussionists with high levels of training may further capitalize on the benefits of sensorimotor interactions. Surprisingly, percussionists and non-percussionists performed no differently when listening alone, in contrast to other studies examining the role of training in timing abilities. This raises interesting questions about the degree to which percussionists' known expertise in timing may interact with their use of motion when judging rhythmic precision.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/WDZWSU9G/Manning and Schutz - 2016 - Trained to keep a beat movement-related enhanceme.pdf}
}

@article{marascuiloExtensionsSignificanceTest1970,
  title = {Extensions of the {{Significance Test}} for {{One-Parameter Signal Detection Hypotheses}}},
  author = {Marascuilo, Leonard A.},
  year = {1970},
  month = jun,
  journal = {Psychometrika},
  volume = {35},
  number = {2},
  pages = {237--243},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02291265},
  langid = {english}
}

@article{marshallEffectsWordPosition2009,
  title = {Effects of {{Word Position}} and {{Stress}} on {{Onset Cluster Production}}: {{Evidence}} from {{Typical Development}}, {{Specific Language Impairment}}, and {{Dyslexia}}},
  shorttitle = {Effects of {{Word Position}} and {{Stress}} on {{Onset Cluster Production}}},
  author = {Marshall, Chloe R. and {van der Lely}, Heather K. J.},
  year = {2009},
  journal = {Language},
  volume = {85},
  number = {1},
  pages = {39--57},
  issn = {0097-8507},
  abstract = {Children with specific language impairment (SLI) and dyslexia have phonological deficits that are claimed to cause their language and literacy impairments and to be responsible for the overlap between the two disorders. Little is known, however, about the phonological grammar of children with SLI and dyslexia, and indeed whether they show differences in phonological development. We designed a nonword repetition task to investigate the impact of word position and stress on the production accuracy of onset clusters. We compared the performance of children with SLI and dyslexia, SLI only, and dyslexia only (mean age eleven), and three groups of typically developing children (aged five, seven, and nine). Analysis of cluster production accuracy revealed that all three clinical groups made significantly more errors on word-medial clusters compared to word-initial clusters. Unstressed clusters were more difficult than stressed clusters for the two dyslexic groups but not the SLI-only group. None of the groups of typically developing children showed an effect of word position or stress on cluster accuracy. All groups, however, created new clusters significantly more frequently in initial than medial positions. These results indicate a difference in phonological grammar in children with SLI and dyslexia that could potentially shed light on the relationship between the two disorders. Furthermore, they indicate that structural position and stress are developmentally independent elements in phonological representations.}
}

@article{marslen-wilsonFunctionalParallelismSpoken1987,
  title = {Functional {{Parallelism}} in {{Spoken Word-Recognition}}},
  author = {{Marslen-Wilson}, William D.},
  year = {1987},
  month = mar,
  journal = {Cognition},
  volume = {25},
  number = {1-2},
  pages = {71--102},
  issn = {00100277},
  doi = {10.1016/0010-0277(87)90005-9},
  abstract = {The process of spoken word-recognition breaks down into three basic functions, of access, selection and integration. Access concerns the mapping of the speech input onto the representations of lexical form, selection concerns the discrimination of the best-fitting match to this input, and integration covers the mapping of syntactic and semantic information at the lexical level onto higher levels of processing. This paper describes two versions of a ``cohort''-based model of these processes, showing how if evolves from a partially interactive model, where access is strictly autonomous but selection is subject to top-down control, to a fully bottom-up model, where context plays no role in the processes of form-based access and selection. Context operates instead at the interface between higher-level representations and information generated on-line about the syntactic and semantic properties of members of the cohort. The new model retains intact the fundamental characteristics of a cohort-based word-recognition process. It embodies the concepts of multiple access and multiple assessment, allowing a maximally efficient recognition process, based on the principle of the contingency of perceptual choice.},
  langid = {english}
}

@article{marslen-wilsonFunctionalParallelismSpoken1987a,
  title = {Functional {{Parallelism}} in {{Spoken Word-Recognition}}},
  author = {{Marslen-Wilson}, William D.},
  year = {1987},
  month = mar,
  journal = {Cognition},
  volume = {25},
  number = {1-2},
  pages = {71--102},
  issn = {00100277},
  doi = {10.1016/0010-0277(87)90005-9},
  abstract = {The process of spoken word-recognition breaks down into three basic functions, of access, selection and integration. Access concerns the mapping of the speech input onto the representations of lexical form, selection concerns the discrimination of the best-fitting match to this input, and integration covers the mapping of syntactic and semantic information at the lexical level onto higher levels of processing. This paper describes two versions of a ``cohort''-based model of these processes, showing how if evolves from a partially interactive model, where access is strictly autonomous but selection is subject to top-down control, to a fully bottom-up model, where context plays no role in the processes of form-based access and selection. Context operates instead at the interface between higher-level representations and information generated on-line about the syntactic and semantic properties of members of the cohort. The new model retains intact the fundamental characteristics of a cohort-based word-recognition process. It embodies the concepts of multiple access and multiple assessment, allowing a maximally efficient recognition process, based on the principle of the contingency of perceptual choice.},
  langid = {english}
}

@article{massaroPhonologicalContextSpeech1983,
  title = {Phonological {{Context}} in {{Speech Perception}}},
  author = {Massaro, Dominic W. and Cohen, Michael M.},
  year = {1983},
  month = jul,
  journal = {Perception \& Psychophysics},
  volume = {34},
  number = {4},
  pages = {338--348},
  issn = {1532-5962},
  doi = {10.3758/BF03203046},
  abstract = {Speech perception can be viewed in terms of the listener's integration of two sources of information: the acoustic features transduced by the auditory receptor system and the context of the linguistic message. The present research asked how these sources were evaluated and integrated in the identification of synthetic speech. A speech continuum between the glide-vowel syllables /ri/ and /li/ was generated by varying the onset frequency of the third formant. Each sound along the continuum was placed in a consonant-cluster vowel syllable after an initial consonant /p/, /t/, /s/, and /v/. In English, both /r/ and /l/ are phonologically admissible following /p/ but are not admissible following /v/. Only /l/ is admissible following /s/ and only /r/ is admissible following /t/. A third experiment used synthetic consonant-cluster vowel syllables in which the first consonant varied between /b/ and /d and the second consonant varied between /l/ and /r/. Identification of synthetic speech varying in both acoustic featural information and phonological context allowed quantitative tests of various models of how these two sources of information are evaluated and integrated in speech perception.},
  langid = {english},
  keywords = {Context Effect,Root Mean Square Deviation,Speech Perception,Speech Sound,Stop Consonant}
}

@phdthesis{mccartneyTernarityBinarity2003,
  title = {Ternarity through Binarity},
  author = {McCartney, Steven James},
  year = {2003},
  abstract = {Ternary stress pattern\textemdash the lapse of more than one syllable between stresses\textemdash have been challenging for metrical stress theory. The existence of a ternary primitive predicts the existence of trisyllabic word minima, trisyllabic reduplicants, and most directly, stress on every third syllable. The alternative to a ternary primitive has its own predictions, such as the systematic skipping of one light syllable between metrical feet. As such, this, too, would predict the systematic occurrence of stress on every third syllable. Most of the world's languages that have stress are binary and show strict alternating rhythm on stress-bearing units, and so these ternary languages are somewhat problematic. This research shows that the predictions borne of a ternary primitive or its binary alternative do not hold. More specifically, that systems widely believed to be ternary are more uniformly identified as binary, with sporadic ternary effects under duress. This is particularly important, because we predict that the existence of those requirements that yield a ternary effect should apply across-the-board in some languages, and this prediction is shown not to hold. Evidence from Finnish, Estonian, and Koniag Alutiiq suggest that both the quantity of the individual syllable in specific contexts as well as the morphological status of certain syllables can be stress-attracting such that a binary rhythmic alternation can be interrupted to the extent that it appears ternary. Additional evidence from Old English and Bani-Hassan Bedouin Arabic, originally thought to be evidence of the binary equivalent of a ternary primitive, are shown to be well-formed binary systems whose sporadic ternary effects are predictable on the basis of requirements we know to hold in other languages. Finally, an examination of Sentani reveals that remaining instances of ternarity are predicted on the basis of the unusual application of requirements known to hold in other languages.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9780496638215},
  langid = {english},
  school = {ProQuest Dissertations Publishing}
}

@article{mcclellandTRACEModelSpeech1986,
  title = {The {{TRACE}} Model of Speech Perception},
  author = {McClelland, James L and Elman, Jeffrey L},
  year = {1986},
  month = jan,
  journal = {Cognitive Psychology},
  volume = {18},
  number = {1},
  pages = {1--86},
  issn = {0010-0285},
  doi = {10.1016/0010-0285(86)90015-0},
  abstract = {We describe a model called the TRACE model of speech perception. The model is based on the principles of interactive activation. Information processing takes place through the excitatory and inhibitory interactions of a large number of simple processing units, each working continuously to update its own activation on the basis of the activations of other units to which it is connected. The model is called the TRACE model because the network of units forms a dynamic processing structure called ``the Trace,'' which serves at once as the perceptual processing mechanism and as the system's working memory. The model is instantiated in two simulation programs. TRACE I, described in detail elsewhere, deals with short segments of real speech, and suggests a mechanism for coping with the fact that the cues to the identity of phonemes vary as a function of context. TRACE II, the focus of this article, simulates a large number of empirical findings on the perception of phonemes and words and on the interactions of phoneme and word perception. At the phoneme level, TRACE II simulates the influence of lexical information on the identification of phonemes and accounts for the fact that lexical effects are found under certain conditions but not others. The model also shows how knowledge of phonological constraints can be embodied in particular lexical items but can still be used to influence processing of novel, nonword utterances. The model also exhibits categorical perception and the ability to trade cues off against each other in phoneme identification. At the word level, the model captures the major positive feature of Marslen-Wilson's COHORT model of speech perception, in that it shows immediate sensitivity to information favoring one word or set of words over others. At the same time, it overcomes a difficulty with the COHORT model: it can recover from underspecification or mispronunciation of a word's beginning. TRACE II also uses lexical information to segment a stream of speech into a sequence of words and to find word beginnings and endings, and it simulates a number of recent findings related to these points. The TRACE model has some limitations, but we believe it is a step toward a psychologically and computationally adequate model of the process of speech perception.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/RD9HAISC/McClelland and Elman - 1986 - The TRACE model of speech perception.pdf;/Users/sarah/Zotero/storage/DIVJXWWJ/0010028586900150.html}
}

@article{mcgurkHearingLipsSeeing1976,
  title = {Hearing {{Lips}} and {{Seeing}}},
  author = {McGurk, H and MacDonald, J.W.},
  year = {1976},
  journal = {Nature},
  langid = {english}
}

@article{mcmurraybobWaitingLexicalAccess2017,
  title = {Waiting for Lexical Access: {{Cochlear}} Implants or Severely Degraded Input Lead Listeners to Process Speech Less Incrementally},
  shorttitle = {Waiting for Lexical Access},
  author = {McMurray, Bob and {Farris-Trimble, Ashley} and Rigler, Hannah},
  year = {2017},
  month = dec,
  journal = {Cognition},
  volume = {169},
  pages = {147--164},
  publisher = {{Elsevier}},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2017.08.013},
  abstract = {Spoken language unfolds over time. Consequently, there are brief periods of ambiguity, when incomplete input can match many possible words. Typical li\ldots},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/E95WE67R/2017 - Waiting for lexical access Cochlear implants or s.pdf;/Users/sarah/Zotero/storage/GKCCYD7X/S0010027717302378.html}
}

@article{mcmurrayGradientEffectsWithinCategory2002,
  title = {Gradient {{Effects}} of {{Within-Category Phonetic Variation}} on {{Lexical Access}}},
  author = {McMurray, Bob and Tanenhaus, Michael K. and Aslin, Richard N.},
  year = {2002},
  month = dec,
  journal = {Cognition},
  volume = {86},
  number = {2},
  pages = {B33-B42},
  issn = {00100277},
  doi = {10.1016/S0010-0277(02)00157-9},
  abstract = {In order to determine whether small within-category differences in voice onset time (VOT) affect lexical access, eye movements were monitored as participants indicated which of four pictures was named by spoken stimuli that varied along a 0\textendash{} 40 ms VOT continuum. Within-category differences in VOT resulted in gradient increases in fixations to cross-boundary lexical competitors as VOT approached the category boundary. Thus, fine-grained acoustic/phonetic differences are preserved in patterns of lexical activation for competing lexical candidates and could be used to maximize the efficiency of on-line word recognition. q 2002 Elsevier Science B.V. All rights reserved.},
  langid = {english}
}

@article{mcphersonTalkingBalafonSambla2019,
  title = {The {{Talking Balafon}} of the {{Sambla}}: {{Grammatical Principles}} and {{Documentary Implications}}},
  shorttitle = {The {{Talking Balafon}} of the {{Sambla}}},
  author = {McPherson, Laura},
  year = {2019},
  journal = {Anthropological Linguistics},
  volume = {60},
  number = {3},
  pages = {255--294},
  issn = {1944-6527},
  doi = {10.1353/anl.2019.0006},
  abstract = {This article makes the case for linguists to take part in the study of musical surrogate languages, where linguistic form is transposed onto music. It draws on the case study of the Sambla balafon, a West African resonator xylophone. Seenku (Northwestern Mande, Samogo), the language of the Sambla people, has a highly complex tonal system, whose four contrastive levels and multiple contour tones are encoded musically in the notes of the balafon, allowing musicians to communicate without ever opening their mouths. I analyze the grammar of the surrogate language and demonstrate its use in both phonological analysis and language documentation.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/846APQLE/McPherson - 2019 - The Talking Balafon of the Sambla Grammatical Pri.pdf}
}

@article{mcphersonTonetuneAssociationTommo2018,
  title = {Tone-Tune Association in {{Tommo So}} ({{Dogon}}) Folk Songs},
  author = {McPherson, Laura and Ryan, Kevin M.},
  year = {2018},
  journal = {Language},
  volume = {94},
  number = {1},
  pages = {119--156},
  issn = {1535-0665},
  doi = {10.1353/lan.2018.0003},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/E8VI23IT/McPherson and Ryan - 2018 - Tone-tune association in Tommo So (Dogon) folk son.pdf}
}

@article{mcqueenPhonologicalAbstractionMental2006,
  title = {Phonological {{Abstraction}} in the {{Mental Lexicon}}},
  author = {McQueen, James M. and Cutler, Anne and Norris, Dennis},
  year = {2006},
  month = nov,
  journal = {Cognitive Science},
  volume = {30},
  number = {6},
  pages = {1113--1126},
  issn = {1551-6709},
  doi = {10.1207/s15516709cog0000_79},
  abstract = {A perceptual learning experiment provides evidence that the mental lexicon cannot consist solely of detailed acoustic traces of recognition episodes. In a training lexical decision phase, listeners h...},
  langid = {english},
  keywords = {Episodic models,Perceptual learning,Phonological abstraction,Speech perception,Spoken-word recognition}
}

@book{MeasuresListeningEffort,
  title = {Measures of {{Listening Effort Are Multidimensional}} : {{Ear}} and {{Hearing}}}
}

@article{mesarosAutomaticRecognitionLyrics2010,
  title = {Automatic {{Recognition}} of {{Lyrics}} in {{Singing}}},
  author = {Mesaros, Annamaria and Virtanen, Tuomas},
  year = {2010},
  journal = {EURASIP Journal on Audio, Speech, and Music Processing},
  volume = {2010},
  pages = {1--11},
  issn = {1687-4714, 1687-4722},
  doi = {10.1155/2010/546047},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/3XDUYDH8/Mesaros and Virtanen - 2010 - Automatic Recognition of Lyrics in Singing.pdf}
}

@article{mesarosAutomaticRecognitionLyrics2010a,
  title = {Automatic {{Recognition}} of {{Lyrics}} in {{Singing}}},
  author = {Mesaros, Annamaria and Virtanen, Tuomas},
  year = {2010},
  journal = {EURASIP Journal on Audio, Speech, and Music Processing},
  volume = {2010},
  pages = {1--11},
  issn = {1687-4714, 1687-4722},
  doi = {10.1155/2010/546047},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/QGBEDY5A/Mesaros and Virtanen - 2010 - Automatic Recognition of Lyrics in Singing.pdf}
}

@article{mesgaraniPhoneticFeatureEncoding2014,
  title = {Phonetic {{Feature Encoding}} in {{Human Superior Temporal Gyrus}}},
  author = {Mesgarani, Nima and Cheung, Connie and Johnson, Keith and Chang, Edward F.},
  year = {2014},
  month = feb,
  journal = {Science},
  volume = {343},
  number = {6174},
  pages = {1006--1010},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1245994},
  abstract = {Deciphering Language Consonants and vowels represent basic building blocks of human language. How their characteristics are extracted from acoustic speech input is not well understood. Directly recording from the superior temporal gyrus of patients as part of their clinical evaluation for epilepsy surgery, Mesgarani et al. (p. 1006, published online 30 January; see the Perspective by Grodzinsky and Nelken) investigated neural responses while the subjects listened to continuous speech. The findings reveal how both vowels and consonants of different phonetic categories are encoded. During speech perception, linguistic elements such as consonants and vowels are extracted from a complex acoustic speech signal. The superior temporal gyrus (STG) participates in high-order auditory processing of speech, but how it encodes phonetic information is poorly understood. We used high-density direct cortical surface recordings in humans while they listened to natural, continuous speech to reveal the STG representation of the entire English phonetic inventory. At single electrodes, we found response selectivity to distinct phonetic features. Encoding of acoustic properties was mediated by a distributed population response. Phonetic features could be directly related to tuning for spectrotemporal acoustic cues, some of which were encoded in a nonlinear fashion or by integration of multiple cues. These findings demonstrate the acoustic-phonetic representation of speech in human STG. The human auditory cortex encodes what speech sounds like. [Also see Perspective by Grodzinsky and Nelken] The human auditory cortex encodes what speech sounds like. [Also see Perspective by Grodzinsky and Nelken]},
  copyright = {Copyright \textcopyright{} 2014, American Association for the Advancement of Science},
  langid = {english},
  pmid = {24482117}
}

@article{mokLanguageSpecificRealizationsSyllable2010,
  title = {Language-{{Specific Realizations}} of {{Syllable Structure}} and {{Vowel-to-Vowel Coarticulation}}},
  author = {Mok, P. K. Peggy},
  year = {2010},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {128},
  number = {3},
  pages = {1346--1356},
  issn = {0001-4966},
  doi = {10.1121/1.3466859},
  abstract = {This paper investigates the effects of syllable structure on vowel-to-vowel (V-to-V) coarticulation using Thai and English data. Languages differ in syllable complexity and their realizations of syllable structure. It was hypothesized that languages with complex syllable structure (English) would allow more V-to-V coarticulation than languages with simple syllable structure (Thai). Onset and coda consonants are different acoustically, articulatorily, typologically and perceptually. Onsets are generally `stronger' and more stable than codas because they are longer, louder, and involve tighter articulatory constrictions. It was hypothesized that closed syllables (that end in a consonant C, i.e., VC\#V) would allow more V-to-V coarticulation than open syllables (V\#CV). /C1V1\#C2V2C1V1\#C2V2\${$<\$$}math display="inline" overflow="scroll" altimg="eq-00001.gif"\${$><\$$}mrow\${$><\$$}msub\${$><\$$}mtext\${$>\$$}C\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}1\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}msub\${$><\$$}mtext\${$>\$$}V\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}1\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}mo\${$>\#<\$$}/mo\${$><\$$}msub\${$><\$$}mtext\${$>\$$}C\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}2\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}msub\${$><\$$}mtext\${$>\$$}V\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}2\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}/mrow\${$><\$$}/math\${$>\$$}/ and /C1V1C2\#V2tC1V1C2\#V2t\${$<\$$}math display="inline" overflow="scroll" altimg="eq-00002.gif"\${$><\$$}mrow\${$><\$$}msub\${$><\$$}mtext\${$>\$$}C\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}1\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}msub\${$><\$$}mtext\${$>\$$}V\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}1\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}msub\${$><\$$}mtext\${$>\$$}C\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}2\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}mo\${$>\#<\$$}/mo\${$><\$$}msub\${$><\$$}mtext\${$>\$$}V\${$<\$$}/mtext\${$><\$$}mn\${$>\$$}2\${$<\$$}/mn\${$><\$$}/msub\${$><\$$}mtext\${$>\$$}t\${$<\$$}/mtext\${$><\$$}/mrow\${$><\$$}/math\${$>\$$}/ sequences were recorded from six native speakers in Thai and six in English. First and second formant frequencies were measured. Results show that English allows more V-to-V coarticulation than Thai regardless of the intervocalic duration and vowel quality difference, but open and closed syllables only affect V-to-V coarticulation minimally. In addition to syllable structure, other possible factors contributing to the language difference in V-to-V coarticulation are discussed.}
}

@article{monsellCompetitorPrimingSpoken1998,
  title = {Competitor {{Priming}} in {{Spoken Word Recognition}}},
  author = {Monsell, Stephen and Hirsh, Katherine W.},
  year = {1998},
  month = nov,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {24},
  number = {6},
  pages = {1495--1520},
  issn = {0278-7393},
  doi = {10.1037/0278-7393.24.6.1495},
  abstract = {Most models predict that priming a word should retard recognition of another sharing its initial sounds. Available short lag priming data do not clearly support the prediction. The authors report 7 continuous lexical-decision experiments with 288 participants. With lags of 1\textendash{} 5 min between prime and probe, response time increased for a monosyllabic word preceded by a word sharing its onset and vowel (but not one sharing its rime) and for a polysyllabic word preceded by another sharing its first syllable. The effect was limited to words primed by words, suggesting that identifying the prime strengthens its lexical attractor, making identification of a lexical neighbor more difficult. With lags of only a few trials, facilitatory effects of phonological similarity or familiarity bias effects were also seen; this may explain why clear evidence for inhibitory priming has been lacking hitherto. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {17–47 yr olds,Adolescent,Adult,Attention,competitor priming in spoken word recognition,Female,Humans,Lexical Decision,lexical decision performance,Male,Mental Recall,Middle Aged,Oral Communication,Paired-Associate Learning,Phonetics,Priming,Reaction Time,Speech Perception,Verbal Learning,Word Recognition}
}

@article{munshiWeightSensitivitySyllable2012,
  title = {Weight {{Sensitivity}} and {{Syllable Codas}} in {{Srinagar Koshur}}},
  author = {MUNSHI, SADAF and CROWHURST, MEGAN J.},
  year = {2012},
  journal = {Journal of Linguistics},
  volume = {48},
  number = {2},
  pages = {427--472},
  issn = {0022-2267},
  abstract = {This paper describes and analyses the pattern of word stress found in the standard dialect of Koshur (Kashmiri) spoken in Srinagar. The significance of Koshur for studies of stress lies in that taken together, its pattern of stress assignment and a pervasive pattern of syncope conspire to produce a four-way syllable weight distinction that has sometimes been expressed as the scale CViC \${$>\$$} CV: \${$>\$$} CVC \${$>\$$} CV. The interesting feature of this type of scale is that closed syllables, CV: C and CVC are preferred as stress peaks over open syllables with vowels of the same length. Other researchers have noted that in languages with this scale, or the abbreviated ternary version CV: \${$>\$$} CVC \${$>\$$} CV, CVC syllables behave ambiguously with respect to stress. They seem to be heavy in relation to CV when CV: syllables are absent. In a stress clash context however, CVC defers to CV:. ' Mora-only' accounts of other languages with this scale have interpreted the ambiguous behaviour of CVC as evidence that CVC syllables are bimoraic where their behaviour seems to group them with CV: but monomoraic elsewhere (e.g. Rosenthall \& van der H\"ulst 1999, Moren 2000). To account for the CV: C \${$>\$$} CV: effect, mora-only accounts have been forced to assume that CV: C are trimoraic. We show that a mora-only analysis does not offer a satisfying account of the Koshur facts, and we argue instead that the origin of the CVC \${$>\$$} CV and CV: C \${$>\$$} CV: effects is the presence of a coda that branches from the final mora of a syllable, making the closed syllables more harmonic as prosodie heads. Under this view, branchingness emerges as another dimension of the mora, along with moraic quantity and the quality of segments linked to moras, which contributes to syllable prominence.}
}

@article{nanceAcousticsThreeWayLateral2020,
  title = {The {{Acoustics}} of {{Three-Way Lateral}} and {{Nasal Palatalisation Contrasts}} in {{Scottish Gaelic}}},
  author = {Nance, Claire and Kirkham, Sam},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {2858--2872},
  issn = {0001-4966},
  doi = {10.1121/10.0000998},
  langid = {english}
}

@book{NeuralBasisInhibitory,
  title = {The {{Neural Basis}} of {{Inhibitory Effects}} of {{Semantic}} and {{Phonological Neighbors}} in {{Spoken Word Production}}. - {{Abstract}} - {{Europe PMC}}}
}

@inproceedings{niebuhrClearSpeechMere2017,
  title = {Clear {{Speech}} \textemdash{} {{Mere Speech}}? {{How Segmental}} and {{Prosodic Speech Reduction Shape}} the {{Impression That Speakers Create}} on {{Listeners}}},
  shorttitle = {Clear {{Speech}} \textemdash{} {{Mere Speech}}?},
  booktitle = {Interspeech 2017},
  author = {Niebuhr, Oliver},
  year = {2017},
  month = aug,
  pages = {894--898},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2017-28},
  abstract = {Research on speech reduction is primarily concerned with analyzing, modeling, explaining, and, ultimately, predicting phonetic variation. That is, the focus is on the speech signal itself. The present paper adds a little side note to this fundamental line of research by addressing the question whether variation in the degree of reduction also has a systematic effect on the attributes we ascribe to the speaker who produces the speech signal. A perception experiment was carried out for German in which 46 listeners judged whether or not speakers showing 3 different combinations of segmental and prosodic reduction levels (unreduced, moderately reduced, strongly reduced) are appropriately described by 13 physical, social, and cognitive attributes. The experiment shows that clear speech is not mere speech, and less clear speech is not just reduced either. Rather, results revealed a complex interplay of reduction levels and perceived speaker attributes in which moderate reduction can make a better impression on listeners than no reduction. In addition to its relevance in reduction models and theories, this interplay is instructive for various fields of speech application from social robotics to charisma coaching.},
  langid = {english}
}

@article{nygaardSpeechPerceptionTalkerContingent1994,
  title = {Speech {{Perception}} as a {{Talker-Contingent Process}}},
  author = {Nygaard, Lynne C. and Sommers, Mitchell S. and Pisoni, David B.},
  year = {1994},
  journal = {Psychological Science},
  volume = {5},
  number = {1},
  pages = {42--46},
  issn = {0956-7976},
  abstract = {To determine how familiarity with a talker's voice affects perception of spoken words, we trained two groups of subjects to recognize a set of voices over a 9-day period. One group then identified novel words produced by the same set of talkers at four signal-to-noise ratios. Control subjects identified the same words produced by a different set of talkers. The results showed that the ability to identify a talker's voice improved intelligibility of novel words produced by that talker. The results suggest that speech perception may involve talker-contingent processes whereby perceptual learning of aspects of the vocal source facilitates the subsequent phonetic analysis of the acoustic signal.}
}

@article{ohalaProsodicPhonologyPhonetics1984,
  title = {Prosodic {{Phonology}} and {{Phonetics}}},
  author = {Ohala, John J. and Kawasaki, Haruko},
  year = {1984},
  month = may,
  journal = {Phonol. yearb.},
  volume = {1},
  pages = {113--127},
  issn = {0265-8062, 2059-6286},
  doi = {10.1017/S0952675700000312},
  abstract = {Our colleague Charles Fillmore invented the following parable (personal communication) to characterise the two dominant ways linguists attempt to solve problems of language structure and behaviour.},
  langid = {english}
}

@article{oinasFINNISHESTONIANFOLK1976,
  title = {{{THE FINNISH AND ESTONIAN FOLK EPIC}}},
  author = {Oinas, Felix J.},
  year = {1976},
  journal = {Journal of Baltic Studies},
  volume = {7},
  number = {1},
  pages = {1--12},
  publisher = {{Taylor \& Francis, Ltd.}},
  issn = {0162-9778}
}

@article{oinasFinnishEstonianFolk1976,
  title = {The {{Finnish}} and {{Estonian}} Folk Epic},
  author = {Oinas, Felix J.},
  year = {1976},
  month = mar,
  journal = {Journal of Baltic Studies},
  volume = {7},
  number = {1},
  pages = {1--12},
  issn = {0162-9778, 1751-7877},
  doi = {10.1080/01629777600000011},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/D8X634G5/Oinas - 1976 - The Finnish and Estonian folk epic.pdf}
}

@article{okadaIdentificationLexicalPhonological2006,
  title = {Identification of {{Lexical}}\textendash{} {{Phonological Networks}} in the {{Superior Temporal Sulcus Using Functional Magnetic Resonance Imaging}}},
  author = {Okada, Kayoko and Hickok, Gregory},
  year = {2006},
  month = aug,
  journal = {NeuroReport},
  volume = {17},
  number = {12},
  pages = {1293},
  issn = {0959-4965},
  doi = {10.1097/01.wnr.0000233091.82536.b2},
  abstract = {General agreement exists that dorsal aspects of the temporal lobe support the perception of speech but there is less agreement regarding the mapping between levels of speech processing and neural regions within the dorsal temporal lobe. The present experiment sought to identify temporal lobe regions that support one such level, namely, lexical\textendash{} phonological representation/processing. To do this, we manipulated phonological neighborhood density, a variable that affects processing within lexical\textendash{} phonological networks. In a functional magnetic resonance imaging experiment, 10 participants listened to blocks of either high-density or low-density words. High-density words produced significantly more activation in the posterior half of the superior temporal sulcus bilaterally, suggesting that these regions are involved in lexical\textendash{} phonological processing networks.},
  langid = {american}
}

@article{oldfieldThingsWordsBrain1966,
  title = {Things, {{Words}} and the {{Brain}}*},
  author = {Oldfield, R. C.},
  year = {1966},
  month = nov,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {18},
  number = {4},
  pages = {340--353},
  publisher = {{SAGE Publications}},
  issn = {0033-555X},
  doi = {10.1080/14640746608400052},
  langid = {english}
}

@article{orasMusicalManifestationsTextual2011,
  title = {Musical {{Manifestations}} of {{Textual Patterning}} in {{Estonian Regilaul}}},
  author = {Oras, Janika},
  year = {2011},
  month = may,
  journal = {Journal of Ethnology and Folkloristics},
  volume = {4},
  abstract = {The article analyses the marking of song text patterns by means of musical devices in the performances of Estonian regilaul. The article examines which variants of musical rhythm and melodic contour are preferred by four singers in their performance of verses that have different functions within the song structure. In both the text and the musical rhythm, a greater number of syllables, and the attendant changes in musical rhythm, mark the verses that have an initiating function and which communicate entirely new information. In performing such verses, rather than the extension verses of parallelism groups or verse repetitions, in the short melodies with narrow pitch range, the singers prefer more "intense" variants of melody contours in which the higher notes of the scale are predominantly used. In two-line melodies, the singer's patterning of the song text is largely determined by the musical logic, attempting to align the beginnings of the melodic strophes and verse groups.},
  file = {/Users/sarah/Zotero/storage/DNKZM8Q3/Oras - 2011 - Musical Manifestations of Textual Patterning in Es.pdf}
}

@article{orasMUSICALMANIFESTATIONSTEXTUAL2021,
  title = {{{MUSICAL MANIFESTATIONS OF TEXTUAL PAT T E R N I NG I N E S T ON I A N R E G I L AU L}}},
  author = {Oras, Janika},
  year = {2021},
  pages = {15},
  abstract = {The article* analyses the marking of song text patterns by means of musical devices in the performances of Estonian regilaul. The article examines which variants of musical rhythm and melodic contour are preferred by four singers in their performance of verses that have different functions within the song structure. In both the text and the musical rhythm, a greater number of syllables, and the attendant changes in musical rhythm, mark the verses that have an initiating function and which communicate entirely new information. In performing such verses, rather than the extension verses of parallelism groups or verse repetitions, in the short melodies with narrow pitch range, the singers prefer more ``intense'' variants of melody contours in which the higher notes of the scale are predominantly used. In two-line melodies, the singer's patterning of the song text is largely determined by the musical logic, attempting to align the beginnings of the melodic strophes and verse groups.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/SY2I52UQ/Oras - 2021 - MUSICAL MANIFESTATIONS OF TEXTUAL PAT T E R N I NG.pdf}
}

@article{ortega-llebariaAcousticCorrelatesStress2011,
  title = {Acoustic {{Correlates}} of {{Stress}} in {{Central Catalan}} and {{Castilian Spanish}}},
  author = {{Ortega-Llebaria}, Marta and Prieto, Pilar},
  year = {2011},
  month = mar,
  journal = {Lang Speech},
  volume = {54},
  number = {1},
  pages = {73--97},
  publisher = {{SAGE Publications Ltd}},
  issn = {0023-8309},
  doi = {10.1177/0023830910388014},
  abstract = {The general literature on the phonetic correlates of stress agrees that duration, and in stress accent languages, F0 are consistent correlates of stress. However, the role of amplitude changes in the speech signal is more controversial. In particular, the conflicting results of spectral tilt as a correlate of stress have been attributed to the effects of vowel reduction. We examined the stress correlates of duration, overall intensity and spectral tilt in Catalan and Spanish in both accented and unaccented contexts while controlling for formant frequency differences between morphologically corresponding vowels in stressed and unstressed environments by comparing vowels that maintain the same quality across stress contexts with those that do not. Duration was a consistent stress correlate in all vowels in both languages, regardless of their formant frequency differences across stress contexts and of the absence of pitch accents. In fact, stress-related formant frequency differences between corresponding vowels amplify the duration cues to the stress contrast. On the other hand, the use speakers made of intensity was not as pervasive as that of duration. Specifically, changes in spectral tilt were significant only in Catalan and in those vowels that alternate a more open and peripheral realization in stressed syllables with a mid-central realization in unstressed syllables, indicating that spectral tilt is related to the formant frequency differences linked to the centralization processes rather than to the stress contrast.}
}

@article{osullivanAttentionalSelectionCocktail2015,
  title = {Attentional {{Selection}} in a {{Cocktail Party Environment Can Be Decoded}} from {{Single-Trial EEG}}},
  author = {O'Sullivan, James A. and Power, Alan J. and Mesgarani, Nima and Rajaram, Siddharth and Foxe, John J. and {Shinn-Cunningham}, Barbara G. and Slaney, Malcolm and Shamma, Shihab A. and Lalor, Edmund C.},
  year = {2015},
  month = jul,
  journal = {Cereb Cortex},
  volume = {25},
  number = {7},
  pages = {1697--1706},
  issn = {1047-3211},
  doi = {10.1093/cercor/bht355},
  abstract = {Abstract. How humans solve the cocktail party problem remains unknown. However, progress has been made recently thanks to the realization that cortical activit},
  langid = {english}
}

@article{OverviewHierarchicalStructure2021,
  title = {An {{Overview}} of {{Hierarchical Structure}} in {{Music}}},
  year = {2021},
  pages = {25},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/93CQC9ZL/2021 - An Overview of Hierarchical Structure in Music.pdf}
}

@article{pallierInfluenceNativeLanguagePhonology2001,
  title = {The {{Influence}} of {{Native-Language Phonology}} on {{Lexical Access}}: {{Exemplar-Based Versus Abstract Lexical Entries}}},
  shorttitle = {The {{Influence}} of {{Native-Language Phonology}} on {{Lexical Access}}},
  author = {Pallier, Christophe and Colom{\'e}, Angels and {Sebasti{\'a}n-Gall{\'e}s}, N{\'u}ria},
  year = {2001},
  month = nov,
  journal = {Psychological Science},
  volume = {12},
  number = {6},
  pages = {445--449},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00383},
  abstract = {This study used medium-term auditory repetition priming to investigate word-recognition processes. Highly fluent Catalan-Spanish bilinguals whose first language was either Catalan or Spanish were tested in a lexical decision task involving Catalan words and nonwords. Spanish-dominant individuals, but not Catalan-dominant individuals, exhibited repetition priming for minimal pairs differing in only one feature that is nondistinctive in Spanish (e.g., /net{$\Elzschwa$}/ vs. /n{$\smallin$}t{$\Elzschwa$}/), thereby indicating that they processed these words as homophones. This finding provides direct evidence both that word recognition uses a language-specific phonological representation and that lexical entries are stored in the mental lexicon as abstract forms.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/9F5PMN3M/Pallier et al. - 2001 - The Influence of Native-Language Phonology on Lexi.pdf}
}

@article{patelEmpiricalComparisonRhythm2003,
  title = {An Empirical Comparison of Rhythm in Language and Music},
  author = {Patel, Aniruddh D and Daniele, Joseph R},
  year = {2003},
  month = feb,
  journal = {Cognition},
  volume = {87},
  number = {1},
  pages = {B35-B45},
  issn = {00100277},
  doi = {10.1016/S0010-0277(02)00187-7},
  abstract = {Musicologists and linguists have often suggested that the prosody of a culture's spoken language can influence the structure of its instrumental music. However, empirical data supporting this idea have been lacking. This has been partly due to the difficulty of developing and applying comparable quantitative measures to melody and rhythm in speech and music. This study uses a recentlydeveloped measure for the study of speech rhythm to compare rhythmic patterns in English and French language and classical music. We find that English and French musical themes are significantly different in this measure of rhythm, which also differentiates the rhythm of spoken English and French. Thus, there is an empirical basis for the claim that spoken prosody leaves an imprint on the music of a culture. q 2002 Elsevier Science B.V. All rights reserved.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/H9B9ZPTC/Patel and Daniele - 2003 - An empirical comparison of rhythm in language and .pdf}
}

@book{patelMusicLanguageBrain2007,
  title = {Music, {{Language}}, and the {{Brain}}},
  author = {Patel, Aniruddh D.},
  year = {2007},
  publisher = {{Oxford University Press, Incorporated}},
  address = {{New York, UNITED STATES}},
  isbn = {978-0-19-802877-2},
  keywords = {Auditory perception -- Physiological aspects.,Cognitive neuroscience.,Communication.,Language acquisition -- Physiological aspects.,Music -- Physiological aspects.,Music -- Psychological aspects.,Music and language.},
  file = {/Users/sarah/Zotero/storage/FAM537LY/Patel - 2007 - Music, Language, and the Brain.pdf;/Users/sarah/Zotero/storage/7P9THXIB/reader.html}
}

@article{patelStressTimedVsSyllableTimed2003,
  title = {Stress-{{Timed}} vs. {{Syllable-Timed Music}}? {{A Comment}} on {{Huron}} and {{Ollen}} (2003)},
  shorttitle = {Stress-{{Timed}} vs. {{Syllable-Timed Music}}?},
  author = {Patel, Aniruddh D. and Daniele, Joseph R.},
  year = {2003},
  month = dec,
  journal = {Music Perception},
  volume = {21},
  number = {2},
  pages = {273--276},
  issn = {0730-7829, 1533-8312},
  doi = {10.1525/mp.2003.21.2.273},
  abstract = {Linguists have long distinguished between ````stress-timed'''' and ````syllable-timed'''' languages. Using new methods for comparing rhythm in language and music (A. D. Patel \& J. R. Daniele, 2003) and new data on musical rhythm from a range of nations (D. Huron \& J. Ollen, 2003), one can begin to address whether stress-timed and syllable-timed languages are associated with distinctive musical rhythms. In conducting such studies, it is important to be aware of historical influences on musical rhythm that might run counter to linguistic influences. An empirical method for studying historical influences is proposed.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/5ZTH2YS8/Patel and Daniele - 2003 - Stress-Timed vs. Syllable-Timed Music A Comment o.pdf}
}

@book{PDFAuditoryCognitive,
  title = {({{PDF}}) {{Auditory}}, {{Cognitive}}, and {{Linguistic Factors Predict Speech Recognition}} in {{Adverse Listening Conditions}} for {{Children With Hearing Loss}}}
}

@book{PDFCophonologiesPh,
  title = {({{PDF}}) {{Cophonologies}} by {{Ph}}(r){{Ase}}},
  journal = {ResearchGate},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  langid = {english}
}

@book{PDFFindingSignal,
  title = {({{PDF}}) {{Finding}} the {{Signal}} in the {{Noise}}: {{Minimizing Responses From Bots}} and {{Inattentive Humans}} in {{Online Research}}},
  shorttitle = {({{PDF}}) {{Finding}} the {{Signal}} in the {{Noise}}},
  journal = {ResearchGate},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  langid = {english}
}

@book{PDFInvestigationNetwork,
  title = {(1) ({{PDF}}) {{An Investigation}} of {{Network Growth Principles}} in the {{Phonological Language Network}}}
}

@book{PDFListenersPerceive,
  title = {({{PDF}}) {{Listeners Perceive Prefixes Differently}}: {{Evidence}} from a {{Noise-Rating Task}}},
  shorttitle = {({{PDF}}) {{Listeners Perceive Prefixes Differently}}},
  journal = {ResearchGate},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  langid = {english}
}

@article{peircePsychoPyPsychologySoftware,
  title = {{{PsychoPy}} - {{Psychology Software}} for {{Python}}},
  author = {Peirce, Jonathan},
  pages = {544},
  langid = {english}
}

@article{peramunagePhonologicalNeighborhoodEffects2010,
  title = {Phonological {{Neighborhood Effects}} in {{Spoken Word Production}}: {{An fMRI Study}}},
  shorttitle = {Phonological {{Neighborhood Effects}} in {{Spoken Word Production}}},
  author = {Peramunage, Dasun and Blumstein, Sheila E. and Myers, Emily B. and Goldrick, Matthew and {Baese-Berk}, Melissa},
  year = {2010},
  month = mar,
  journal = {Journal of Cognitive Neuroscience},
  volume = {23},
  number = {3},
  pages = {593--603},
  publisher = {{MIT Press}},
  issn = {0898-929X},
  doi = {10.1162/jocn.2010.21489},
  abstract = {The current study examined the neural systems underlying lexically conditioned phonetic variation in spoken word production. Participants were asked to read aloud singly presented words, which either had a voiced minimal pair (MP) neighbor (e.g., cape) or lacked a minimal pair (NMP) neighbor (e.g., cake). The voiced neighbor never appeared in the stimulus set. Behavioral results showed longer voice-onset time for MP target words, replicating earlier behavioral results [Baese-Berk, M., \& Goldrick, M. Mechanisms of interaction in speech production. Language and Cognitive Processes, 24, 527\textendash{} 554, 2009]. fMRI results revealed reduced activation for MP words compared to NMP words in a network including left posterior superior temporal gyrus, the supramarginal gyrus, inferior frontal gyrus, and precentral gyrus. These findings support cascade models of spoken word production and show that neural activation at the lexical level modulates activation in those brain regions involved in lexical selection, phonological planning, and, ultimately, motor plans for production. The facilitatory effects for words with MP neighbors suggest that competition effects reflect the overlap inherent in the phonological representation of the target word and its MP neighbor.}
}

@article{perkellEconomyEffortDifferent2002,
  title = {Economy of {{Effort}} in {{Different Speaking Conditions}}. {{I}}. {{A Preliminary Study}} of {{Intersubject Differences}} and {{Modeling Issues}}},
  author = {Perkell, Joseph S. and Zandipour, Majid and Matthies, Melanie L. and Lane, Harlan},
  year = {2002},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {112},
  number = {4},
  pages = {1627--1641},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.1506369}
}

@article{pimentelDisambiguatorySignalsAre2021,
  title = {Disambiguatory {{Signals}} Are {{Stronger}} in {{Word-initial Positions}}},
  author = {Pimentel, Tiago and Cotterell, Ryan and Roark, Brian},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.02183 [cs]},
  eprint = {2102.02183},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Psycholinguistic studies of human word processing and lexical access provide ample evidence of the preferred nature of word-initial versus word-final segments, e.g., in terms of attention paid by listeners (greater) or the likelihood of reduction by speakers (lower). This has led to the conjecture -- as in Wedel et al. (2019b), but common elsewhere -- that languages have evolved to provide more information earlier in words than later. Information-theoretic methods to establish such tendencies in lexicons have suffered from several methodological shortcomings that leave open the question of whether this high word-initial informativeness is actually a property of the lexicon or simply an artefact of the incremental nature of recognition. In this paper, we point out the confounds in existing methods for comparing the informativeness of segments early in the word versus later in the word, and present several new measures that avoid these confounds. When controlling for these confounds, we still find evidence across hundreds of languages that indeed there is a cross-linguistic tendency to front-load information in words.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/sarah/Zotero/storage/MK92MMT9/Pimentel et al. - 2021 - Disambiguatory Signals are Stronger in Word-initia.pdf;/Users/sarah/Zotero/storage/MB72DC3H/Pimentel et al. - 2021 - Disambiguatory Signals are Stronger in Word-initia.html}
}

@incollection{plechacCollocationDrivenMethodDiscovering2018,
  title = {A {{Collocation-Driven Method}} of {{Discovering Rhymes}} (in {{Czech}}, {{English}}, and {{French Poetry}})},
  booktitle = {Taming the {{Corpus}}: {{From Inflection}} and {{Lexis}} to {{Interpretation}}},
  author = {Plech{\'a}{\v c}, Petr},
  editor = {Fidler, Masako and Cvr{\v c}ek, V{\'a}clav},
  year = {2018},
  series = {Quantitative {{Methods}} in the {{Humanities}} and {{Social Sciences}}},
  pages = {79--95},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-98017-1_5},
  abstract = {The chapter presents a model for discovering rhymes in a corpus of poetic texts. The algorithm employs an adaptation of the usual collocation extraction technique in order to identify some common rhyme pairs in a corpus. The output is then used as a training set for simple machine learning. The method has been tested on corpora of poetry in three different languages (Czech, English, and French) with F-scores ranging from 0.9 to 0.95.},
  isbn = {978-3-319-98017-1},
  langid = {english},
  keywords = {Corpus linguistics,Machine learning,Morphological richness,Rhyme,Versification}
}

@article{poeppelSpeechRhythmsTheir2020,
  title = {Speech {{Rhythms}} and {{Their Neural Foundations}}},
  author = {Poeppel, David and Assaneo, M. Florencia},
  year = {2020},
  month = jun,
  journal = {Nature Reviews Neuroscience},
  volume = {21},
  number = {6},
  pages = {322--334},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0304-4},
  abstract = {The recognition of spoken language has typically been studied by focusing on either words or their constituent elements (for example, low-level features or phonemes). More recently, the `temporal mesoscale' of speech has been explored, specifically regularities in the envelope of the acoustic signal that correlate with syllabic information and that play a central role in production and perception processes. The temporal structure of speech at this scale is remarkably stable across languages, with a preferred range of rhythmicity of 2\textendash{} 8\textbackslash,Hz. Importantly, this rhythmicity is required by the processes underlying the construction of intelligible speech. A lot of current work focuses on audio-motor interactions in speech, highlighting behavioural and neural evidence that demonstrates how properties of perceptual and motor systems, and their relation, can underlie the mesoscale speech rhythms. The data invite the hypothesis that the speech motor cortex is best modelled as a neural oscillator, a conjecture that aligns well with current proposals highlighting the fundamental role of neural oscillations in perception and cognition. The findings also show motor theories (of speech) in a different light, placing new mechanistic constraints on accounts of the action\textendash{} perception interface.},
  copyright = {2020 Springer Nature Limited},
  langid = {english}
}

@article{pompiliLifeEventsPrecipitants2011,
  title = {Life Events as Precipitants of Suicide Attempts among First-Time Suicide Attempters, Repeaters, and Non-Attempters},
  author = {Pompili, Maurizio and Innamorati, Marco and Szanto, Katalin and Di Vittorio, Cristina and Conwell, Yeates and Lester, David and Tatarelli, Roberto and Girardi, Paolo and Amore, Mario},
  year = {2011},
  month = apr,
  journal = {Psychiatry Research},
  volume = {186},
  number = {2},
  pages = {300--305},
  issn = {0165-1781},
  doi = {10.1016/j.psychres.2010.09.003},
  abstract = {The aims of this study were to investigate risk factors for suicide attempts and propose a model explaining the associations among life events and suicide status. We assessed 263 subjects admitted following a suicide attempt to the Division of Psychiatry of the Department of Neurosciences of the University of Parma and compared them with 263 non-attempter clinical control subjects. Attempters reported significantly more adverse life events both in the last 6months, and between the ages of 0\textendash 15years than non-attempters. A multinomial logistic regression analysis with stepwise forward entry indicated that the best model to explain suicide status was one which included life events in the last 6months, life events during age 0\textendash 15years, and their interaction. First-time attempter status (vs. non-attempters) was more likely to be linked to life events in the last 6months, the interaction between life events in the last 6months and life events during age 0\textendash 15years, and low social support. Those attempters with one or more prior attempts (repeat attempters) were more likely than non-attempters to be linked to the interaction between life events in the last 6months and life events during age 0\textendash 15years, and to higher rates of psychopharmacological treatment before the index admission. Guided by these findings, monitoring the impact of early-life and recent events in vulnerable individuals should be part of risk assessment and treatment.},
  langid = {english},
  keywords = {Adults,Stressful life events,Suicide},
  file = {/Users/sarah/Zotero/storage/D3B3ILM7/Pompili et al. - 2011 - Life events as precipitants of suicide attempts am.pdf;/Users/sarah/Zotero/storage/2BFDUNIE/S0165178110005792.html}
}

@article{porschmannImpactFaceMasks2020,
  title = {Impact of {{Face Masks}} on {{Voice Radiation}}},
  author = {P{\"o}rschmann, Christoph and L{\"u}beck, Tim and Arend, Johannes M.},
  year = {2020},
  month = dec,
  journal = {The Journal of the Acoustical Society of America},
  volume = {148},
  number = {6},
  pages = {3663--3670},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0002853},
  abstract = {With the COVID-19 pandemic, the wearing of face masks covering mouth and nose has become ubiquitous all around the world. This study investigates the impact of typical face masks on voice radiation. To analyze the transmission loss caused by masks and the influence of masks on directivity, this study measured the full-spherical voice directivity of a dummy head with a mouth simulator covered with six masks of different types, i.e., medical masks, filtering facepiece respirator masks, and cloth face coverings. The results show a significant frequency-dependent transmission loss, which varies depending on the mask, especially above 2\textbackslash,kHz. Furthermore, the two facepiece respirator masks also significantly affect speech directivity, as determined by the directivity index (DI). Compared to the measurements without a mask, the DI deviates by up to 7\textbackslash,dB at frequencies above 3\textbackslash,kHz. For all other masks, the deviations are below 2\textbackslash,dB in all third-octave frequency bands.}
}

@article{princeMetricalTheoryEstonian1980,
  title = {A {{Metrical Theory}} for {{Estonian Quantity}}},
  author = {Prince, Alan S.},
  year = {1980},
  journal = {Linguistic Inquiry},
  volume = {11},
  number = {3},
  pages = {511--562},
  publisher = {{MIT Press}},
  issn = {0024-3892}
}

@book{ProlificOnlineParticipant,
  title = {Prolific | {{Online Participant Recruitment}} for {{Surveys}} and {{Market Research}}}
}

@article{QuatrainFormEnglish2021,
  title = {Quatrain {{Form}} in {{English Folk Verse}}},
  year = {2021},
  volume = {74},
  number = {3},
  pages = {36},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/Y447XXAN/2021 - Quatrain Form in English Folk Verse.pdf}
}

@misc{RegilauluLuguVaike,
  title = {Regilaulu Lugu | {{V\"aike Hellero}}},
  howpublished = {https://folklore.ee/regilaul/lugu/kuula},
  file = {/Users/sarah/Zotero/storage/EBSXJMNJ/kuula.html}
}

@book{RelationshipNativeSpeaker,
  title = {The {{Relationship Between Native Speaker Judgments}} of {{Nonnative Pronunciation}} and {{Deviance}} in {{Segmentais}}, {{Prosody}}, and {{Syllable Structure}} - {{Anderson-Hsieh}} - 1992 - {{Language Learning}} - {{Wiley Online Library}}}
}

@article{remijsenStudyToneLanguages2014,
  title = {The {{Study}} of {{Tone}} in {{Languages}} with a {{Quantity Contrast}}},
  author = {Remijsen, Bert},
  year = {2014},
  month = dec,
  journal = {Language Documentation \& Conservation},
  volume = {8},
  pages = {672--689},
  publisher = {{University of Hawai'i Press}},
  abstract = {This paper deals with the study of tone in languages that additionally have a phonological contrastive of quantity, such as vowel length or stress. In such complex word-prosodic systems, tone and the quantity contrast(s) can be fully independent of one another, or they may interact. Both of these configurations are illustrated in this paper, and the phonetic pressures underlying the development of interactions are laid out. The paper pays particular attention to the challenge of investigating complex word-prosodic systems. Central to the approach advocated here is the combination of qualitative fieldwork data collection methods with instrumental analysis. *This paper is in the series How to Study a Tone Language, edited by Steven Bird and Larry Hyman},
  copyright = {Creative Commons Attribution Non-Commercial Share Alike License},
  isbn = {9780985621124},
  langid = {english}
}

@article{roedigerCreatingFalseMemories1995,
  title = {Creating {{False Memories}}: {{Remembering Words Not Presented}} in {{Lists}}},
  author = {Roediger, Henry L and McDermott, Kathleen B},
  year = {1995},
  journal = {Journal of Experimental Psychology: Copyright 1995 by the American Psychological Association, Inc. Learning, Memory, and Cognition 0278-7393/95/S3.00 1995, Vol. 21, No. 4,803-814},
  volume = {21},
  pages = {12},
  langid = {english}
}

@article{roettgerPreregistrationExperimentalLinguistics2021,
  title = {Preregistration in Experimental Linguistics: Applications, Challenges, and Limitations},
  shorttitle = {Preregistration in Experimental Linguistics},
  author = {Roettger, Timo B.},
  year = {2021},
  month = mar,
  journal = {Linguistics},
  volume = {0},
  number = {0},
  pages = {000010151520190048},
  issn = {1613-396X, 0024-3949},
  doi = {10.1515/ling-2019-0048},
  abstract = {The current publication system neither incentivizes publishing null results nor direct replication attempts, which biases the scientific record toward novel findings that appear to support presented hypotheses (referred to as ``publication bias''). Moreover, flexibility in data collection, measurement, and analysis (referred to as ``researcher degrees of freedom'') can lead to overconfident beliefs in the robustness of a statistical relationship. One way to systematically decrease publication bias and researcher degrees of freedom is preregistration. A preregistration is a time-stamped document that specifies how data is to be collected, measured, and analyzed prior to data collection. While preregistration is a powerful tool to reduce bias, it comes with certain challenges and limitations which have to be evaluated for each scientific discipline individually. This paper discusses applications, challenges and limitations of preregistration for experimental linguistic research.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/L9PR9SZJ/Roettger - 2021 - Preregistration in experimental linguistics appli.pdf}
}

@article{roettgerResearcherDegreesFreedom2019,
  title = {Researcher Degrees of Freedom in Phonetic Research},
  author = {Roettger, Timo B.},
  year = {2019},
  month = jan,
  journal = {Laboratory Phonology: Journal of the Association for Laboratory Phonology},
  volume = {10},
  number = {1},
  pages = {1},
  publisher = {{Ubiquity Press}},
  issn = {1868-6354},
  doi = {10.5334/labphon.147},
  abstract = {The results of published research critically depend on methodological decisions that have been made during data analysis. These so-called `researcher degrees of freedom' (Simmons, Nelson, \&amp; Simonsohn, 2011) can affect the results and the conclusions researchers draw from it. It is argued that phonetic research faces a large number of researcher degrees of freedom due to its scientific object\textemdash speech\textemdash being inherently multidimensional and exhibiting complex interactions between multiple covariates. A Type-I error simulation is presented that demonstrates the severe inflation of false positives when exploring researcher degrees of freedom. It is argued that combined with common cognitive fallacies, exploitation of researcher degrees of freedom introduces strong bias and poses a serious challenge to quantitative phonetics as an empirical science. This paper discusses potential remedies for this problem including adjusting the threshold for significance; drawing a clear line between confirmatory and exploratory analyses via preregistration; open, honest, and transparent practices in communicating data analytical decisions; and direct replications.},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  langid = {english},
  keywords = {false positive,methodology,preregistration,replication,reproducibility,speech production,statistical analysis},
  file = {/Users/sarah/Zotero/storage/JEY7U4UT/Roettger - 2019 - Researcher degrees of freedom in phonetic research.pdf;/Users/sarah/Zotero/storage/2FB3VQSJ/labphon.147.html}
}

@inproceedings{rosenbergSpeechProsodyMachines2018,
  title = {Speech, {{Prosody}}, and {{Machines}}: {{Nine Challenges}} for {{Prosody Research}}},
  shorttitle = {Speech, {{Prosody}}, and {{Machines}}},
  booktitle = {9th {{International Conference}} on {{Speech Prosody}} 2018},
  author = {Rosenberg, Andrew},
  year = {2018},
  month = jun,
  pages = {784--793},
  publisher = {{ISCA}},
  doi = {10.21437/SpeechProsody.2018-159},
  abstract = {Speech technology is becoming commonplace. Traditional telephony based interactive voice systems have been joined by virtual assistants and navigation systems to create a broad ecosystem of voice enabled technologies. Prosody is an essential component to human communication, but machines still lag in their ability to understand information communicated prosodically and to produce human-like intonation.},
  langid = {english}
}

@article{rosenHowMixedMixed2020,
  title = {How ``{{Mixed}}'' {{Is Mixed Language Phonology}}? {{An Acoustic Analysis}} of the {{Michif Vowel System}}},
  shorttitle = {How ``{{Mixed}}'' {{Is Mixed Language Phonology}}?},
  author = {Rosen, Nicole and Stewart, Jesse and Sammons, Olivia N.},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {2989--2999},
  issn = {0001-4966},
  doi = {10.1121/10.0001009},
  langid = {english}
}

@article{rossLostProsodicOppositions1994,
  title = {Lost {{Prosodic Oppositions}}: {{A Study}} of {{Contrastive Duration}} in {{Estonian Funeral Laments}}},
  shorttitle = {Lost {{Prosodic Oppositions}}},
  author = {Ross, Jaan and Lehiste, Ilse},
  year = {1994},
  month = oct,
  journal = {Language and Speech},
  volume = {37},
  number = {4},
  pages = {407--424},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/002383099403700405},
  abstract = {This study examined the temporal structure of three recorded South-Eastem Estonian laments, a vocal style close to the old folksong tradition of the same region. A one-to-one correspondence was found between syllables in the text and notes in the melody. The duration of more than 700 syllables was measured. Syllable duration was found to vary by a considerable amount. In spoken language, the three quantities of disyllabic Estonian words are signalled by characteristic ratios between the durations of the first and the second syllable (S1/S2 ratio), which have approximately the values of 0.67, 1.5, and 2.0 for short, long, and overlong degrees. In laments, the range of S1/S2 ratios was much smaller. The difference in S1/S2 ratio between long and overlong disyllabic words was nonsignificant in all three performances, and that between short and long words was nonsignificant in one performance. This tendency toward rhythmic regularity may be explained on the basis of the original activity-associated nature of the old folksong tradition.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/R2ZZTXZN/Ross and Lehiste - 1994 - Lost Prosodic Oppositions A Study of Contrastive .pdf}
}

@article{rossStudyTimingEstonian1989,
  title = {A Study of Timing in an {{Estonian}} Runic Song},
  author = {Ross, Jaan},
  year = {1989},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {86},
  number = {5},
  pages = {1671--1677},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.398597}
}

@article{rossTimingEstonianFolk1998,
  title = {Timing in {{Estonian Folk Songs}} as {{Interaction}} between {{Speech Prosody}}, {{Meter}}, and {{Musical Rhythm}}},
  author = {Ross, Jaan and Lehiste, Ilse},
  year = {1998},
  month = jul,
  journal = {Music Perception},
  volume = {15},
  number = {4},
  pages = {319--333},
  issn = {0730-7829},
  doi = {10.2307/40300861},
  abstract = {Durations of acoustical segments were measured in four Estonian folk songs sung by a single performer, consisting of 152 verse lines, eight syllables each, with one note in the melody normally corresponding to one syllable in the text. The results were analyzed with regard to three aspects: notation, meter, and speech prosody. Three songs out of four are notated as isochronous sequences of 8 eighth notes per each verse line; in one song, certain pairs of eighth notes are replaced by a dotted eighth note plus a sixteenth note. The results revealed a complex interaction between meter, musical rhythm, and speech prosody. Variations in durations of sound events reflect the Kalevala meter on which the songs are based, with average rises in a foot being acoustically longer than falls. The duration differences between rises and falls are reduced in the socalled broken lines, which contain monosyllabic and trisyllabic words and allow for accommodation of short stressed syllables at a fall of a foot as required by the meter. Semantically relevant oppositions of wordinitial short-long and long-short disyllabic units in speech are not kept completely intact in folk songs. Short-long disyllables are treated in a different manner by the performer, depending on whether their initial syllable occurs at a rise or at a fall in a foot.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/38QPMVU5/Ross and Lehiste - 1998 - Timing in Estonian Folk Songs as Interaction betwe.pdf}
}

@article{rossTradeoffQuantityStress1996,
  title = {Trade-off between Quantity and Stress in {{Estonian}} Folksong Performance?},
  author = {Ross, Jaan and Lehiste, Ilse},
  year = {1996},
  journal = {Folklore: Electronic Journal of Folklore},
  volume = {02},
  pages = {116--123},
  issn = {14060957, 14060949},
  doi = {10.7592/FEJF1996.02.rosslehi},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/94FQH73B/Ross and Lehiste - 1996 - Trade-off between quantity and stress in Estonian .pdf}
}

@article{ryanPhonologicalWeightRYAN2016,
  title = {Phonological Weight: {{RYAN}}},
  shorttitle = {Phonological Weight},
  author = {Ryan, Kevin M.},
  year = {2016},
  month = dec,
  journal = {Language and Linguistics Compass},
  volume = {10},
  number = {12},
  pages = {720--733},
  issn = {1749818X},
  doi = {10.1111/lnc3.12229},
  abstract = {Grammars frequently categorize syllables for prosodic purposes, treating one class as heavier (e.g., more stressattracting) than another. While such categorization is usually dichotomous, complex and gradient scales are also attested, with various organizational criteria. This article reviews the range of phenomena that invoke weight distinctions and introduces some current debates concerning weight, touching on topics such as the syllable versus interval as the domain of weight, rich scalarity, process and position specificities, the role of onsets, the phonetic basis of categorization, and the mora.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/W2YNYVT2/Ryan - 2016 - Phonological weight RYAN.pdf}
}

@article{sadatReconcilingPhonologicalNeighborhood2014,
  title = {Reconciling Phonological Neighborhood Effects in Speech Production through Single Trial Analysis},
  author = {Sadat, Jasmin and Martin, Clara D. and Costa, Albert and Alario, F. -Xavier},
  year = {2014},
  month = feb,
  journal = {Cognitive Psychology},
  volume = {68},
  pages = {33--58},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2013.10.001},
  abstract = {A crucial step for understanding how lexical knowledge is represented is to describe the relative similarity of lexical items, and how it influences language processing. Previous studies of the effects of form similarity on word production have reported conflicting results, notably within and across languages. The aim of the present study was to clarify this empirical issue to provide specific constraints for theoretical models of language production. We investigated the role of phonological neighborhood density in a large-scale picture naming experiment using fine-grained statistical models. The results showed that increasing phonological neighborhood density has a detrimental effect on naming latencies, and re-analyses of independently obtained data sets provide supplementary evidence for this effect. Finally, we reviewed a large body of evidence concerning phonological neighborhood density effects in word production, and discussed the occurrence of facilitatory and inhibitory effects in accuracy measures. The overall pattern shows that phonological neighborhood generates two opposite forces, one facilitatory and one inhibitory. In cases where speech production is disrupted (e.g. certain aphasic symptoms), the facilitatory component may emerge, but inhibitory processes dominate in efficient naming by healthy speakers. These findings are difficult to accommodate in terms of monitoring processes, but can be explained within interactive activation accounts combining phonological facilitation and lexical competition.},
  langid = {english},
  keywords = {Lexical access,Mental lexicon,Neighborhood density,Phonological similarity,Speech production},
  file = {/Users/sarah/Zotero/storage/HIFTK2J6/Sadat et al. - 2014 - Reconciling phonological neighborhood effects in s.pdf;/Users/sarah/Zotero/storage/NPKYDASE/S0010028513000571.html}
}

@article{sadatReconcilingPhonologicalNeighborhood2014a,
  title = {Reconciling Phonological Neighborhood Effects in Speech Production through Single Trial Analysis},
  author = {Sadat, Jasmin and Martin, Clara D. and Costa, Albert and Alario, F. -Xavier},
  year = {2014},
  month = feb,
  journal = {Cognitive Psychology},
  volume = {68},
  pages = {33--58},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2013.10.001},
  abstract = {A crucial step for understanding how lexical knowledge is represented is to describe the relative similarity of lexical items, and how it influences language processing. Previous studies of the effects of form similarity on word production have reported conflicting results, notably within and across languages. The aim of the present study was to clarify this empirical issue to provide specific constraints for theoretical models of language production. We investigated the role of phonological neighborhood density in a large-scale picture naming experiment using fine-grained statistical models. The results showed that increasing phonological neighborhood density has a detrimental effect on naming latencies, and re-analyses of independently obtained data sets provide supplementary evidence for this effect. Finally, we reviewed a large body of evidence concerning phonological neighborhood density effects in word production, and discussed the occurrence of facilitatory and inhibitory effects in accuracy measures. The overall pattern shows that phonological neighborhood generates two opposite forces, one facilitatory and one inhibitory. In cases where speech production is disrupted (e.g. certain aphasic symptoms), the facilitatory component may emerge, but inhibitory processes dominate in efficient naming by healthy speakers. These findings are difficult to accommodate in terms of monitoring processes, but can be explained within interactive activation accounts combining phonological facilitation and lexical competition.},
  langid = {english},
  keywords = {Lexical access,Mental lexicon,Neighborhood density,Phonological similarity,Speech production},
  file = {/Users/sarah/Zotero/storage/78JVHPLR/Sadat et al. - 2014 - Reconciling phonological neighborhood effects in s.pdf}
}

@article{sanfordHowDoesExtraversion2009,
  title = {How {{Does}} the {{Extraversion Personality Trait Influence False Recall}} with the {{Deese}}\textendash{{Roediger}}\textendash{{McDermott}} ({{DRM}}) {{Paradigm}}?},
  author = {Sanford, Louis C. and Fisk, John E.},
  year = {2009},
  month = dec,
  journal = {Journal of Research in Personality},
  volume = {43},
  number = {6},
  pages = {972--977},
  issn = {0092-6566},
  doi = {10.1016/j.jrp.2009.05.011},
  abstract = {Relative to more introverted persons, extraverts have been found to exhibit better recall and recognition in a range of memory paradigms including demonstrating a superior semantic priming effect. The present study sought to establish whether this aspect of personality might be associated with the false memory paradigm developed by Deese, Roediger, and McDermott (the DRM paradigm). Lists containing semantically related words were presented to extraverts, ambiverts, and introverts. Compared to the other two groups, extraverts falsely recalled more critical lures (words that although semantically related were not in the original lists) and non-list words. The results are discussed in relation to the concept of spreading activation.},
  keywords = {DRM,Extraversion,False memory,Spreading activation}
}

@article{sargDoesMelodicAccent2006,
  title = {Does Melodic Accent Shape the Melody Contour in {{Estonian}} Folk Songs?},
  author = {S{\"a}rg, Taive},
  year = {2006},
  month = jan,
  abstract = {This paper tests the effect of Thomassen's (1982) m odel of melodic accent in unaccompanied isochronous mono- phonic folk song style regilaul . According to Thomassen, the value of melodic accent depends on the shape of mel- ody contour. Regilaul songs are ancient Estonian folk songs that differ from Western folk song tradition. It was supposed that the singers' perception of melodicall y ac- cented points has shaped melody contours in oral tr adition, Melodic accents were probably used to accentuate le xical stresses. Lexical stress on the word's initial syllable is of central importance as a carrier of phonological inf orma- tion in Estonian. The coincidence of melodic accents with lexical str esses was examined for two types of verses: ordinary vers es that have lexical stresses on metrically strong position s, and broken verses that have (one or more) lexical stres s(es) on metrically weak position(s). It was assumed that le xical stresses, metric stresses and melodic accents are w ell syn- chronized in ordinary verses, but singers vary the melody contour in broken verses to increase melodic accent on metrically weak position(s) carrying lexically stre ss(ed) syllables.},
  file = {/Users/sarah/Zotero/storage/SDZ5VGVQ/Särg - 2006 - Does melodic accent shape the melody contour in Es.pdf}
}

@article{sargMelodicAccentEstonian2007,
  title = {Melodic Accent in {{Estonian}} and {{Lithuanian}} Folk Songs},
  author = {S{\"a}rg, Taive and Ambrazevi{\v c}ius, Rytis},
  year = {2007},
  month = sep,
  pages = {15--19},
  abstract = {Background in music psychology. Musical accent may be defined as an increased prominence ascribed to a sound event. Of the various types of accent proposed by music theorists, one of the most contentious has been the so-called 'melodic accent'. Huron and Royal (1996) have tested eight conceptions of melodic accent of three samples of music: Western folk music and art music, Gregorian chant. The results for all three studies were consistent with a perceptual model of melodic accent developed by Thomassen (1982). Although the correlation with Thomassen's model of melodic accent was significant, the effect magnitude was relatively small and emerged most clearly in unaccompanied isochronous solo passages. Background in ethnomusicology. Estonian folk songs called regilaul are ancient unaccompanied isochronous monophonic folk songs that differ from Western folk song tradition. Unaccompanied isochronous folk songs are also found in Lithuanian tradition, although they do not comprise homogeneous stylistic layer like Estonian regilaul. Some Estonian and Lithuanian tunes are varied in the course of singing, in terms of melodic contours. It is proved in the earlier work (S\"arg 2006) that melodic accent in interaction with lexical stress has an effect on shaping melody contour in regilaul. On purpose, singers synchronize melodic accents to lexical stresses both in metrically regular (ordinary) verses and in metrically varied (broken) verses. But still is the question why some melodies are not varied in the case of metrical variation. Aims. First, we aim to test the effect of Thomassen's model of melodic accent in Estonian contemporary melodies, composed in regilaul style and in Lithuanian unaccompanied isochronous folk songs. The second question is why there are several melodies in old regilaul tradition as well as in Lithuanian vocal tradition that usually remain invariable.},
  file = {/Users/sarah/Zotero/storage/J6ZH3BDH/Särg and Ambrazevičius - 2007 - Melodic accent in Estonian and Lithuanian folk son.pdf}
}

@article{sarvRegilaulClearingAlliterative1999,
  title = {Regilaul: {{Clearing}} the Alliterative Haze},
  shorttitle = {Regilaul},
  author = {Sarv, Mari},
  year = {1999},
  journal = {Folklore: Electronic Journal of Folklore},
  volume = {10},
  pages = {126--140},
  issn = {14060957, 14060949},
  doi = {10.7592/FEJF1999.10.alliter},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/E5VRSVKP/Sarv - 1999 - Regilaul Clearing the alliterative haze.pdf}
}

@article{scarboroughClarityCommunicationClear2013,
  title = {Clarity in {{Communication}}: ``{{Clear}}'' {{Speech Authenticity}} and {{Lexical Neighborhood Density Effects}} in {{Speech Production}} and {{Perception}}},
  shorttitle = {Clarity in {{Communication}}},
  author = {Scarborough, Rebecca and Zellou, Georgia},
  year = {2013},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {134},
  number = {5},
  pages = {3793--3807},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.4824120},
  abstract = {Speech produced in the context of real or imagined communicative difficulties is characterized by hyperarticulation. Phonological neighborhood density (ND) conditions similar patterns in production: Words with many neighbors are hyperarticulated relative to words with fewer; Hi ND words also show greater coarticulation than Lo ND words [e.g., Scarborough, R. (2012). ``Lexical similarity and speech production: Neighborhoods for nonwords,'' Lingua 122(2), 164\textendash{} 176]. Coarticulatory properties of ``clear speech'' are more variable across studies. This study examined hyperarticulation and nasal coarticulation across five real and simulated clear speech contexts and two neighborhood conditions, and investigated consequences of these details for word perception. The data revealed a continuum of (attempted) clarity, though real listener-directed speech (Real) differed from all of the simulated styles. Like the clearest simulated-context speech (spoken ``as if to someone hard-of-hearing''\textemdash{} HOH), Real had greater hyperarticulation than other conditions. However, Real had the greatest coarticulatory nasality while HOH had the least. Lexical decisions were faster for words from Real than from HOH, indicating that speech produced in real communicative contexts (with hyperarticulation and increased coarticulation) was perceptually better than simulated clear speech. Hi ND words patterned with Real in production, and Real Hi ND words were clear enough to overcome the dense neighborhood disadvantage.}
}

@article{scheerCODAMIRRORV22010,
  title = {{{THE CODA MIRROR V2}}},
  author = {SCHEER, TOBIAS and ZIKOV{\'A}, MARK{\'E}TA},
  year = {2010},
  journal = {Acta Linguistica Hungarica},
  volume = {57},
  number = {4},
  pages = {411--431},
  issn = {1216-8076},
  abstract = {Abstract: This article further develops Coda Mirror theory (S\'eg\'eral\textendash{} Scheer 2001a): its short-comings are identified (overgeneration: the super-weak position predicted has no empirical echo, and the four-way parametric situation predicted in domain-final position is confronted with only two attested configurations), and a solution is proposed by dispensing with the equal-rightedness of government and licensing. Government over licensing is the principle proposed: no constituent can simultaneously be the target of both lateral forces, and if both could in principle apply, government is given precedence. A welcome by-product of this move is a new definition of open vs. closed syllables that makes sense: vowels in the former, but not in the latter, are licensed.}
}

@article{schellenbergSingingToneLanguage,
  title = {Singing in a {{Tone Language}}: {{Shona}}},
  author = {Schellenberg, Murray},
  pages = {9},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/Q3K2E8NH/Schellenberg - Singing in a Tone Language Shona.pdf}
}

@book{ScholarsTalkBeing,
  title = {Scholars {{Talk}} about {{Being Black}} on {{Campus}} in 2020}
}

@article{schuchatPublicHealthResponse2020,
  title = {Public {{Health Response}} to the {{Initiation}} and {{Spread}} of {{Pandemic COVID-19}} in the {{United States}}, {{February}} 24\textendash{{April}} 21, 2020},
  author = {Schuchat, Anne},
  year = {2020},
  month = may,
  journal = {MMWR Morb Mortal Wkly Rep},
  volume = {69},
  number = {18},
  pages = {551--556},
  issn = {0149-2195},
  doi = {10.15585/mmwr.mm6918e2},
  pmcid = {PMC7737947},
  pmid = {32379733}
}

@article{schwartzProblemsRepresentation,
  title = {"{{The}}" {{Problems}} of {{Representation}}},
  author = {Schwartz, Robert},
  journal = {Social Research; Camden, N. J.},
  volume = {51},
  number = {4},
  pages = {1047--1064},
  issn = {0037-783X},
  langid = {english},
  keywords = {Social Sciences (General)}
}

@article{shengListMemoryYoung2015,
  title = {List {{Memory}} in {{Young Adults With Language Learning Disability}}},
  author = {Sheng, Li and Byrd, Courtney T. and McGregor, Karla K. and Zimmerman, Hannah and Bludau, Kadee},
  year = {2015},
  month = apr,
  journal = {Journal of Speech, Language and Hearing Research (Online); Rockville},
  volume = {58},
  number = {2},
  pages = {336--344},
  doi = {http://dx.doi.org/10.1044/2015_JSLHR-L-13-0143},
  abstract = {The purpose of this study was to characterize the verbal memory limitations of young adults with language learning disability (LLD). Sixteen young adults with LLD and 34 age-and education-matched controls with typical language participated in a Deese-Roediger-McDermott list recall experiment. Participants listened to 12-item word lists that converged on a nonpresented critical item semantically, or dually in a hybrid list and recalled words in no particular order. Group comparisons were made on veridical recall and false recall of nonpresented critical items. Recall performance was analyzed by list type and list position to examine potential differences in the quality of memorial processes. The LLD group produced fewer veridical recalls than the controls. Both groups demonstrated list type and list position effects in veridical recall. False recall of the critical items was comparable in the 2 groups and varied by list type in predictable ways.},
  copyright = {Copyright American Speech-Language-Hearing Association Apr 2015},
  langid = {english},
  keywords = {Colleges \& universities,Handicapped–Hearing Impaired,Learning disabilities,Medical Sciences–Otorhinolaryngology,Memory,Semantics,Short term}
}

@article{shiffrinEffectsCategoryLength,
  title = {Effects of {{Category Length}} and {{Strength}} on {{Familiarity}} in {{Recognition}}},
  author = {Shiffrin, Richard M and Huber, David E and Marinelli, Kim},
  pages = {21},
  langid = {english}
}

@book{shookCLEARPONDEnglish2012,
  title = {{{CLEARPOND-English}}},
  author = {Shook, Anthony},
  year = {2012},
  journal = {CLEARPOND: Cross-Linguistic Easy-Access Resource for Phonological and Orthographic Neighborhood Densities},
  copyright = {Northwestern Bilingualism and Psycholinguistics Group}
}

@article{siewCommunityStructurePhonological2013,
  title = {Community {{Structure}} in the {{Phonological Network}}},
  author = {Siew, Cynthia S. Q.},
  year = {2013},
  journal = {Front. Psychol.},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00553},
  abstract = {Community structure, which refers to the presence of densely connected groups within a larger network, is a common feature of several real-world networks from a variety of domains such as the human brain, social networks of hunter-gatherers and business organizations, and the World Wide Web (Porter et al., 2009). Using a community detection technique known as the Louvain optimization method, 17 communities were extracted from the giant component of the phonological network described in Vitevitch (2008). Additional analyses comparing the lexical and phonological characteristics of words in these communities against words in randomly generated communities revealed several novel discoveries. Larger communities tend to consist of short, frequent words of high degree and low age of acquisition ratings, and smaller communities tend to consist of longer, less frequent words of low degree and high age of acquisition ratings. Real communities also contained fewer different phonological segments compared to random communities, although the number of occurrences of phonological segments found in real communities was much higher than that of the same phonological segments in random communities. Interestingly, the observation that relatively few biphones occur very frequently and a large number of biphones occur rarely within communities mirrors the pattern of the overall frequency of words in a language (Zipf, 1935). The present findings have important implications for understanding the dynamics of activation spread among words in the phonological network that are relevant to lexical processing, as well as understanding the mechanisms that underlie language acquisition and the evolution of language.},
  langid = {english},
  keywords = {community structure,language acquisition,language evolution,Lexical Processing,mental Lexicon,Network Science,phonology}
}

@article{sluijterSpectralBalanceAcoustic1996,
  title = {Spectral Balance as an Acoustic Correlate of Linguistic Stress},
  author = {Sluijter, Agaath M. C. and {van Heuven}, Vincent J.},
  year = {1996},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {100},
  number = {4},
  pages = {2471--2485},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.417955},
  file = {/Users/sarah/Zotero/storage/JE27NT93/Sluijter and van Heuven - 1996 - Spectral balance as an acoustic correlate of lingu.pdf}
}

@article{smiljanicFaceMasksSpeaking2021,
  title = {Face Masks and Speaking Style Affect Audio-Visual Word Recognition and Memory of Native and Non-Native Speech},
  author = {Smiljanic, Rajka and Keerstock, Sandie and Meemann, Kirsten and Ransom, Sarah M.},
  year = {2021},
  month = jun,
  journal = {The Journal of the Acoustical Society of America},
  volume = {149},
  number = {6},
  pages = {4013--4023},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0005191},
  abstract = {Though necessary, protective mask wearing in response to the COVID-19 pandemic presents communication challenges. The present study examines how signal degradation and loss of visual information due to masks affects intelligibility and memory for native and non-native speech. We also test whether clear speech can alleviate perceptual difficulty for masked speech. One native and one non-native speaker of English recorded video clips in conversational speech without a mask and conversational and clear speech with a mask. Native English listeners watched video clips presented in quiet or mixed with competing speech. The results showed that word recognition and recall of speech produced with a mask can be as accurate as without a mask in optimal listening conditions. Masks affected non-native speech processing at easier noise levels than native speech. Clear speech with a mask significantly improved accuracy in all listening conditions. Speaking clearly, reducing noise, and using surgical masks as well as good signal amplification can help compensate for the loss of intelligibility due to background noise, lack of visual cues, physical distancing, or non-native speech. The findings have implications for communication in classrooms and hospitals where listeners interact with teachers and healthcare providers, oftentimes non-native speakers, through their protective barriers.},
  copyright = {All rights reserved},
  file = {/Users/sarah/Zotero/storage/BLWMTEZB/Smiljanic et al. - 2021 - Face masks and speaking style affect audio-visual .pdf}
}

@article{smiljanicProductionPerceptionClear2005,
  title = {Production and {{Perception}} of {{Clear Speech}} in {{Croatian}} and {{English}}},
  author = {Smiljani{\'c}, Rajka and Bradlow, Ann R.},
  year = {2005},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {118},
  number = {3},
  pages = {1677--1688},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.2000788},
  abstract = {Previous research has established that naturally produced English clear speech is more intelligible than English conversational speech. The major goal of this paper was to establish the presence of the clear speech effect in production and perception of a language other than English, namely Croatian. A systematic investigation of the conversational-to-clear speech transformations across languages with different phonological properties (e.g., large versus small vowel inventory) can provide a window into the interaction of general auditory-perceptual and phonological, structural factors that contribute to the high intelligibility of clear speech. The results of this study showed that naturally produced clear speech is a distinct, listener-oriented, intelligibility-enhancing mode of speech production in both languages. Furthermore, the acoustic-phonetic features of the conversational-to-clear speech transformation revealed cross-language similarities in clear speech production strategies. In both languages, talkers exhibited a decrease in speaking rate and an increase in pitch range, as well as an expansion of the vowel space. Notably, the findings of this study showed equivalent vowel space expansion in English and Croatian clear speech, despite the difference in vowel inventory size across the two languages, suggesting that the extent of vowel contrast enhancement in hyperarticulated clear speech is independent of vowel inventory size.},
  file = {/Users/sarah/Zotero/storage/E2D2LPIE/Smiljanić and Bradlow - 2005 - Production and Perception of Clear Speech in Croat.pdf}
}

@article{smiljanicTemporalOrganizationEnglish2008,
  title = {Temporal {{Organization}} of {{English Clear}} and {{Conversational Speech}}},
  author = {Smiljani{\'c}, Rajka and Bradlow, Ann R.},
  year = {2008},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {124},
  number = {5},
  pages = {3171--3182},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.2990712},
  abstract = {This study investigated the effect of hyperarticulated, intelligibility-enhancing clear speech on temporal characteristics as reflected in number, durations, and variability of consonant and vowel intervals in sentence- and paragraph-length utterances. The results of sentence-in-noise listening tests showed a consistent clear speech intelligibility gain across the utterances of varying complexity indicating that the talkers successfully maintained clear speech articulatory modifications throughout longer stretches of speech. The acoustic analysis revealed that some temporal restructuring accompanied changes in speaking style. This temporal restructuring was observed in the insertion of consonant and vowel segments that were dropped or coarticulated in conversational speech and in an increase in the number of prosodic phrases for clear speech. Importantly, coefficients of variation (variation of consonantal and vocalic intervals normalized for changes in speaking rate) for both consonantal and vowel intervals remained stable in the two speaking styles. Overall, these results suggest that increased intelligibility of clear speech may be attributed to prosodic structure enhancement (increased phrasing and enhanced segmentability) and stable global temporal properties.}
}

@article{soleAmbiguityLanguageNetworks2015,
  title = {Ambiguity in {{Language Networks}}},
  author = {Sol{\'e}, Ricard V. and Seoane, Lu{\'i}s F.},
  year = {2015},
  journal = {The Linguistic Review},
  volume = {32},
  number = {1},
  pages = {5--35},
  issn = {1613-3676},
  doi = {10.1515/tlr-2014-0014},
  abstract = {Human language defines the most complex outcomes of evolution. The emergence of such an elaborated form of communication allowed humans to create extremely structured societies and manage symbols at different levels including, among others, semantics. All linguistic levels have to deal with an astronomic combinatorial potential that stems from the recursive nature of languages. This recursiveness is indeed a key defining trait. However, not all words are equally combined nor frequent. In breaking the symmetry between less and more often used and between less and more meaning-bearing units, universal scaling laws arise. Such laws, common to all human languages, appear on different stages from word inventories to networks of interacting words. Among these seemingly universal traits exhibited by language networks, ambiguity appears to be a specially relevant component. Ambiguity is avoided in most computational approaches to language processing, and yet it seems to be a crucial element of language architecture. Here we review the evidence both from language network architecture and from theoretical reasonings based on a least effort argument. Ambiguity is shown to play an essential role in providing a source of language efficiency, and is likely to be an inevitable byproduct of network growth.},
  keywords = {language networks,least-effort language,semantic ambiguity,Zipf law}
}

@article{sommersWhoReallyLives1999,
  title = {Who {{Really Lives Next Door}}: {{Creating False Memories}} with {{Phonological Neighbors}}},
  shorttitle = {Who {{Really Lives Next Door}}},
  author = {Sommers, Mitchell S. and Lewis, Bryan P.},
  year = {1999},
  month = jan,
  journal = {Journal of Memory and Language},
  volume = {40},
  number = {1},
  pages = {83--108},
  issn = {0749-596X},
  doi = {10.1006/jmla.1998.2614},
  abstract = {Three experiments were conducted to examine false recall and recognition with lists of phonologically related words. Experiment 1 found that the pattern of false memories (both recall and recognition) obtained for lists of phonological associates was similar to results that have been observed with semantically associated word lists (Roediger \& McDermott, 1995). Experiment 2 demonstrated that increasing the number of talkers producing list items did not significantly affect either false recall or recognition. Experiment 2 also showed that the representations underlying false memories can contain highly detailed voice information. Experiment 3 found that changing to lists with the least, rather than most, confusable phonological associates of critical (nonpresented) items significantly reduced the incidence of false memories. The findings are discussed within the framework of the Neighborhood Activation Model of spoken word recognition and suggest that similar mechanisms may mediate false memories with lists of semantic and phonological associates.},
  langid = {english},
  keywords = {associative processes,false memory,neighborhood activation model}
}

@article{songEffectsCoarticulationMorphological2013,
  title = {The {{Effects}} of {{Coarticulation}} and {{Morphological Complexity}} on the {{Production}} of {{English Coda Clusters}}: {{Acoustic}} and {{Articulatory Evidence}} from 2-{{Year-Olds}} and {{Adults Using Ultrasound}}},
  shorttitle = {The {{Effects}} of {{Coarticulation}} and {{Morphological Complexity}} on the {{Production}} of {{English Coda Clusters}}},
  author = {Song, Jae Yung and Demuth, Katherine and {Shattuck-Hufnagel}, Stefanie and M{\'e}nard, Lucie},
  year = {2013},
  month = may,
  journal = {Journal of Phonetics},
  volume = {41},
  number = {3},
  pages = {281--295},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2013.03.004},
  abstract = {Most studies of phonological development have explored the acquisition of segments, syllables and words using perceptual/transcription methods. Less is known about the articulatory aspects of early speech, or the development of articulatory-acoustic mapping. Recent research on adult speech finds that coarticulation effects are evidenced in both the acoustics and the articulatory gestures, and suggests tighter coarticulation and less variability for monomorphemic compared to polymorphemic segment sequences. The present study explored phonological context and morphological effects in the speech of five adults and five 2-year-olds, combining acoustic and articulatory analysis from ultrasound recordings. The results show that coarticulation effects are found in the word-final consonant cluster (box) for both adults and children. For children, these were evidenced only in the articulatory data. In addition, both age groups showed differences in tongue height between the monomorphemic (box) and bimorphemic (rocks) clusters, suggesting a possible morphological effect. These findings confirm that ultrasound methods can be successfully employed to explore aspects of early gestural development in children as young as 2, and raise many questions regarding the nature of speech planning processes as a function of lexical versus morphological form.},
  langid = {english}
}

@book{SpeakingHearingClearly,
  title = {Speaking and {{Hearing Clearly}}: {{Talker}} and {{Listener Factors}} in {{Speaking Style Changes}} - {{Smiljani\'c}} - 2009 - {{Language}} and {{Linguistics Compass}} - {{Wiley Online Library}}}
}

@article{SpeechProsodyBroca1982,
  title = {Speech {{Prosody}} in {{Broca}}'s {{Aphasia}}},
  year = {1982},
  month = jul,
  journal = {Brain and Language},
  volume = {16},
  number = {2},
  pages = {171--190},
  publisher = {{Academic Press}},
  issn = {0093-934X},
  doi = {10.1016/0093-934X(82)90082-7},
  abstract = {Because speech prosody is thought to be impaired in Broca's aphasia, we conducted three experiments using Broca's aphasics and nonneurological control\textbackslash ldots},
  langid = {english}
}

@incollection{sperberMappingMentalPublic1998,
  title = {The {{Mapping Between}} the {{Mental}} and the {{Public Lexicon}}},
  booktitle = {[{{Book Chapter}}]},
  author = {Sperber, Dan and Wilson, Deirdre},
  editor = {Carruthers, Peter and Boucher, Jill},
  year = {1998},
  pages = {184--200},
  publisher = {{Cambridge University Press}}
}

@article{stamerPhonologicalSimilarityInfluences2012,
  title = {Phonological {{Similarity Influences Word Learning}} in {{Adults Learning Spanish}} as a {{Foreign Language}}},
  author = {Stamer, Melissa K. and Vitevitch, Michael S.},
  year = {2012},
  month = jul,
  journal = {Biling (Camb Engl)},
  volume = {15},
  number = {3},
  pages = {490--502},
  issn = {1366-7289},
  doi = {10.1017/S1366728911000216},
  abstract = {Neighborhood density\textemdash{} the number of words that sound similar to a given word ()\textemdash{} influences word-learning in native English speaking children and adults (; ): novel words with many similar sounding English words (i.e., dense neighborhood) are learned more quickly than novel words with few similar sounding English words (i.e., sparse neighborhood). The present study examined how neighborhood density influences word-learning in native English speaking adults learning Spanish as a foreign language. Students in their third-semester of Spanish language classes learned advanced Spanish words that sounded similar to many known Spanish words (i.e., dense neighborhood) or sounded similar to few known Spanish words (i.e., sparse neighborhood). In three word-learning tasks, performance was better for Spanish words with dense rather than sparse neighborhoods. These results suggest that a similar mechanism may be used to learn new words in a native and a foreign language.},
  pmcid = {PMC3742450},
  pmid = {23950692}
}

@article{steedmanSURFACECOMPOSITIONALSEMANTICSENGLISH2014,
  title = {{{THE SURFACE-COMPOSITIONAL SEMANTICS OF ENGLISH INTONATION}}},
  author = {Steedman, Mark},
  year = {2014},
  journal = {Language},
  volume = {90},
  number = {1},
  pages = {2--57},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  abstract = {This article proposes a syntax and a semantics for intonation in English and some related languages. The semantics is 'surface-compositional', in the sense that syntactic derivation constructs information-structural logical form monotonically, without rules of structural revision, and without autonomous rules of 'focus projection'. This is made possible by the generalized notion of syntactic constituency afforded by combinatory categorial grammar (CCG)\textemdash{} in particular, the fact that its rules are restricted to string-adjacent type-driven combination. In this way, the grammar unites intonation structure and information structure with surface-syntactic derivational structure and Montague-style compositional semantics, even when they deviate radically from traditional surface structure. The article revises and extends earlier CCG-based accounts of intonational semantics, grounding hitherto informal notions like 'theme' and 'rheme' (a.k.a. 'topic' and 'comment', 'presupposition' and 'focus', etc.) and 'background' and 'contrast' (a.k.a. 'given' and 'new', 'focus', etc.) in a logic of speaker/hearer supposition and update, using a version of Rooth's alternative semantics. A CCG grammar fragment is defined that constrains language-specific intonation and its interpretation more narrowly than previous attempts.}
}

@article{steedmanSURFACECOMPOSITIONALSEMANTICSENGLISH2014a,
  title = {{{THE SURFACE-COMPOSITIONAL SEMANTICS OF ENGLISH INTONATION}}},
  author = {Steedman, Mark},
  year = {2014},
  journal = {Language},
  volume = {90},
  number = {1},
  pages = {2--57},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  abstract = {This article proposes a syntax and a semantics for intonation in English and some related languages. The semantics is 'surface-compositional', in the sense that syntactic derivation constructs information-structural logical form monotonically, without rules of structural revision, and without autonomous rules of 'focus projection'. This is made possible by the generalized notion of syntactic constituency afforded by combinatory categorial grammar (CCG)\textemdash{} in particular, the fact that its rules are restricted to string-adjacent type-driven combination. In this way, the grammar unites intonation structure and information structure with surface-syntactic derivational structure and Montague-style compositional semantics, even when they deviate radically from traditional surface structure. The article revises and extends earlier CCG-based accounts of intonational semantics, grounding hitherto informal notions like 'theme' and 'rheme' (a.k.a. 'topic' and 'comment', 'presupposition' and 'focus', etc.) and 'background' and 'contrast' (a.k.a. 'given' and 'new', 'focus', etc.) in a logic of speaker/hearer supposition and update, using a version of Rooth's alternative semantics. A CCG grammar fragment is defined that constrains language-specific intonation and its interpretation more narrowly than previous attempts.}
}

@inproceedings{stellaInvestigatingPhoneticOrganisation2016,
  title = {Investigating the {{Phonetic Organisation}} of the {{English Language}} via {{Phonological Networks}}, {{Percolation}} and {{Markov Models}}},
  booktitle = {Proceedings of {{ECCS}} 2014},
  author = {Stella, Massimo and Brede, Markus},
  editor = {Battiston, Stefano and De Pellegrini, Francesco and Caldarelli, Guido and Merelli, Emanuela},
  year = {2016},
  series = {Springer {{Proceedings}} in {{Complexity}}},
  pages = {219--229},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-29228-1_19},
  abstract = {Applying tools from network science and statistical mechanics, this paper represents an interdisciplinary analysis of the phonetic organisation of the English language. By using open datasets, we build phonological networks, where nodes are the phonetic pronunciations of words and edges connect words differing by the addition, deletion, or substitution of exactly one phoneme. We present an investigation of whether the topological features of this phonological network reflect only lower or also higher order correlations in phoneme organisation. We address this question by exploring artificially constructed repertoires of words, constructing phonological networks for these repertoires, and comparing them to the network constructed from the real data. Artificial repertoires of words are built to reflect increasingly higher order statistics of the English corpus. Hence, we start with percolation-type experiments in which phonemes are sampled uniformly at random to construct words, then sample from the real phoneme frequency distribution, and finally we consider repertoires resulting from Markov processes of first, second, and third order. As expected, we find that percolation-type experiments constitute a poor null model for the real data. However, some network features, such as the relatively high assortative mixing by degree and the clustering coefficient of the English PN, can be retrieved by Markov models for word construction. Nevertheless, even Markov processes up to third order cannot fully reproduce other patterns of the empirical network, such as link densities and component sizes. We conjecture that this difference is related to the combinatorial space the real and the artificial phonological networks are embedded into and that the connectivity properties of phonological networks reflect additional patterns in word organisation in the English language which cannot be captured by lower order phoneme correlations.},
  isbn = {978-3-319-29228-1},
  langid = {english},
  keywords = {Giant Component,Markov Process,Mental Lexicon,Phonological Similarity,Regular Graph}
}

@article{stellaMultiplexModelMental2018,
  title = {Multiplex {{Model}} of {{Mental Lexicon Reveals Explosive Learning}} in {{Humans}}},
  author = {Stella, Massimo},
  year = {2018},
  journal = {SCIEnTIFIC ReportS},
  pages = {11},
  langid = {english}
}

@article{stellaPatternsEnglishLanguage2015,
  title = {Patterns in the {{English Language}}: {{Phonological Networks}}, {{Percolation}} and {{Assembly Models}}},
  shorttitle = {Patterns in the {{English Language}}},
  author = {Stella, Massimo and Brede, Markus},
  year = {2015},
  month = may,
  journal = {J. Stat. Mech.},
  volume = {2015},
  number = {5},
  pages = {P05006},
  issn = {1742-5468},
  doi = {10.1088/1742-5468/2015/05/P05006},
  abstract = {In this paper we provide a quantitative framework for the study of phonological networks (PNs) for the English language by carrying out principled comparisons to null models, either based on site percolation, randomization techniques, or network growth models. In contrast to previous work, we mainly focus on null models that reproduce lower order characteristics of the empirical data. We find that artificial networks matching connectivity properties of the English PN are exceedingly rare: this leads to the hypothesis that the word repertoire might have been assembled over time by preferentially introducing new words which are small modifications of old words. Our null models are able to explain the `power-law-like' part of the degree distributions and generally retrieve qualitative features of the PN such as high clustering, high assortativity coefficient and small-world characteristics. However, the detailed comparison to expectations from null models also points out significant differences, suggesting the presence of additional constraints in word assembly. Key constraints we identify are the avoidance of large degrees, the avoidance of triadic closure and the avoidance of large non-percolating clusters.},
  langid = {english}
}

@article{stellaPatternsEnglishLanguage2015a,
  title = {Patterns in the {{English Language}}: {{Phonological Networks}}, {{Percolation}} and {{Assembly Models}}},
  shorttitle = {Patterns in the {{English Language}}},
  author = {Stella, Massimo and Brede, Markus},
  year = {2015},
  month = may,
  journal = {J. Stat. Mech.},
  volume = {2015},
  number = {5},
  eprint = {1410.4445},
  eprinttype = {arxiv},
  pages = {P05006},
  issn = {1742-5468},
  doi = {10.1088/1742-5468/2015/05/P05006},
  abstract = {In this paper we provide a quantitative framework for the study of phonological networks (PNs) for the English language by carrying out principled comparisons to null models, either based on site percolation, randomization techniques, or network growth models. In contrast to previous work, we mainly focus on null models that reproduce lower order characteristics of the empirical data. We find that artificial networks matching connectivity properties of the English PN are exceedingly rare: this leads to the hypothesis that the word repertoire might have been assembled over time by preferentially introducing new words which are small modifications of old words. Our null models are able to explain the "power-law-like" part of the degree distributions and generally retrieve qualitative features of the PN such as high clustering, high assortativity coefficient, and small-world characteristics. However, the detailed comparison to expectations from null models also points out significant differences, suggesting the presence of additional constraints in word assembly. Key constraints we identify are the avoidance of large degrees, the avoidance of triadic closure, and the avoidance of large non-percolating clusters.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Condensed Matter - Statistical Mechanics}
}

@article{stellaPatternsEnglishLanguage2015b,
  title = {Patterns in the {{English Language}}: {{Phonological Networks}}, {{Percolation}} and {{Assembly Models}}},
  shorttitle = {Patterns in the {{English Language}}},
  author = {Stella, Massimo and Brede, Markus},
  year = {2015},
  month = may,
  journal = {J. Stat. Mech.},
  volume = {2015},
  number = {5},
  eprint = {1410.4445},
  eprinttype = {arxiv},
  pages = {P05006},
  issn = {1742-5468},
  doi = {10.1088/1742-5468/2015/05/P05006},
  abstract = {In this paper we provide a quantitative framework for the study of phonological networks (PNs) for the English language by carrying out principled comparisons to null models, either based on site percolation, randomization techniques, or network growth models. In contrast to previous work, we mainly focus on null models that reproduce lower order characteristics of the empirical data. We find that artificial networks matching connectivity properties of the English PN are exceedingly rare: this leads to the hypothesis that the word repertoire might have been assembled over time by preferentially introducing new words which are small modifications of old words. Our null models are able to explain the "power-law-like" part of the degree distributions and generally retrieve qualitative features of the PN such as high clustering, high assortativity coefficient, and small-world characteristics. However, the detailed comparison to expectations from null models also points out significant differences, suggesting the presence of additional constraints in word assembly. Key constraints we identify are the avoidance of large degrees, the avoidance of triadic closure, and the avoidance of large non-percolating clusters.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Condensed Matter - Statistical Mechanics}
}

@article{stewartFickleFricativesFricative2020,
  title = {Fickle {{Fricatives}}: {{Fricative}} and {{Stop Perception}} in {{Gurindji Kriol}}, {{Roper Kriol}}, and {{Standard Australian English}}},
  shorttitle = {Fickle {{Fricatives}}},
  author = {Stewart, Jesse and Meakins, Felicity and Algy, Cassandra and Ennever, Thomas and Joshua, Angelina},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {2766--2778},
  issn = {0001-4966},
  doi = {10.1121/10.0000991},
  langid = {english}
}

@article{sumbyVisualContributionSpeech1954a,
  title = {Visual {{Contribution}} to {{Speech Intelligibility}} in {{Noise}}},
  author = {Sumby, W. H. and Pollack, Irwin},
  year = {1954},
  month = mar,
  journal = {The Journal of the Acoustical Society of America},
  volume = {26},
  number = {2},
  pages = {212--215},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.1907309}
}

@article{suomiDurationalPatternsNorthern2013,
  title = {Durational Patterns in {{Northern Estonian}} and {{Northern Finnish}}},
  author = {Suomi, Kari and Meister, Einar and Ylitalo, Riikka and Meister, Lya},
  year = {2013},
  month = jan,
  journal = {Journal of Phonetics},
  volume = {41},
  number = {1},
  pages = {1--16},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2012.09.001},
  abstract = {Estonian and Finnish are closely related languages in which quantity is extensively exploited for lexical and grammatical purposes (in both consonants and vowels, independent of each other), yet with several phonological differences between the quantity systems (e.g. a ternary opposition in Estonian, a binary one in Finnish). To date, segment durations in the two languages have not been systematically compared. This paper reports a necessarily explorative experiment with two primary goals: first, to compare the phonetic realisation of quantity in the two languages in selected word structures, and second, to relate the results on accentual lengthening to the predictions of a speech timing framework (White, 2002) that has been developed on the basis of observations in an essentially non-quantity language, namely English. It was observed, besides cross-language differences in the durational realisation of the three-way and two-way quantity contrasts that durationally C1, outside the quantity system in both languages, behaves differently in the two languages. It was also observed that the patterns of accentual lengthening in the two languages are highly consistent with predictions of the timing framework.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/9WXNCYVQ/S009544701200068X.html}
}

@article{tallmanAcousticCorrelatesStress2020,
  title = {The {{Acoustic Correlates}} of {{Stress}} and {{Tone}} in {{Ch\'acobo}} ({{Pano}}): {{A Production Study}}},
  shorttitle = {The {{Acoustic Correlates}} of {{Stress}} and {{Tone}} in {{Ch\'acobo}} ({{Pano}})},
  author = {Tallman, Adam J. R. and {El{\'i}as-Ulloa}, Jos{\'e}},
  year = {2020},
  month = apr,
  journal = {The Journal of the Acoustical Society of America},
  volume = {147},
  number = {4},
  pages = {3028--3042},
  issn = {0001-4966},
  doi = {10.1121/10.0001014},
  langid = {english}
}

@misc{tampereAnthologyEstonianTraditional,
  title = {Anthology of {{Estonian Traditional Music}}},
  author = {Tampere, Herbert},
  abstract = {Anthology of Estonian Traditional Music provides an overview of the earlier folk music tradition of Estonia. The anthology includes the archival recordings 98 regilaul songs and 17 instrumental tunes from the years 1912\textendash 1966.},
  howpublished = {https://www.folklore.ee/pubte/eraamat/rahvamuusika/en/index},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/JD7EEPMB/index.html}
}

@article{temperleyMusicLanguageCorrelationsScotch2011,
  title = {Music-{{Language Correlations}} and the ``{{Scotch Snap}}''},
  author = {Temperley, Nicholas and Temperley, David},
  year = {2011},
  month = sep,
  journal = {Music Perception},
  volume = {29},
  number = {1},
  pages = {51--63},
  publisher = {{University of California Press}},
  issn = {0730-7829},
  doi = {10.1525/mp.2011.29.1.51},
  abstract = {in this study we examine a rhythmic pattern known as the Scotch Snap (SS): a sixteenth-note on the beat followed by a dotted eighth-note. A musical corpus analysis shows that the SS is common in both Scottish and English songs, but virtually nonexistent in German and Italian songs. We explore possible linguistic correlates for this phenomenon. Our reasoning is that languages in which stressed syllables are often short might tend to favor the SS pattern. The traditional distinction between long and short vowels correlates partly with the SS pattern across languages, but not completely. (German allows short stressed vowels, but the SS pattern is not common in German music.) We then examine the duration of stressed syllables in four modern speech corpora: one British English, one German, and two Italian. British English shows a much higher proportion of very short stressed syllables (less than 100 ms) than the other two languages. Four vowels account for a large proportion of very short stressed syllables in British English, and also constitute a large proportion of SS tokens in our English musical corpus. This is the first study known to us that establishes a correlation between speech rhythms in languages and musical rhythms in the songs of those languages.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/P73I2NPW/Music-Language-Correlations-and-the-Scotch-Snap.html}
}

@article{temperleyMusicLanguageCorrelationsScotch2011a,
  title = {Music-{{Language Correlations}} and the ``{{Scotch Snap}}''},
  author = {Temperley, Nicholas and Temperley, David},
  year = {2011},
  month = sep,
  journal = {Music Perception},
  volume = {29},
  number = {1},
  pages = {51--63},
  issn = {0730-7829, 1533-8312},
  doi = {10.1525/mp.2011.29.1.51},
  abstract = {in this study we examine a rhythmic pattern known as the Scotch Snap (SS): a sixteenth-note on the beat followed by a dotted eighth-note. A musical corpus analysis shows that the SS is common in both Scottish and English songs, but virtually nonexistent in German and Italian songs. We explore possible linguistic correlates for this phenomenon. Our reasoning is that languages in which stressed syllables are often short might tend to favor the SS pattern. The traditional distinction between long and short vowels correlates partly with the SS pattern across languages, but not completely. (German allows short stressed vowels, but the SS pattern is not common in German music.) We then examine the duration of stressed syllables in four modern speech corpora: one British English, one German, and two Italian. British English shows a much higher proportion of very short stressed syllables (less than 100 ms) than the other two languages. Four vowels account for a large proportion of very short stressed syllables in British English, and also constitute a large proportion of SS tokens in our English musical corpus. This is the first study known to us that establishes a correlation between speech rhythms in languages and musical rhythms in the songs of those languages.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/E9FXUXD3/Temperley and Temperley - 2011 - Music-Language Correlations and the “Scotch Snap”.pdf}
}

@misc{TernarityBinarityProQuest,
  title = {Ternarity through Binarity - {{ProQuest}}},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
  howpublished = {https://www.proquest.com/docview/305299014?pq-origsite=gscholar\&fromopenview=true},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/WVS8IHZK/305299014.html}
}

@article{tilsenSpeechRhythmAnalysis2013,
  title = {Speech Rhythm Analysis with Decomposition of the Amplitude Envelope: {{Characterizing}} Rhythmic Patterns within and across Languages},
  shorttitle = {Speech Rhythm Analysis with Decomposition of the Amplitude Envelope},
  author = {Tilsen, Sam and Arvaniti, Amalia},
  year = {2013},
  month = jul,
  journal = {The Journal of the Acoustical Society of America},
  volume = {134},
  number = {1},
  pages = {628--639},
  issn = {0001-4966},
  doi = {10.1121/1.4807565},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/BC7IBWL2/Tilsen and Arvaniti - 2013 - Speech rhythm analysis with decomposition of the a.pdf}
}

@inproceedings{tormisProblemsThatRegilaul2007,
  title = {Some\_problems\_with\_that\_regilaul.Pdf},
  booktitle = {{{RING}}},
  author = {Tormis, Veljo},
  year = {2007},
  file = {/Users/sarah/Zotero/storage/VR5URZR4/Some_problems_with_that_regilaul.pdf}
}

@article{traunmullerEffectLocalSpeaking2003,
  title = {The {{Effect}} of {{Local Speaking Rate}} on the {{Perception}} of {{Quantity}} in {{Estonian}}},
  author = {Traunm{\"u}ller, Hartmut and Krull, Diana},
  year = {2003},
  journal = {Phonetica},
  volume = {60},
  number = {3},
  pages = {187--207},
  publisher = {{Karger Publishers}},
  issn = {0031-8388, 1423-0321},
  doi = {10.1159/000073502},
  abstract = {The Estonian language with its elaborate system of contrasts in quantity, whose essentials are described in the paper, is used to investigate human perception of distinctive contrasts in the duration of vowels, consonants and larger units. In the experiments reported, the speaking rate of a preceding or following syllable was manipulated in addition to that of a target V, C or VC sequence that carried a quantity distinction in disyllabic words. The results confirmed that the second syllable in such words, in particular the duration of its vowel, serves as a reference, but they showed segments of additional syllables to contribute in the same direction. The results provided no support for ascribing quantity to any larger units than phonetic segments. Speech rate effects of similar magnitude have been observed in Japanese, while effects of the same kind were found to be smaller in Dutch. These differences may be linked with the functions durational contrasts have in the different languages. It appears that listeners have to adapt more fully to variations in the local speaking rate when there are no additional cues and the functional load of quantity distinctions is high.},
  langid = {english},
  pmid = {14571060},
  file = {/Users/sarah/Zotero/storage/ZNL2UECZ/73502.html}
}

@article{treimanSpecialRoleRimes1995,
  title = {The {{Special Role}} of {{Rimes}} in the {{Description}}, {{Use}}, and {{Acquisition}} of {{English Orthography}}},
  author = {Treiman, Rebecca and Mullennix, John and {Bijeljac-Babic}, Ranka and {Richmond-Welty}, E. Daylene},
  year = {1995},
  journal = {Journal of Experimental Psychology: General},
  volume = {124},
  number = {2},
  pages = {107--136},
  issn = {1939-2222(Electronic),0096-3445(Print)},
  doi = {10.1037/0096-3445.124.2.107},
  abstract = {The links between spellings and sounds in a large set of English words with consonant\textendash{} vowel\textendash{} consonant phonological structure were examined. Orthographic rimes, or units consisting of a vowel grapheme and a final consonant grapheme, had more stable pronunciations than either individual vowels or initial consonant-plus-vowel units. In 2 large-scale studies of word pronunciation, the consistency of pronunciation of the orthographic rime accounted for variance in latencies and errors beyond that contributed by the consistency of pronunciation of the individual graphemes and by other factors. In 3 experiments, as well, children and adults made more errors on words with less consistently pronounced orthographic rimes than on words with more consistently pronounced orthographic rimes. Relations between spellings and sounds in the simple monomorphemic words of English are more predictable when the level of onsets and rimes is taken into account than when only graphemes and phonemes are considered. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Orthography,Phonology,Pronunciation}
}

@article{trenkicDefinitenessSerbianCroatian2004,
  title = {Definiteness in {{Serbian}}/{{Croatian}}/{{Bosnian}} and {{Some Implications}} for the {{General Structure}} of the {{Nominal Phrase}}},
  author = {Trenkic, Danijela},
  year = {2004},
  month = nov,
  journal = {Lingua},
  volume = {114},
  number = {11},
  pages = {1401--1427},
  issn = {00243841},
  doi = {10.1016/j.lingua.2003.09.005},
  abstract = {This paper questions traditional views that in Serbian/Croatian/Bosnian (S/C/B), languages without a system of articles, definiteness may be expressed through some other linguistic means, namely word order, the aspect of adjectives, and demonstrative determiners. While it is assumed that semantic/ pragmatic definiteness as a universal category is inferred in communication though some general principles of goal-oriented behaviour, it is argued that it is not grammaticalised in these languages. The structure of the nominal phrase in S/C/B is discussed, and evidence from an SLA study presented which supports the argument that DP is not projected on top of (full) nominal phrases in S/C/B.},
  langid = {english}
}

@article{turnbullAsymmetricContributionConsonants2017,
  title = {The {{Asymmetric Contribution}} of {{Consonants}} and {{Vowels}} to {{Phonological Similarity}}: {{Evidence}} from {{Lexical Priming}}},
  shorttitle = {The {{Asymmetric Contribution}} of {{Consonants}} and {{Vowels}} to {{Phonological Similarity}}},
  author = {Turnbull, Rory and Peperkamp, Sharon},
  year = {2017},
  month = dec,
  journal = {ML},
  volume = {12},
  number = {3},
  pages = {404--430},
  issn = {1871-1340, 1871-1375},
  doi = {10.1075/ml.17010.tur},
  abstract = {Lexical priming is known to arise from phonological similarity between prime and target, and this phenomenon is an important component of our understanding of the processes of lexical access and competition. However, the precise nature of the role of phonological similarity in lexical priming is understudied. In the present study, two experiments were conducted in which participants performed auditory lexical decision on CVC targets which were preceded by primes that either matched the target in all phonemes (CVC condition), in the first two phonemes (CV\_ condition), the last two phonemes (\_VC condition), the initial and last phonemes (C\_C condition) or no phonemes (unrelated condition). Relative to the unrelated condition, all conditions except CV\_ led to facilitation of response time to target words. The \_VC and C\_C conditions led to equivalent facilitation magnitude, while the CV\_ condition showed neither facilitation nor inhibition. Accounting for these results requires appeal to processes of lexical competition and also to the notion that phonemes do not lend equivalent phonological similarity; that is, vowels and consonants are processed differently.},
  langid = {english}
}

@article{tylerCrossLanguageDifferencesCue2009,
  title = {Cross-{{Language Differences}} in {{Cue Use}} for {{Speech Segmentation}}},
  author = {Tyler, Michael D. and Cutler, Anne},
  year = {2009},
  month = jul,
  journal = {The Journal of the Acoustical Society of America},
  volume = {126},
  number = {1},
  pages = {367--376},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.3129127}
}

@misc{UsefulnessMetricsQuantification,
  title = {The Usefulness of Metrics in the Quantification of Speech Rhythm | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.wocn.2012.02.003},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0095447012000137?token=1D09186D68E143DA07EF7B9A0D9108CF9869F4874FC5ABB943BE0D5E70ADA9AE81C534AB8E0258A5EC8A3AF7A7E623C3\&originRegion=us-east-1\&originCreation=20211011170942},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/ARSJQLSI/S0095447012000137.html}
}

@article{vanalphenEffectVoiceOnset2006,
  title = {The {{Effect}} of {{Voice Onset Time Differences}} on {{Lexical Access}} in {{Dutch}}.},
  author = {{van Alphen}, Petra M. and McQueen, James M.},
  year = {2006},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {32},
  number = {1},
  pages = {178--196},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/0096-1523.32.1.178},
  langid = {english}
}

@article{vanengenClearSpeechLexical2017,
  title = {Clear {{Speech}} and {{Lexical Competition}} in {{Younger}} and {{Older Adult Listeners}}},
  author = {Van Engen, Kristin J.},
  year = {2017},
  month = aug,
  journal = {The Journal of the Acoustical Society of America},
  volume = {142},
  number = {2},
  pages = {1067--1077},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.4998708},
  abstract = {This study investigated whether clear speech reduces the cognitive demands of lexical competition by crossing speaking style with lexical difficulty. Younger and older adults identified more words in clear versus conversational speech and more easy words than hard words. An initial analysis suggested that the effect of lexical difficulty was reduced in clear speech, but more detailed analyses within each age group showed this interaction was significant only for older adults. The results also showed that both groups improved over the course of the task and that clear speech was particularly helpful for individuals with poorer hearing: for younger adults, clear speech eliminated hearing-related differences that affected performance on conversational speech. For older adults, clear speech was generally more helpful to listeners with poorer hearing. These results suggest that clear speech affords perceptual benefits to all listeners and, for older adults, mitigates the cognitive challenge associated with identifying words with many phonological neighbors.}
}

@article{vanengenListeningEffortAccented2014,
  title = {Listening {{Effort}} and {{Accented Speech}}},
  author = {Van Engen, Kristin J. and Peelle, Jonathan E.},
  year = {2014},
  journal = {Front. Hum. Neurosci.},
  volume = {8},
  publisher = {{Frontiers}},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2014.00577},
  abstract = {Listening effort and accented speech},
  langid = {english},
  keywords = {accent,listening effort,speech comprehension,Speech Perception,speech perception in noise}
}

@book{vicentiniNotesObservations,
  title = {Notes and {{Observations From}}},
  author = {Vicentini, Alessandra and Milano, Universit{\`a}},
  abstract = {in Language}
}

@article{vidalNeuralSignalViolations2019,
  title = {Neural {{Signal}} to {{Violations}} of {{Abstract Rules Using Speech-Like Stimuli}}},
  author = {Vidal, Yamil and Brusini, Perrine and Bonfieni, Michela and Mehler, Jacques and Bekinschtein, Tristan A.},
  year = {2019},
  month = sep,
  journal = {eNeuro},
  volume = {6},
  number = {5},
  publisher = {{Society for Neuroscience}},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0128-19.2019},
  abstract = {As the evidence of predictive processes playing a role in a wide variety of cognitive domains increases, the brain as a predictive machine becomes a central idea in neuroscience. In auditory processing, a considerable amount of progress has been made using variations of the Oddball design, but most of the existing work seems restricted to predictions based on physical features or conditional rules linking successive stimuli. To characterize the predictive capacity of the brain to abstract rules, we present here two experiments that use speech-like stimuli to overcome limitations and avoid common confounds. Pseudowords were presented in isolation, intermixed with infrequent deviants that contained unexpected phoneme sequences. As hypothesized, the occurrence of unexpected sequences of phonemes reliably elicited an early prediction error signal. These prediction error signals do not seemed to be modulated by attentional manipulations due to different task instructions, suggesting that the predictions are deployed even when the task at hand does not volitionally involve error detection. In contrast, the amount of syllables congruent with a standard pseudoword presented before the point of deviance exerted a strong modulation. Prediction error's amplitude doubled when two congruent syllables were presented instead of one, despite keeping local transitional probabilities constant. This suggests that auditory predictions can be built integrating information beyond the immediate past. In sum, the results presented here further contribute to the understanding of the predictive capabilities of the human auditory system when facing complex stimuli and abstract rules.},
  chapter = {New Research},
  copyright = {Copyright \textcopyright{} 2019 Vidal et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
  langid = {english},
  pmid = {31551251},
  keywords = {auditory processing,EEG,predictive coding}
}

@article{vigneauMetaanalyzingLeftHemisphere2006,
  title = {Meta-Analyzing Left Hemisphere Language Areas: {{Phonology}}, Semantics, and Sentence Processing},
  shorttitle = {Meta-Analyzing Left Hemisphere Language Areas},
  author = {Vigneau, M. and Beaucousin, V. and Herv{\'e}, P. Y. and Duffau, H. and Crivello, F. and Houd{\'e}, O. and Mazoyer, B. and {Tzourio-Mazoyer}, N.},
  year = {2006},
  month = may,
  journal = {NeuroImage},
  volume = {30},
  number = {4},
  pages = {1414--1432},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2005.11.002},
  abstract = {The advent of functional neuroimaging has allowed tremendous advances in our understanding of brain\textendash language relationships, in addition to generating substantial empirical data on this subject in the form of thousands of activation peak coordinates reported in a decade of language studies. We performed a large-scale meta-analysis of this literature, aimed at defining the composition of the phonological, semantic, and sentence processing networks in the frontal, temporal, and inferior parietal regions of the left cerebral hemisphere. For each of these language components, activation peaks issued from relevant component-specific contrasts were submitted to a spatial clustering algorithm, which gathered activation peaks on the basis of their relative distance in the MNI space. From a sample of 730 activation peaks extracted from 129 scientific reports selected among 260, we isolated 30 activation clusters, defining the functional fields constituting three distributed networks of frontal and temporal areas and revealing the functional organization of the left hemisphere for language. The functional role of each activation cluster is discussed based on the nature of the tasks in which it was involved. This meta-analysis sheds light on several contemporary issues, notably on the fine-scale functional architecture of the inferior frontal gyrus for phonological and semantic processing, the evidence for an elementary audio\textendash motor loop involved in both comprehension and production of syllables including the primary auditory areas and the motor mouth area, evidence of areas of overlap between phonological and semantic processing, in particular at the location of the selective human voice area that was the seat of partial overlap of the three language components, the evidence of a cortical area in the pars opercularis of the inferior frontal gyrus dedicated to syntactic processing and in the posterior part of the superior temporal gyrus a region selectively activated by sentence and text processing, and the hypothesis that different working memory perception\textendash actions loops are identifiable for the different language components. These results argue for large-scale architecture networks rather than modular organization of language in the left hemisphere.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/T2S64HYE/Vigneau et al. - 2006 - Meta-analyzing left hemisphere language areas Pho.pdf;/Users/sarah/Zotero/storage/6FZFN9ZG/S1053811905024511.html}
}

@article{vitevitchBeginningSpanishLexicon2012,
  title = {The {{Beginning Spanish Lexicon}}: {{A Web-Based Interface}} to {{Calculate Phonological Similarity}} among {{Spanish Words}} in {{Adults Learning Spanish}} as a {{Foreign Language}}},
  shorttitle = {The {{Beginning Spanish Lexicon}}},
  author = {Vitevitch, Michael S. and Stamer, Melissa K. and Kieweg, Douglas},
  year = {2012},
  journal = {Second Language Research},
  volume = {28},
  number = {1},
  pages = {103--112},
  issn = {0267-6583},
  abstract = {A number of resources provide psycholinguistic researchers with information about the words that the typical child or adult knows in a variety of languages. What is currently not available is a resource that provides information about the words that a typical adult learning a foreign language knows. We created such a resource for Spanish: The Beginning Spanish Lexicon. The present report describes the words contained in this web-accessible resource, and the information about those words provided by the interface. This information is freely accessible at: http://www.people.ku. edu/\textbackslash textasciitilde mvitevit/BegSpanLex.html}
}

@article{vitevitchInfluenceOnsetDensity2002,
  title = {Influence of {{Onset Density}} on {{Spoken-Word Recognition}}},
  author = {Vitevitch, Michael S.},
  year = {2002},
  month = apr,
  journal = {J Exp Psychol Hum Percept Perform},
  volume = {28},
  number = {2},
  pages = {270--278},
  issn = {0096-1523},
  doi = {10.1037//0096-1523.28.2.270},
  abstract = {Previous research has suggested that the initial portion of a word activates similar sounding words that compete for recognition. Other research has shown that the number of similar sounding words that are activated influences the speed and accuracy of recognition. Words with few neighbors are processed more quickly and accurately than words with many neighbors. The influences of the number of lexical competitors in the initial part of the word were examined in a shadowing and a lexical-decision task. Target words with few neighbors that share the initial phoneme were responded to more quickly than target words with many neighbors that share the initial phoneme. The implications of onset-density effects for models of spoken-word recognition are discussed.},
  pmcid = {PMC2553695},
  pmid = {11999854}
}

@article{vitevitchmichaels.WhatCanGraph2008,
  title = {What {{Can Graph Theory Tell Us About Word Learning}} and {{Lexical Retrieval}}?},
  author = {{Vitevitch Michael S.}},
  year = {2008},
  month = apr,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {51},
  number = {2},
  pages = {408--422},
  doi = {10.1044/1092-4388(2008/030)},
  abstract = {Purpose Graph theory and the new science of networks provide a mathematically rigorous approach to examine the development and organization of complex systems. These tools were applied to the mental lexicon to examine the organization of words in the lexicon and to explore how that structure might influence the acquisition and retrieval of phonological word-forms. Method Pajek, a program for large network analysis and visualization (V. Batagelj \& A. Mvrar, 1998), was used to examine several characteristics of a network derived from a computerized database of the adult lexicon. Nodes in the network represented words, and a link connected two nodes if the words were phonological neighbors. Results The average path length and clustering coefficient suggest that the phonological network exhibits small-world characteristics. The degree distribution was fit better by an exponential rather than a power-law function. Finally, the network exhibited assortative mixing by degree. Some of these structural characteristics were also found in graphs that were formed by 2 simple stochastic processes suggesting that similar processes might influence the development of the lexicon. Conclusions The graph theoretic perspective may provide novel insights about the mental lexicon and lead to future studies that help us better understand language development and processing.}
}

@article{vitevitchNeighborhoodDensityEffects2005,
  title = {Neighborhood {{Density Effects}} in {{Spoken Word Recognition}} in {{Spanish}}},
  author = {Vitevitch, Michael S and Rodr{\'i}guez, Eva},
  year = {2005},
  month = mar,
  journal = {Journal of Multilingual Communication Disorders},
  volume = {3},
  number = {1},
  pages = {64--73},
  issn = {1476-9670, 1476-9689},
  doi = {10.1080/14769670400027332},
  abstract = {The present work examined the relationships among familiarity ratings, frequency of occurrence, neighborhood density, and word length in a corpus of Spanish words. The observed relationships were similar to the relationships found among the same variables in English. An auditory lexical decision task was then performed to examine the influence of word frequency, neighborhood density, and neighborhood frequency on spoken word recognition in Spanish. In contrast to the competitive effect of phonological neighborhoods typically observed in English, a facilitative effect of neighborhood density and neighborhood frequency was found in Spanish. Implications for models of spoken word recognition and language disorders are discussed.},
  langid = {english}
}

@article{vitevitchPhonologicalNeighborhoodEffects2016,
  title = {Phonological {{Neighborhood Effects}} in {{Spoken Word Perception}} and {{Production}}},
  author = {Vitevitch, Michael S. and Luce, Paul A.},
  year = {2016},
  month = jan,
  journal = {Annu. Rev. Linguist.},
  volume = {2},
  number = {1},
  pages = {75--94},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguistics-030514-124832},
  abstract = {Research on spoken word perception and production has identified two hallmarks of spoken word processing: multiple activation of representations of the sound patterns of words in memory and subsequent competition among these patterns. Evidence for this activation-competition process has come, in part, from experimental studies examining the effects of phonological neighborhoods, which are collections of similar-sounding words that are activated in memory during both perception and production. In this article, we review more than 20 years of research on phonological neighborhood effects in spoken word processing that has demonstrated that the speed and accuracy of spoken word perception and production are, in large part, a function of the density and frequency of neighborhoods of spoken words. We conclude our review with a discussion of new avenues of research\textemdash{} based on recent advances in network science\textemdash{} that hold the promise of deepening our understanding of the mental operations involved in our uniquely human capacity for communicating with the spoken word.},
  langid = {english}
}

@article{vitevitchWordLengthLexical2008,
  title = {Word {{Length}} and {{Lexical Competition}}: {{Longer Is}} the {{Same}} as {{Shorter}}},
  shorttitle = {Word {{Length}} and {{Lexical Competition}}},
  author = {Vitevitch, Michael S. and Stamer, Melissa K. and Sereno, Joan A.},
  year = {2008},
  month = dec,
  journal = {Lang Speech},
  volume = {51},
  number = {4},
  pages = {361--383},
  issn = {0023-8309},
  doi = {10.1177/0023830908099070},
  abstract = {Neighborhood density refers to the number of words that sound similar to a given word. Previous studies have found that neighborhood density influences the recognition of spoken words (Luce \& Pisoni, 1998); however, this work has focused almost exclusively on monosyllabic words in English. To investigate the effects of neighborhood density on longer words, bisyllabic words varying in neighborhood density were presented auditorily to participants in a perceptual identification task and a lexical decision task. In the perceptual identification task, words with sparse neighborhoods were more accurately identified than words with dense neighborhoods. In the lexical decision task, words with sparse neighborhoods were responded to more quickly and more accurately than words with dense neighborhoods. These results are similar to those found in studies examining the influence of neighborhood density on the recognition of monosyllabic words in English. In order to better understand lexical processing, models of spoken word recognition must account for the processing of words of all types.},
  langid = {english}
}

@incollection{vorwergExperimentalMethodsPsycholinguistics2012,
  title = {Experimental {{Methods}} in {{Psycholinguistics}}},
  booktitle = {Methods in {{Contemporary Linguistics}}},
  author = {Vorwerg, Constanze},
  editor = {Ender, Andrea and Leemann, Adrian and W{\"a}lchli, Bernhard},
  year = {2012},
  edition = {First},
  pages = {363--386},
  publisher = {{De Gruyter}},
  abstract = {To study language production, language comprehension, language representation and language acquisition means largely to ask what processes are involved, what mechanisms underlie and what factors contribute to the phenomena explored. Therefore the experiment is one of the most important methodological approaches within psycholinguistics. Its basic idea is to systematically manipulate certain variables while controlling for the effects of others \textendash{} as a way of dealing with the problem of scientific \textbackslash emphexplanation , as opposed to the problem of \textbackslash emphdescription (which is tackled by other methods). If we are to find out \textbackslash emphhow and \textbackslash emphwhy something occurs, we need to compare different}
}

@article{wagnerPoeticRhymeReflects2010,
  title = {Poetic Rhyme Reflects Cross-Linguistic Differences in Information Structure},
  author = {Wagner, Michael and McCurdy, Katherine},
  year = {2010},
  month = nov,
  journal = {Cognition},
  volume = {117},
  number = {2},
  pages = {166--175},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2010.08.007},
  abstract = {Identical rhymes (right/write, attire/retire) are considered satisfactory and even artistic in French poetry but are considered unsatisfactory in English. This has been a consistent generalization over the course of centuries, a surprising fact given that other aspects of poetic form in French were happily applied in English. This paper puts forward the hypothesis that this difference is not merely one of poetic tradition, but is grounded in the distinct ways in which information-structure affects prosody in the two languages. A study of rhyme usage in poetry and a perception experiment confirm that native speakers' intuitions about rhyming in the two languages indeed differ, and a further perception experiment supports the hypothesis that this fact is due to a constraint on prosody that is active in English but not in French. The findings suggest that certain forms of artistic expression in poetry are influenced, and even constrained, by more general properties of a language.},
  langid = {english},
  keywords = {Focus,Givenness,Information structure,Poetry,Prosody,Rhyme},
  file = {/Users/sarah/Zotero/storage/BA2S9UA8/S0010027710001769.html}
}

@article{wallaceRecognitionMemoryErrors1995,
  title = {Recognition {{Memory Errors Produced}} by {{Implicit Activation}} of {{Word Candidates}} during the {{Processing}} of {{Spoken Words}}},
  author = {Wallace, William P. and Stewart, Mark T. and Malone, Christine P.},
  year = {1995},
  month = aug,
  journal = {Journal of Memory and Language; New York},
  volume = {34},
  number = {4},
  pages = {417--439},
  issn = {0749-596X},
  langid = {english},
  keywords = {Education,Linguistics}
}

@article{warrenContinuousUptakeAcoustic1987,
  title = {Continuous {{Uptake}} of {{Acoustic Cues}} in {{Spoken Word Recognition}}},
  author = {Warren, Paul and {Marslen-Wilson}, William},
  year = {1987},
  month = may,
  journal = {Perception \& Psychophysics},
  volume = {41},
  number = {3},
  pages = {262--275},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03208224},
  langid = {english}
}

@article{warrenContinuousUptakeAcoustic1987a,
  title = {Continuous {{Uptake}} of {{Acoustic Cues}} in {{Spoken Word Recognition}}},
  author = {Warren, Paul and {Marslen-Wilson}, William},
  year = {1987},
  month = may,
  journal = {Perception \& Psychophysics},
  volume = {41},
  number = {3},
  pages = {262--275},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03208224},
  langid = {english}
}

@misc{weeninkSSP2018,
  title = {{{SSP}}},
  author = {Weenink, David},
  year = {2018},
  file = {/Users/sarah/Zotero/storage/4KPS98JE/sspbook.pdf}
}

@article{wescottTypesVowelAlternation1970,
  title = {Types of {{Vowel Alternation}} in {{English}}},
  author = {Wescott, Roger W.},
  year = {1970},
  month = dec,
  journal = {\textbackslash emphWORD},
  volume = {26},
  number = {3},
  pages = {309--343},
  issn = {0043-7956, 2373-5112},
  doi = {10.1080/00437956.1970.11435602},
  langid = {english}
}

@article{westburySoundsNeighborhoodFalse2002,
  title = {Sounds of the {{Neighborhood}}: {{False Memories}} and the {{Structure}} of the {{Phonological Lexicon}}},
  shorttitle = {Sounds of the {{Neighborhood}}},
  author = {Westbury, Chris and Buchanan, Lori and Brown, Norman R.},
  year = {2002},
  month = apr,
  journal = {Journal of Memory and Language},
  volume = {46},
  number = {3},
  pages = {622--651},
  issn = {0749596X},
  doi = {10.1006/jmla.2001.2821},
  langid = {english}
}

@article{whangEffectsPhonotacticPredictability2019,
  title = {Effects of {{Phonotactic Predictability}} on {{Sensitivity}} to {{Phonetic Detail}}},
  author = {Whang, James},
  year = {2019},
  month = apr,
  journal = {Laboratory Phonology: Journal of the Association for Laboratory Phonology},
  volume = {10},
  number = {1},
  pages = {8},
  issn = {1868-6354},
  doi = {10.5334/labphon.125},
  langid = {english}
}

@article{wilkersonChildrenNeglectAttachment2008,
  title = {Children of {{Neglect}} with {{Attachment}} and {{Time Perception Deficits}}: {{Strategies}} and {{Interventions}}},
  shorttitle = {Children of {{Neglect}} with {{Attachment}} and {{Time Perception Deficits}}},
  author = {Wilkerson, Dennis and Johnson, Gail and Johnson, Richard},
  year = 2008,
  journal = {Education},
  volume = {129},
  number = {2},
  pages = {343--352},
  publisher = {{Project Innovation, Inc.}},
  issn = {00131172},
  abstract = {Early childhood neglect can limit a child's normal cognitive development and result in behavior problems in the classroom. When normal attachment is disrupted, learning difficulties can result in problems with time awareness. It has also been shown that an awareness of time is a key concept for the formation of organizational and math skills. This article reports practical suggestions and activities for teachers and clinicians to help the child with attachment and time perception issues.},
  keywords = {ATTACHMENT behavior in children,CHILD abuse,CHILD psychology,COGNITIVE development,MATHEMATICAL ability testing,TIME perception in children},
  file = {/Users/sarah/Zotero/storage/V945ZHLY/Wilkerson et al. - 2008 - Children of Neglect with Attachment and Time Perce.pdf}
}

@article{williamsModalityIndependentEffectsPhonological2015,
  title = {Modality-{{Independent Effects}} of {{Phonological Neighborhood Structure}} on {{Initial L2 Sign Language Learning}}},
  author = {Williams, Joshua and Newman, Sharlene D.},
  year = {2015},
  month = jun,
  journal = {Research in Language},
  volume = {13},
  number = {2},
  pages = {199--213},
  issn = {2083-4616},
  doi = {10.1515/rela-2015-0022},
  abstract = {The goal of the present study was to characterize how neighborhood structure in sign language influences lexical sign acquisition in order to extend our understanding of how the lexicon influences lexical acquisition in both sign and spoken languages. A referentmatching lexical sign learning paradigm was administered to a group of 29 hearing sign language learners in order to create a sign lexicon. The lexicon was constructed based on exposures to signs that resided in either sparse or dense handshape and location neighborhoods. The results of the current study indicated that during the creation of the lexicon signs that resided in sparse neighborhoods were learned better than signs that resided in dense neighborhoods. This pattern of results is similar to what is seen in child first language acquisition of spoken language. Therefore, despite differences in child first language and adult second language acquisition, these results contribute to a growing body of literature that implicates the phonological features that structure of the lexicon is influential in initial stages of lexical acquisition for both spoken and sign languages. This is the first study that uses an innovated lexicon-construction methodology to explore interactions between phonology and the lexicon in L2 acquisition of sign language.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/8EYVZBNA/Williams and Newman - 2015 - Modality-Independent Effects of Phonological Neigh.pdf}
}

@article{winnSlowerSpeakingRate2020,
  title = {Slower {{Speaking Rate Reduces Listening Effort Among Listeners With Cochlear Implants}}},
  author = {Winn, Matthew B. and Teece, Katherine H.},
  year = {2020},
  month = sep,
  journal = {Ear and Hearing},
  volume = {Publish Ahead of Print},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000958},
  abstract = {Objectives: Slowed speaking rate was examined for its effects on speech intelligibility, its interaction with the benefit of contextual cues, and the impact of these factors on listening effort in adults with cochlear implants. Design: Participants (n = 21 cochlear implant users) heard high- and low-context sentences that were played at the original speaking rate, as well as a slowed (1.4\texttimes{} duration) speaking rate, using uniform pitch-synchronous time warping. In addition to intelligibility measures, changes in pupil dilation were measured as a time-varying index of processing load or listening effort. Slope of pupil size recovery to baseline after the sentence was used as an index of resolution of perceptual ambiguity. Results: Speech intelligibility was better for high-context compared to low-context sentences and slightly better for slower compared to original-rate speech. Speech rate did not affect magnitude and latency of peak pupil dilation relative to sentence offset. However, baseline pupil size recovered more substantially for slower-rate sentences, suggesting easier processing in the moment after the sentence was over. The effect of slowing speech rate was comparable to changing a sentence from low context to high context. The effect of context on pupil dilation was not observed until after the sentence was over, and one of two analyses suggested that context had greater beneficial effects on listening effort when the speaking rate was slower. These patterns maintained even at perfect sentence intelligibility, suggesting that correct speech repetition does not guarantee efficient or effortless processing. With slower speaking rates, there was less variability in pupil dilation slopes following the sentence, implying mitigation of some of the difficulties shown by individual listeners who would otherwise demonstrate prolonged effort after a sentence is heard. Conclusions: Slowed speaking rate provides release from listening effort when hearing an utterance, particularly relieving effort that would have lingered after a sentence is over. Context arguably provides even more release from listening effort when speaking rate is slower. The pattern of prolonged pupil dilation for faster speech is consistent with increased need to mentally correct errors, although that exact interpretation cannot be verified with intelligibility data alone or with pupil data alone. A pattern of needing to dwell on a sentence to disambiguate misperceptions likely contributes to difficulty in running conversation where there are few opportunities to pause and resolve recently heard utterances.},
  langid = {american}
}

@book{WiringEconomyPrinciple,
  title = {The {{Wiring Economy Principle}}: {{Connectivity Determines Anatomy}} in the {{Human Brain}}}
}

@article{wongHowCanLyrics2002,
  title = {How {{Can}} the {{Lyrics}} of a {{Song}} in a {{Tone Language Be Understood}}?},
  author = {Wong, Patrick C. M. and Diehl, Randy L.},
  year = {2002},
  month = oct,
  journal = {Psychology of Music},
  volume = {30},
  number = {2},
  pages = {202--209},
  publisher = {{SAGE Publications Ltd}},
  issn = {0305-7356},
  doi = {10.1177/0305735602302006},
  abstract = {In a tone language, pitch variations are used to contrast word meaning. For example, the Cantonese syllable /si/ means "teacher" when spoken in a high pitch and "yes" when spoken in a low pitch. How is fundamental frequency (Fo) used to signal lexical tones that occur in songs? In an examination of Cantonese songs, it was found that songwriters abandon the ratio scale of Fo differences that is applied to lexical tones in carefully read speech and instead use an ordinal scale. For example, a high tone that is normally 12\% higher than a mid-tone in speech can be realised as any higher Fo (but never a lower Fo) in songs. A perceptual experiment showed that native Cantonese-speaking listeners similarly apply an ordinal Fo scale to arrive at the lexical meaning of the lyric. This ratio-to-ordinal mapping in Cantonese songs ensures the musicality of the melody while preserving adequate identifiability of lexical tones in the lyric.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/RBULSQW6/Wong and Diehl - 2002 - How Can the Lyrics of a Song in a Tone Language Be.pdf}
}

@article{wongHowCanLyrics2002a,
  title = {How {{Can}} the {{Lyrics}} of a {{Song}} in a {{Tone Language Be Understood}}?},
  author = {Wong, Patrick C. M. and Diehl, Randy L.},
  year = {2002},
  month = oct,
  journal = {Psychology of Music},
  volume = {30},
  number = {2},
  pages = {202--209},
  issn = {0305-7356, 1741-3087},
  doi = {10.1177/0305735602302006},
  abstract = {In a tone language, pitch variations are used to contrast word meaning. For example, the Cantonese syllable /si/ means "teacher" when spoken in a high pitch and "yes" when spoken in a low pitch. How is fundamental frequency (Fo) used to signal lexical tones that occur in songs? In an examination of Cantonese songs, it was found that songwriters abandon the ratio scale of Fo differences that is applied to lexical tones in carefully read speech and instead use an ordinal scale. For example, a high tone that is normally 12\% higher than a mid-tone in speech can be realised as any higher Fo (but never a lower Fo) in songs. A perceptual experiment showed that native Cantonese-speaking listeners similarly apply an ordinal Fo scale to arrive at the lexical meaning of the lyric. This ratio-to-ordinal mapping in Cantonese songs ensures the musicality of the melody while preserving adequate identifiability of lexical tones in the lyric.},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/XWZNHKJH/Wong and Diehl - 2002 - How Can the Lyrics of a Song in a Tone Language Be.pdf}
}

@article{wongMelodyToneRelation1999,
  title = {Melody-tone Relation in {{Cantonese}} Songs},
  author = {Wong, Patrick C. M. and Diehl, Randy L.},
  year = {1999},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {106},
  number = {4},
  pages = {2286--2286},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.427815}
}

@article{woodsConductingPerceptionResearch2015,
  title = {Conducting {{Perception Research}} over the {{Internet}}: {{A Tutorial Review}}},
  shorttitle = {Conducting {{Perception Research}} over the {{Internet}}},
  author = {Woods, Andy T. and Velasco, Carlos and Levitan, Carmel A. and Wan, Xiaoang and Spence, Charles},
  year = {2015},
  month = jul,
  journal = {PeerJ},
  volume = {3},
  pages = {e1058},
  publisher = {{PeerJ Inc.}},
  issn = {2167-8359},
  doi = {10.7717/peerj.1058},
  abstract = {This article provides an overview of the recent literature on the use of internet-based testing to address important questions in perception research. Our goal is to provide a starting point for the perception researcher who is keen on assessing this tool for their own research goals. Internet-based testing has several advantages over in-lab research, including the ability to reach a relatively broad set of participants and to quickly and inexpensively collect large amounts of empirical data, via services such as Amazon's Mechanical Turk or Prolific Academic. In many cases, the quality of online data appears to match that collected in lab research. Generally-speaking, online participants tend to be more representative of the population at large than those recruited for lab based research. There are, though, some important caveats, when it comes to collecting data online. It is obviously much more difficult to control the exact parameters of stimulus presentation (such as display characteristics) with online research. There are also some thorny ethical elements that need to be considered by experimenters. Strengths and weaknesses of the online approach, relative to others, are highlighted, and recommendations made for those researchers who might be thinking about conducting their own studies using this increasingly-popular approach to research in the psychological sciences.},
  langid = {english}
}

@article{wurmDynamicsAuditoryComprehension2006,
  title = {Dynamics of the {{Auditory Comprehension}} of {{Prefixed Words}}: {{Cohort Entropies}} and {{Conditional Root Uniqueness Points}}},
  shorttitle = {Dynamics of the {{Auditory Comprehension}} of {{Prefixed Words}}},
  author = {Wurm, Lee H. and Ernestus, Mirjam and Schreuder, Robert and Baayen, R. H.},
  year = {2006},
  month = may,
  journal = {ML},
  volume = {1},
  number = {1},
  pages = {125--146},
  issn = {1871-1340, 1871-1375},
  doi = {10.1075/ml.1.1.08wur},
  abstract = {This auditory lexical decision study shows that cohort entropies, conditional root uniqueness points, and morphological family size all contribute to the dynamics of the auditory comprehension of prefixed words. Three entropy measures calculated for different positions in the stem of Dutch prefixed words revealed facilitation for higher entropies, except at the point of disambiguation, where we observed inhibition. Morphological family size was also facilitatory, but only for prefixed words in which the conditional root uniqueness point coincided with the conventional uniqueness point. For words with early conditional disambiguation, in contrast, only the morphologically related words that were onset-aligned with the target word facilitated lexical decision.},
  langid = {english}
}

@book{Xhosa,
  title = {Xhosa}
}

@article{xuTonalAlignmentSyllable2006,
  title = {Tonal {{Alignment}}, {{Syllable Structure}} and {{Coarticulation}}: {{Toward}} an {{Integrated Model}}},
  shorttitle = {Tonal {{Alignment}}, {{Syllable Structure}} and {{Coarticulation}}},
  author = {Xu, Yi and Liu, Fang},
  year = {2006},
  journal = {Italian Journal of Linguistics},
  pages = {18--125},
  abstract = {Abstract. The finding of consistent tone-segment alignment in many languages in recent research raises questions about the temporal organization of speech sounds in general. In this paper we explore the possibility that tonal alignment patterns can lead to the discovery of basic principles of temporal organization in speech. Based on a recent finding about the segmentability of approximants in English and Mandarin, we propose a general model of temporal organization, in which the syllable is the basic time structure that specifies the alignment of consonants, vowels, tones and phonation registers. All these sounds are unified under the term phone defined as a collection of unidirectional articulatory movements toward a simple or composite target. The phones are temporally organized by the syllable under three principles: co-onset of initial C and V, sequential offset of coda C, and full synchronization of tone and phonation register with the syllable. Under the time structure model, true coarticulation, in the strict sense of co-occurrence of separate phones, occurs only between initial C and V; and there is no anticipatory C to V coarticulation, no cross-consonantal V-to-V coarticulation, and no carryover coarticulation of any kind. 1.}
}

@article{yanivVowelSimilarityConnectionist1990,
  title = {Vowel {{Similarity}}, {{Connectionist Models}}, and {{Syllable Structure}} in {{Motor Programming}} of {{Speech}}},
  author = {Yaniv, Ilan and Meyer, David E. and Gordon, Peter C. and Huff, Carol A. and Sevald, Christine A.},
  year = {1990},
  month = feb,
  journal = {Journal of Memory and Language},
  volume = {29},
  number = {1},
  pages = {1--26},
  issn = {0749-596X},
  doi = {10.1016/0749-596X(90)90007-M},
  abstract = {Using a response-priming procedure, five experiments examined the effects of vowel similarity on the motor programming of spoken syllables. In this procedure, subjects prepared to produce a pair of spoken syllables as rapidly as possible, but sometimes had to produce the syllables in reverse order instead. The spoken responses consisted of consonant-vowel-consonant (CVC) syllables whose medial vowels were /i/, /I/, /{$\lambda$}/, and /{$\alpha$}/. Performance was measured as a function of the phonetic relationship between the vowels in a syllable pair. Longer response latencies occurred for syllable pairs that contained similar vowels (e.g., /i/ and /I/) than for syllable pairs that contained dissimilar vowels (e.g., /i/ and /{$\lambda$}/). This inhibitory vowel-similarity effect occurred regardless of whether the initial consonants of the syllables in a pair were the same or different. However, it decreased substantially when the final consonants of the paired syllables were different. These results suggest that a lateral-inhibition mechanism may modulate the motor programming of vowels during speech production. They also provide evidence for the integrity of vowel-consonant (VC) subunits in syllables.}
}

@article{yihoyoungEffectTalkerListener,
  title = {The {{Effect}} of {{Talker}} and {{Listener Depressive Symptoms}} on {{Speech Intelligibility}}},
  author = {{Yi Hoyoung} and {Smiljanic Rajka} and {Chandrasekaran Bharath}},
  journal = {Journal of Speech, Language, and Hearing Research},
  doi = {10.1044/2019_JSLHR-S-19-0112},
  abstract = {Purpose This study examined the effect of depressive symptoms on production and perception of conversational and clear speech (CS) sentences. Method Five talkers each with high-depressive (HD) and low-depressive (LD) symptoms read sentences in conversational and clear speaking style. Acoustic measures of speaking rate, mean fundamental frequency (F0; Hz), F0 range (Hz), and energy in the 1\textendash{} 3 kHz range (dB) were obtained. Thirty-two young adult participants (15 HD, 16 LD) heard these conversational and clear sentences mixed with energetic masking (speech-shaped noise) at -5 dB SPL signal-to-noise ratio. Another group of 39 young adult participants (18 HD, 19 LD) heard the same sentences mixed with informational masking (one-talker competing speech) at -12 dB SPL signal-to-noise ratio. The key word correct score was obtained. Results CS was characterized by a decreased speaking rate, increased F0 mean and range, and increased energy in the 1\textendash{} 3 kHz range. Talkers with HD symptoms produced these modifications significantly less compared to talkers with LD symptoms. When listening to speech in energetic masking (speech-shaped noise), listeners with both HD and LD symptoms benefited less from the CS produced by HD talkers. Listeners with HD symptoms performed significantly worse than listeners with LD symptoms when listening to speech in informational masking (one-talker competing speech). Conclusions Results provide evidence that depressive symptoms impact intelligibility and have the potential to aid in clinical decision making for individuals with depression.}
}

@article{yipCastingDoubtOnset2003,
  title = {Casting {{Doubt}} on the {{Onset}}\textendash{{Rime Distinction}}},
  author = {Yip, Moira},
  year = {2003},
  month = aug,
  journal = {Lingua},
  volume = {113},
  number = {8},
  pages = {779--816},
  issn = {0024-3841},
  doi = {10.1016/S0024-3841(02)00130-4},
  abstract = {If the syllable is composed of Onset and Rime constituents, and if this constituency is taken seriously, then each segment must uniquely belong to either Onset or Rime, and the boundary between the constituents should be clear and consistent in any given language. Pre-nuclear glides provide a test-case for this prediction. It turns out that in a single language these glides may behave in some ways as part of the Onset, and in other ways as part of the Rime, casting doubt on the reality of these constituents. We find not only inter-speaker variation, but also intra-speaker variation. The facts succumb to explanations based on simple linear phonotactics, with no appeal to sub-syllabic constituency, reinforcing the findings of Pierrehumbert and Nair [Language and Speech 38.1 (1995) 77]. The data are drawn primarily from English and from Mandarin Chinese, and the analysis is worked out in Optimality Theory.},
  keywords = {Glides,Syllable structure,Variation}
}

@article{youngShouldWritersUse2010,
  title = {Should {{Writers Use They Own English}}?},
  author = {Young, Vershawn Ashanti},
  year = {2010},
  journal = {Iowa Journal of Cultural Studies},
  pages = {10},
  langid = {english},
  file = {/Users/sarah/Zotero/storage/P4U7X6ZT/Young - Should Writers Use They Own English.pdf}
}

@article{zhangMechanicsHumanVoice2016,
  title = {Mechanics of {{Human Voice Production}} and {{Control}}},
  author = {Zhang, Zhaoyan},
  year = {2016},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {140},
  number = {4},
  pages = {2614--2635},
  issn = {0001-4966},
  doi = {10.1121/1.4964509},
  abstract = {As the primary means of communication, voice plays an important role in daily life. Voice also conveys personal information such as social status, personal traits, and the emotional state of the speaker. Mechanically, voice production involves complex fluid-structure interaction within the glottis and its control by laryngeal muscle activation. An important goal of voice research is to establish a causal theory linking voice physiology and biomechanics to how speakers use and control voice to communicate meaning and personal information. Establishing such a causal theory has important implications for clinical voice management, voice training, and many speech technology applications. This paper provides a review of voice physiology and biomechanics, the physics of vocal fold vibration and sound production, and laryngeal muscular control of the fundamental frequency of voice, vocal intensity, and voice quality. Current efforts to develop mechanical and computational models of voice production are also critically reviewed. Finally, issues and future challenges in developing a causal theory of voice production and perception are discussed.}
}

@article{zotero-236,
  type = {Article}
}

@article{zotero-237,
  type = {Article}
}

@article{zotero-238,
  type = {Article}
}

@article{zotero-239,
  type = {Article}
}

@book{zotero-240,
  type = {Misc}
}

@book{zotero-241,
  type = {Book}
}

@misc{zotero-484,
  howpublished = {https://www.google.com/url?sa=t\&rct=j\&q=\&esrc=s\&source=web\&cd=\&ved=2ahUKEwiezIr2wof2AhXsk2oFHUVtD-AQFnoECAIQAQ\&url=http\%3A\%2F\%2Froa.rutgers.edu\%2Ffiles\%2F310-0399\%2Froa-310-alber-2.ps\&usg=AOvVaw3RJwt8JlUQ3DuTAE5NUMSh},
  file = {/Users/sarah/Zotero/storage/IDK8CTP3/url.html}
}

@book{ZoteroDownloads,
  title = {Zotero | {{Downloads}}}
}


