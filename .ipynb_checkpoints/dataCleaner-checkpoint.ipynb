{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from estnltk.vabamorf.morf import syllabify_word\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_dir = \"/Users/sarah/qp_final/55.txt\"\n",
    "\n",
    "    \n",
    "\n",
    "def phrase_to_syll(file_dur):\n",
    "    song = open(file_dir).read()\n",
    "    phrase_array = song\n",
    "    word_array = []\n",
    "    words = []\n",
    "    frame = pd.DataFrame()\n",
    "    for item in phrase_array:\n",
    "        tmp = item.split(' ')\n",
    "        print(tmp)\n",
    "        for word in tmp: \n",
    "            tmpy = word.strip(string.punctuation)\n",
    "            tmpz = tmpy.strip('\\n')\n",
    "            mine = syllabify_word(tmpz,as_dict = True)\n",
    "            words.append(mine)\n",
    "            syll_col = []\n",
    "            q_col = []\n",
    "            s_col = []   \n",
    "            sec_syll = []\n",
    "            sec_q = []\n",
    "            sec_s = [] \n",
    "            if len(mine) < 1: \n",
    "                word_array.append(word)\n",
    "                syll_col.append('NaN')\n",
    "                q_col.append('NaN')\n",
    "                s_col.append('NaN')\n",
    "            elif len(mine) == 1:\n",
    "                word_array.append(word)\n",
    "                first = mine[0]\n",
    "                syll_col.append(first.get('syllable'))\n",
    "                q_col.append(first.get('quantity'))\n",
    "            elif len(mine) > 1:\n",
    "                word_array.append(word)\n",
    "                first, second, *third  = mine[0:]\n",
    "                # print(first, second, third)\n",
    "                syll_col.append(first.get('syllable'))\n",
    "                q_col.append(first.get('quantity'))\n",
    "                s_col.append(first.get('accent'))\n",
    "                if len(second) > 0: \n",
    "                    sec_syll.append(second.get('syllable'))\n",
    "                    sec_q.append(second.get('quantity'))\n",
    "                    sec_s.append(second.get('accent'))\n",
    "                else: \n",
    "                    sec_syll.append('NaN')\n",
    "                    sec_q.append('NaN')\n",
    "                    sec_s.append('NaN')\n",
    "\n",
    "    frame['first_syll'] = syll_col\n",
    "    frame['first_q']    = q_col\n",
    "    frame['first_stress'] = s_col\n",
    "    frame['second_syll'] = sec_syll\n",
    "    frame['second_quantity'] = sec_q\n",
    "    frame['second_stress'] = sec_s\n",
    "    return frame\n",
    "\n",
    "\n",
    "        \n",
    "# newer_df\n",
    "sunday_df = pd.DataFrame(phrase_to_syll(file_dir))\n",
    "sunday_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tgt\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "gridDir = \"/Users/sarah/qp_final/txtgridtest/018.TextGrid\"\n",
    "\n",
    "# for fn in os.listdir(gridDir):\n",
    "# tmp = tgt.read_textgrid(gridDir)\n",
    "# test = tgt.TextGrid(tmp)\n",
    "tg_df = pd.DataFrame()\n",
    "# tiers = tmp.get_tier_names()\n",
    "\n",
    "def get_duration_label(textgrid, tiername):\n",
    "    tmp = tgt.read_textgrid(textgrid)\n",
    "    tg_df = pd.DataFrame()\n",
    "    mytier = tmp.get_tier_by_name(tiername)\n",
    "    phrase_dur = mytier.intervals\n",
    "    dur = []\n",
    "    label = []\n",
    "    for interval in phrase_dur:\n",
    "        dur.append(interval.end_time-interval.start_time)\n",
    "        label.append(interval.text)\n",
    "    tg_df[\"label\"] = label \n",
    "    tg_df[\"duration\"] = dur\n",
    "    \n",
    "\n",
    "    return tg_df\n",
    "#get tier labels and durations!\n",
    "\n",
    "# tg_df[\"phrase\"] = (phrase_dur[1]-phrase_dur[0])\n",
    "# \n",
    "\n",
    "    \n",
    "\n",
    "word_df = get_duration_label(gridDir,\"word\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration_label_interval(textgrid, tiername):\n",
    "    tmp = tgt.read_textgrid(textgrid)\n",
    "    tg_df = pd.DataFrame()\n",
    "    mytier = tmp.get_tier_by_name(tiername)\n",
    "    phrase_dur = mytier.intervals\n",
    "    dur = []\n",
    "    label = []\n",
    "    for interval in phrase_dur:\n",
    "        \n",
    "        dur.append(interval.end_time-interval.start_time)\n",
    "        label.append(interval.text)\n",
    "    tg_df[\"label\"] = label \n",
    "    tg_df[\"duration\"] = dur\n",
    "    \n",
    "\n",
    "    return tg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "from estnltk.vabamorf.morf import syllabify_word\n",
    "import tgt\n",
    "import string\n",
    "\n",
    "gridDir2 = \"/Users/sarah/qp_final/txtgridtest/69.TextGrid\"\n",
    "def get_duration_labels(textgrid, tiername1,tiername2,tiername3):\n",
    "    tmp = tgt.read_textgrid(textgrid)\n",
    "    mytier = tmp.get_tier_by_name(tiername1)\n",
    "    other = tmp.get_tier_by_name(tiername2)\n",
    "    ictus = tmp.get_tier_by_name(tiername3)\n",
    "    \n",
    "\n",
    "    segments = []\n",
    "\n",
    "   \n",
    "    word_dur = mytier.intervals\n",
    "    \n",
    "    for interval in word_dur:\n",
    "        h = interval.start_time\n",
    "        t = interval.end_time\n",
    "        b = t-h \n",
    "        l = interval.text\n",
    "        tmpseg = [other.get_annotations_between_timepoints(h,t)]\n",
    "        s = syllabify_word(l,as_dict=True)\n",
    "        i = 0 \n",
    "        for list in tmpseg:\n",
    "            n = 0 \n",
    "            while i < len(s):\n",
    "                item = s[i]\n",
    "                shape = item.get('syllable')\n",
    "                q = item.get('quantity')\n",
    "                a = item.get('accent')\n",
    "                geminate = False\n",
    "                for char in shape.strip(string.punctuation):\n",
    "                    if geminate: continue\n",
    "                    if n < len(list): \n",
    "                        myinterval = list[n]\n",
    "                        c = myinterval.text\n",
    "                        d = myinterval.start_time\n",
    "                        g = myinterval.end_time\n",
    "                        tmpick = ictus.get_annotations_between_timepoints(d,g,left_overlap=True,right_overlap=True)\n",
    "                        if len(tmpick) == 0: ick = \"off\"\n",
    "                        else: ick = \"ictus\"\n",
    "                        j = g-d  \n",
    "                        mid = g - (j/2)\n",
    "                        if \"Ë\" in c: \n",
    "                            row = [l,b,shape,q,a,c,j,mid,ick]\n",
    "                            segments.append(row)\n",
    "                            geminate = True\n",
    "                            \n",
    "                        elif char == c: \n",
    "                        \n",
    "                            row = [l,b,shape,q,a,c,j,mid,ick]\n",
    "                            segments.append(row)\n",
    "                        else :\n",
    "                            can = \"(\" + char + \") \" + c\n",
    "                            row = [l,b,shape,q,a,can,j,mid,ick]\n",
    "                            segments.append(row)\n",
    "                        n+=1               \n",
    "                i+= 1 \n",
    "\n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "    nu_df = pd.DataFrame(segments,columns=[\"word\",\"word_dur\",\"syll\",\"quantity\",\"stress\",\"segment\",\"seg_duration\",\"seg_midpoint\",\"ictus\"])\n",
    "    return nu_df\n",
    "\n",
    "syl_dur_df = get_duration_labels(gridDir2,\"word\",\"word/phon\",\"ictus\")\n",
    "syl_dur_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get formants\n",
    "import parselmouth\n",
    "#make a function! \n",
    "test = \"/Users/sarah/qp_final/wavs/069.wav\"\n",
    "song = parselmouth.Sound(test)\n",
    "def get_formants(df, wave):\n",
    "    formant = wave.to_formant_burg()\n",
    "    f1 = []\n",
    "    f2 = []\n",
    "    f3 = []\n",
    "    for float in df.seg_midpoint:\n",
    "        time = float\n",
    "        f1.append(formant.get_value_at_time(1,time))\n",
    "        f2.append(formant.get_value_at_time(2, time))\n",
    "        f3.append(formant.get_value_at_time(3,time))\n",
    "    df[\"f1\"] = f1\n",
    "    df[\"f2\"] = f2\n",
    "    df[\"f3\"] = f3\n",
    "    df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "outpath = \"/Users/sarah/qp_final/txtgridtest/out\"\n",
    "\n",
    "\n",
    "test = \"/Users/sarah/qp_final/txtgridtest/\"\n",
    "\n",
    "songs = \" song directory \"\n",
    "\n",
    "for fn in os.listdir(test):\n",
    "    if '.TextGrid' not in fn: \n",
    "        continue \n",
    "    n = fn.strip('.TextGrid') \n",
    "    data_file = open(\"withick_\" + n +\".csv\",'w')\n",
    "    tmp = pd.DataFrame(get_duration_labels(join(test,fn), \"word\",\"word/phon\",\"ictus\"))\n",
    "    \n",
    "    print(tmp)\n",
    "    tmp.to_csv(data_file)\n",
    "    data_file.close()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ebbf1b151a131b3a0a32805ceb104e187635a7a85732bf0d9da09c55a49fa14"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
