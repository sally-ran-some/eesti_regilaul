\chapter{Methods}
\index{Methods@\emph{Methods}}%

\section{Design}
To test these hypotheses, vowel duration and location on the F1,F2 plane are taken from the nuclei of first (primary stressed) and unstressed syllables of disyllabic feet. \footnote{The exclusion of secondary stress is due to recent findings that secondary stress in spoken Estonian does not exhibit significant differences compared to unstressed syllables of polysyllabic words besides the pen-initial \cite{asuLippus2018}. }

Within each song, samples of syllable-notes consisted only of those matching the nominal isochrony. For example, in verse lines mostly comprised of syllable-notes divided evenly into eighths, neither quarter notes nor sixteenth notes were taken. Syllables in phrase-final position were generally excluded under this criteria. 



\section{Constructing the Corpus}

I first describe the source materials and the selection criteria for the sample corpus of {\it regilaul} folksongs. Following this, the annotation and measurement procedure is detailed. Then the procedure for assembling the corpus of songs and their text annotations is covered before proceeding to the inclusion criteria for vowel duration and dispersion measurements.

\subsection{Materials}



%Until 1948, songs were collected on wax cylinders, then played on a phonograph and transcribed. shellac discs 1936-38, 746 recordings, 
%analogue is the biggest collection in the archive, with over 80,000 individual recordings. Open-reel tape, cassette recordings since the 1970s. 
%both wax and disc were re-recorded onto open-reel tape in 78-79.
%Presently, the sound engineer Jaan Tamm has been working on preserving the earlier tape recordings in digital form for the EFA. WAV files are stored on CD-Rom at the EFA in Tartu, Estonia, while .mp3 and .ogg lossy formats are uploaded to the internet database. 
% collected by Herbert Tampere, Erna Tampere, and Ottilie Kõiva between 1912 and 1966 for the Estonian Folklore Archives in Tartu, Estonia. \\
%
% and   tunes
%the total number of song recordings is over 26,000. Of these, over 11,000 are from the beginning of the 20th century. Tampere did like 2,000 of them..
%
%%
%The need for writing the tunes live during fieldwork has reduced with the availability of analog and now digital audio recording equipment.




Songs for this paper were accessed via The Anthology of Estonian Traditional Music \citep{tampere2016}. Originally published on four vinyl discs in 1970, the digital version showcases a robust sample of the massive collection of {\it regilaul} in Estonian Folklore Archives. In addition to audio, the  compilation includes  photographs, sheet music, and performer demographics of 98 {\it regilaul} songs and 17 instrumental tunes. 
These songs were compiled in part by Herbert Tampere, an early ethnomusicology field work organizer of the EFA, who along with Erna Tampere and Ottilie Kõiva collected these folk songs\citep{oras2002, tampere2016}. 

 initial analysis I chose a sample of songs all belonging to the same regional dialect and recording method. Once several regions were identified as possible candidates, a native Estonian speaker was consulted on the final selection. The nine songs analyzed in this study were all recorded in Parnümaa county from 1961-1966 by Herbert and Erna Tampere. 
% The first criteria is due to the lossy nature of some of the older files available on the site: the online versions are all compressed lossy, so the analog audio originally recorded on tape and then digitized have a higher resolution, even compressed, than songs that have been copied from wax cylinders or shellac discs onto open-reel tape and then digitizing. 


\section{Annotating the Song Audio }

 Each song's lyrics are copied from the site and saved as .txt files in Estonian orthography, each line of the file corresponding to one melody line.  
Audio files of the selected songs are downloaded from the archive in .ogg format, which is the highest resolution of the two lossy formats available from the digital anthology. Each song is then imported into a Logic Pro X \citep{logic2014} session for beat detection, tempo mapping, and trimming. 
To make the tempo map, the session is set to {\it flex tempo}. From here a beat onset detection algorithm is  given the estimated bpm and time signature as a starting point and then run on the song audio. 
The result is documentationion of the precise moment a given note is realized, the absolute duration of that note, and the fluctuations in tempo from measure to measure.
This is beneficial to my purposes in two ways: by accounting for the natural tempo variation of the a capella songs, and by incorporating acoustic parameters to define the beat, which increases the replicability compared to solely using perceptual judgments. 

\footnote{Using onset detection algorithms such as these \citep{bKeeper2007} in phonetics research, especially in the interdisciplinary field of linguistics and musicology, will be particularly beneficial to answering questions about rhythm: finding a way to bring our intuitions and impressions about ``the beat" together with the acoustic phenomenon. By automating the annotation and measurement process using open source tools, the author hopes to share these machines with those who have similar research interests, and also to invite contributors to the data of this corpus of text data time-aligned to queryable audio signal data. } 
From here, a MIDI track is programmed to create a metronome specifically tailored to the song according to the tempo map. Using the aforementioned {\it flex tempo}, the MIDI track adjusts note and measure length to match the fluctuations documented in the by the beat tracker. Once rendered, the metronome and the song audio file are trimmed to match exactly, and the metronome is converted with a script into a textgrid of beat and measure intervals in PRAAT\citep{boersna2022}. 

 
The orthographic text phrases of the song lyrics are then inserted into each verse-phrase interval, which the eSpeak forced aligner for Estonian \citep{eSpeak1995} uses to reverse-synthesize from the phrase input to the word and phonemic level. Because this forced aligner is trained on spoken, not sung Estonian, manual verification and realignment of the vowel segments used in this dataset was often necessary. \\

\subsection{Adjustment Criteria for Vowel Durations}
The beginning of the vowel was broadly aligned according to a combination of acoustic correlates: at the point where 1. intensity was within 2dB of the steady-state medial portion of the vowel with a slope between 0.5 and zero, 2. frequency stabilizing into that syllable-note's pitch category, and 3. the presence of a voicing bar and visible formants f1, f2, and f3. Manner specific criteria: did not include burst in plosives. Boundaries between fricative onsets and vowels was determined by the end of visible high-frequency noise in the spectrum. Coronal fricative /s/ also consistently showed a carat \ref{} in the frequency track immediately preceding the transition to vowel. For approximants, the additional criteria of steady formants was necessary. Following nasal onsets, vowel intensity {\it lowered}, but a near-zero slope still reliably coincided with the other acoustic correlates. 


 The offset boundaries of vowels was set similarly, but instead with slopes less than or equal to -1 in their transition to occlusions. The first three formants were more variable in transition to codas, so the other cues were relied on more heavily. 

Closed syllables with approximant codas /l/were excluded, as neither the forced-aligner nor the phonetician could determine a reliable way to define the boundary between them. In onset position, the boundary between approximant and vowel was more consistently definable by the above criteria (with the additional requirement of steady formants, which generally coincided with the frequency and intensity cues). In cases of vowel adjacency across syllable boundaries, the presence of a visible glottal stop and a similar (though not as strict) pattern to the above criteria would qualify both for inclusion. In the absence of these cues, both nuclei were excluded from the measurements. Other exclusions were due to ambient noise (i.e., churchbells in song 41), ambiguity of word boundaries due to wordplay or nonse words (verified by native speaker informant), and cases where the transcription indicated epenthesis or severe reduction. 
%epenthesized vowels (i.e., pandi mind paju raiumaie) having mind(e) \\


In all cases, if the aforementioned cues were unavailable, ambiguous, or misaligned, the token was elided for this analysis. From all nine songs in the corpus, a total of 757 vowel nuclei met the criteria for inclusion in duration measurements. For the measurements of F1, F2 space, formants were extracted from the mid point of the vowel. 


At this point, the audio recording of each song has tiers annotated for beat, verse lines, and force-aligned word and phoneme levels.
\subsection{Connecting acoustic measurements to text corpus}

The last step in preprocessing is to integrate the annotation of the song audio with the lexical content of the song. This study accomplishes the task using an open-source natural language toolkit in python called estinltk \url{https://github.com/estnltk} \citep{estnltk2020}. Among other things, the toolkit has a robust dictionary of Estonian grammar, including phonetic transcription of syllables with corresponding quantity and stress data. This is especially important data for testing hypotheses about the ternary quantity contrast, which is not always apparent from the orthography. 
%Linguistic descriptions of the Estonian language date back as early as the seventeenth century, but the ternary quantity contrast was not documented until native Estonian linguists contributed their intuitions. The non-native linguists had only described lexical stress \citep{sargEarlyHistoryEstonian2005a}. \\



Once the annotations are complete, python scripts are used aggregate the audio and text that form this corpus: text files of lyrics are connected to the textgrid files corresponding to the audio, and acoustic measurements are extracted from PRAAT using the parselmouth library\citep{parselmouth2018, python1995}. 




\subsection{Statistical Analysis} 
For each hypothesis, linear mixed-effects models were fit using the lme4 package in R \citep{lme4,r2022}. For models with duration as dependent variable, random intercepts were set for individual song, singer, and word. For HQ, fixed effects were syllable quantity, beat position (ictus), and the interaction of those terms. For HA, the fixed effects were ictus, stress, and the interaction of ictus and stress. 

For the model using vowel dispersion (HS) as the predictor, random intercepts were set for performer, word, and segment quality. Fixed effects were ictus, stress, and the interaction of ictus and stress. 
