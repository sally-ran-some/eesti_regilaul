\chapter{Methods}
\index{Methods@\emph{Methods}}%
I first describe the source materials and the selection criteria for the sample corpus of {\it regilaul} folksongs. Following this, the annotation and measurement procedure is detailed. Then the procedure for assembling the corpus of songs and their text annotations is covered before proceeding to the inclusion criteria for vowel duration and dispersion measurements.
\section{Measurements and Design}

Stress, accent, emphasis: not one cue but a convergence of cues. 
Song structure enforces perceptual isochrony, allows word prominence as long as melodic prominence is met (in singing/piano study) 

Two measurements: vowel duration and vowel space

While f0 is a documented cue of prominence in spoken Estonian, the song melody is strict about frequency and pitch. It is less strict about timbre. 
\subsection{Vowel Duration}
Why vowels and not entire syllables? The reason for this is twofold. First, measuring only the syllable nuclei affords more accurate automation. Were we to measure entire syllables, we would be limited to those with sonorant onset consonants, or in a restricted set of environments where consonant onset would be definable. By measuring only the syllable nuclei, we can reliably include more of the available vowel instances. Second, using the sonorant portions of the syllables makes way for the use of onset detection algorithms, so a strong beat is defined by a consistent threshold for each song, relative to the strength of the other beats in the signal. \\
The previous regilaul studies found evidence of syllable-note isochrony. So, if we see Q2 and Q3 vowels increasing in duration, this would be evidence against those findings. If, however, the long and overlong vowels have less duration than the short ones, this is evidence supporting syllable-note isochrony. Due to the structure of heavy syllables, the vowels must shorten in order to accommodate the additional coda segments within the note. 


\subsection{Vowel Space Area and Dispersion}

As a second measure of prominence, we include vowel space area and dispersion. Studies in English have shown that stress can be thought of as localized hyperarticulation or clear speech. \cite{deJong} Vowel space area and dispersion are well documented acoustic correlates of clear speech in English \cite{bradlow}, and has also been confirmed in cross-linguistic studies with Croatian \cite{rajka} and others. \\

While it has not yet been documented as an acoustic correlate of stress in Estonian, I have reason to believe that it will be an available cue for a singer to use, especially in the context of a song. While duration may or may not be an available prominence cue at the word level, vowel space area and dispersion are prominence cues that would not conflict with the prosodic hierarchy of the song. 

In vocal performance, {\it timbre} is an element free for the singer to use expressively. 
If we think of vowel quality as an element of {\it timbre}, then modulating the size of the vowel space is akin to modifying the size of the filter.

then so long as the word-level categories of quality are preserved, the 


\section{Materials}

\begin{figure}[htbp]
\centering
\includegraphics[width=300pt]{figures/055.png}
\caption{Laula! {\it Sing!}}
\label{default}
\end{figure}




The data for this study was sourced at the Estonian Folklore Archives (EFA). 
\citep{orasEstonianFolkloreArchives2022a}.



Until 1948, songs were collected on wax cylinders, then played on a phonograph and transcribed. shellac discs 1936-38, 746 recordings, 
analogue is the biggest collection in the archive, with over 80,000 individual recordings. Open-reel tape, cassette recordings since the 1970s. 
both wax and disc were re-recorded onto open-reel tape in 78-79.
Presently, the sound engineer Jaan Tamm has been working on preserving the earlier tape recordings in digital form for the EFA. WAV files are stored on CD-Rom at the EFA in Tartu, Estonia, while .mp3 and .ogg lossy formats are uploaded to the internet database. 
% collected by Herbert Tampere, Erna Tampere, and Ottilie Kõiva between 1912 and 1966 for the Estonian Folklore Archives in Tartu, Estonia. \\
%
% and   tunes
%the total number of song recordings is over 26,000. Of these, over 11,000 are from the beginning of the 20th century. Tampere did like 2,000 of them..
%
%%
%The need for writing the tunes live during fieldwork has reduced with the availability of analog and now digital audio recording equipment.




Songs for this paper were accessed via The Anthology of Estonian Traditional Music \citep{tampereAnthologyEstonianTraditional2016}. Originally published on four vinyl discs in 1970(\ref{vinyl1970}, the digital version showcases a robust sample of the massive collection of {\it regilaul} in Estonian Folklore Archives. In addition to audio, the  compilation includes  photographs, sheet music, and performer demographics of 98 {\it regilaul} songs and 17 instrumental tunes. 
These songs were compiled in part by Herbert Tampere, an early ethnomusicology field work organizer of the EFA, who along with Erna Tampere and Ottilie Kõiva collected these folk songs. Pictured in \ref{tampy} is a photograph taken of one of the very field trips to record songs studied in this paper. 

\begin{figure}[htb]
\centering

\includegraphics[width=200pt]{figures/Mf_07027_Tampered_Orik.jpg}
\caption{Herbert Tampere on a field trip}
\label{tampy}
\end{figure}


While the ultimate goal is to continue annotation of the entire available corpus of {\it regilaul}, for the initial analysis I chose a sample of songs all belonging to the same regional dialect and recording method. Once several regions were identified as possible candidates, a native Estonian speaker was consulted on the final selection. The nine songs analyzed in this study were all recorded in Parnümaa county from 1961-1966 by Herbert and Erna Tampere. 
% The first criteria is due to the lossy nature of some of the older files available on the site: the online versions are all compressed lossy, so the analog audio originally recorded on tape and then digitized have a higher resolution, even compressed, than songs that have been copied from wax cylinders or shellac discs onto open-reel tape and then digitizing. 


\section{Annotating the Song Audio }



 Each song's lyrics are copied from the site and saved as .txt files in Estonian orthography, each line of the file corresponding to one melody line.  
Audio files of the selected songs are downloaded from the archive in .ogg format, which is the highest resolution of the two lossy\footnote{define lossy} formats available from the digital anthology. Each song is then imported into a Logic Pro X \citep{b131156} session for beat detection, tempo mapping, and trimming. 
To make the tempo map, the session must be set to {\it flex tempo}. From here a beat onset detection algorithm \citep{robertsonBKeeperBeattrackerLive2007} is  given the transcribed bpm and time signature from the archived song data and run on the imported audio file. The result is an annotation of intervals in time, and the bpm for each measure is annotated according to the performance of the song.
The tempo map allows us to document when {\it exactly} in time the particular singer performed a given note, the duration of the sung note, and the acoustic threshold by which the note is defined as ``strong" relative to surrounding notes. The process is informed by the transcribed bpm and time signature included in the anthology. This is beneficial to my purposes in two ways: by accounting for the natural tempo variation in live performance, and by using a consistent metric to determine beat strength acoustically rather than just perceptually.

 From here, a MIDI track is programmed to create a metronome that is the length of a single syllable-note in the song. In most of these, a 4/4 measure contains eight eighth notes, so the metronome track contains four eighth notes indicating the ``ictus" beats. In flex tempo mode, the MIDI track adjusts note and measure length to match the fluctuations in tempo as documented in the map for the song. The metronome and the song audio file are trimmed to match exactly, and the metronome is converted into a textgrid in PRAAT\citep{boersnaPraatDoingPhonetics2022}, where the annotation process continues. 

 


The orthographic text phrases of the song lyrics are then inserted into each phrase interval with a script, and then eSpeak forced aligner for Estonian \citep{duddingtonESpeakSpeechSynthesizer1995} is run on each phrase to the word and phonemic level. Because this forced aligner is trained on spoken, not sung Estonian, the aligner sometimes tries to align words into the signal before they are uttered. In these cases, the word level tier is manually realigned so that it contains all and only the transcribed word, and then the forced aligner is re-run on this word to the segmental level. In the case of a vowel interval containing an obvious silent portion or occlusion, the boundary is manually adjusted to only include sonorant portions of the signal. 
% \begin{figure}[ht]
%\begin{center}
%			\includegraphics[width=300pt]{figures/phrase_grid.png}
%			\caption{single phrase annotation}
%\label{phrase}
%\end{center}
%\end{figure}
%\begin{figure}[hb]
%		\begin{center}
%			\includegraphics[width=300pt]{figures/big_grid.png}
%			
%			\caption{whole song annotation}
%			\label{songwhole}
%		\end{center}
%\end{figure}
%	
%	 In \ref{phrase} is a completed annotation of a single phrase from a song, and in \ref{songwhole} is an entire song file's interval annotation.

At this point, the audio recording of each song has tiers annotated for tempo and strong beat, verse line phrases, two interval tiers force-aligned to word and phoneme levels, and a separate tier with intervals of the individual vowel segments of interest copied from the phoneme tier.
\section{Assembling the corpus and annotations}
The last step in preprocessing is to integrate the annotation of the song audio with the lexical content of the song. This study accomplishes the task using an open-source natural language toolkit in python called estinltk \url{https://github.com/estnltk} \citep{laur-EtAl:2020:LREC}. Among other things, the toolkit has a robust dictionary of Estonian grammar, including phonetic transcription of syllables with quantity and stress data. 


Thus the data structure of this corpus offers two independent metrics of rhythmic prominence in these songs. From the audio recording and the beat detection, we have an annotation of strong beats based on replicable acoustic measurements, and from the dictionary in the natural language toolkit, we have native speaker intuitions about the lexical weight and prominence in the words of the text. While the stress system is generally predictable, the syllable quantity is not always apparent from the orthography, and not always detectible by a non-native listener. Linguistic descriptions of the Estonian language date back as early as the seventeenth century, but the ternary quantity contrast was not documented until native Estonian linguists contributed their intuitions. The non-native linguists had only described lexical stress \citep{sargEarlyHistoryEstonian2005a}. \\

Using onset detection algorithms such as these \citep{robertsonBKeeperBeattrackerLive2007} in phonetics research, especially in the interdisciplinary field of linguistics and musicology, will be particularly beneficial to answering questions about rhythm: finding a way to bring our intuitions and impressions about ``the beat" together with the acoustic phenomenon. By automating the annotation and measurement process using open source tools, the author hopes to share these machines with those who have similar research interests, and also to invite contributors to the data of this corpus of text data time-aligned to queryable audio signal data. 

\section{Study Design}
\subsection{Questions and Hypotheses}

\subsection{Inclusion Criteria for Vowel Measurements}

Once the annotations are complete, the corresponding text files are aggregated and, the corresponding measurements from PRAAT are concatenated via python using the parselmouth library python interface to PRAAT \citep{parselmouth, van1995python}. 
 I extracted vowel intervals which met the following inclusion criteria. For this study, we are interested in the durations of vowels in initial and pen-initial syllable-notes that are transcribed as isochronous in the melodic transcription. 

\subsection{Statistical Analysis} 

For stress and ictus, only q1 and q2 syllables (Q3 never unstressed). \\
for quantity and ictus, only word-level stressed syllables



Design-based formula
Hierarchical Linear Model with group-specific terms

\cite{goodrichRstanarmBayesianApplied2020,brillemanJointLongitudinalTimetoevent2018}
